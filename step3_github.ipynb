{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec7d8f-d2b3-4b61-ad8c-84c278e6c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 1: Imports and Helper Functions ---\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import pytz\n",
    "import traceback\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks # For peak finding in flattened spectra\n",
    "\n",
    "\n",
    "# --- Import FOOOF ---\n",
    "try:\n",
    "    from fooof import FOOOF\n",
    "    from fooof.bands import Bands\n",
    "    from fooof.sim.gen import gen_aperiodic # For generating aperiodic fits\n",
    "    print(f\"Successfully imported 'FOOOF' class, 'Bands', and 'gen_aperiodic'.\")\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR: Could not import 'FOOOF': {e}\"); sys.exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during FOOOF import: {e}\"); sys.exit()\n",
    "\n",
    "# --- Helper Function to add metrics text to plots ---\n",
    "def add_metrics_to_plot(ax, fm_obj, fit_type=\"\", model_choice=None, best_model_flag=False):\n",
    "    \"\"\"Adds aperiodic parameters and fit metrics to the top-right of a FOOOF plot.\n",
    "       bbox facecolor changes based on whether it's the 'best_model_flag'.\n",
    "    \"\"\"\n",
    "    if not fm_obj or not fm_obj.has_model:\n",
    "        line1 = f\"Model: {fit_type or 'N/A'}\"\n",
    "        if model_choice:\n",
    "            line1 = f\"Best: NoFit ({model_choice})\"\n",
    "        text_str = f\"{line1}\\nAP: NaN\\nFit: R2=NaN, Err=NaN\"\n",
    "        ax.text(0.98, 0.98, text_str, transform=ax.transAxes, fontsize=8,\n",
    "                verticalalignment='top', horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', fc='lightcoral', alpha=0.75))\n",
    "        return\n",
    "\n",
    "    ap_params = fm_obj.aperiodic_params_\n",
    "    r_sq = fm_obj.r_squared_\n",
    "    err = fm_obj.error_\n",
    "    mode = fm_obj.aperiodic_mode\n",
    "\n",
    "    if model_choice == \"NoFit\":\n",
    "        bg_color = 'lightcoral'\n",
    "    elif best_model_flag:\n",
    "        bg_color = 'lightgreen'\n",
    "    else:\n",
    "        bg_color = 'wheat'\n",
    "\n",
    "    line1 = f\"Model: {model_choice}\" if model_choice else f\"Type: {fit_type}\"\n",
    "    line1 += f\" (Mode: {mode})\"\n",
    "\n",
    "    line2 = \"AP: \"\n",
    "    if mode == 'fixed' and len(ap_params) == 2:\n",
    "        line2 += f\"Off={ap_params[0]:.2f}, Exp={ap_params[1]:.2f}\"\n",
    "    elif mode == 'knee' and len(ap_params) == 3:\n",
    "        offset_label = \"Off\"; knee_label = \"Knee\"; exp_label = \"Exp\"\n",
    "        knee_status = \"\"\n",
    "        if hasattr(fm_obj, 'freqs') and fm_obj.freqs is not None and len(fm_obj.freqs) > 0:\n",
    "            f_min_analysis = fm_obj.freq_range[0]\n",
    "            if ap_params[1] < (f_min_analysis + 2) or (len(ap_params) > 2 and abs(ap_params[2]) < 0.1):\n",
    "                 knee_status = \" (Knee?)\"\n",
    "        line2 += f\"{offset_label}={ap_params[0]:.2f}, {knee_label}={ap_params[1]:.1f}, {exp_label}={ap_params[2]:.2f}{knee_status}\"\n",
    "    else:\n",
    "        line2 += f\"Params={np.round(ap_params, 2)}\"\n",
    "\n",
    "    line3 = f\"Fit: R2={r_sq:.3f}, Err={err:.2e}\"\n",
    "    text_str = f\"{line1}\\n{line2}\\n{line3}\"\n",
    "    ax.text(0.98, 0.98, text_str, transform=ax.transAxes, fontsize=8,\n",
    "            verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', fc=bg_color, alpha=0.75))\n",
    "\n",
    "# Matplotlib settings\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 600\n",
    "\n",
    "print(\"Cell 1: Imports and helper functions defined.\")\n",
    "\n",
    "# --- Prompt user for subject ID (Patient ID) ---\n",
    "# For development, hardcoded; can replace with input() for interactive use\n",
    "# subject_id_input = input(\"Enter subject ID (e.g., RCS08R or RCS20 for RCS20R/L): \").strip().upper()\n",
    "# For example, if file is RCS20R_data.csv, subject_id_input might be \"RCS20R\"\n",
    "# Or if we want to process RCS20L and RCS20R, the script might loop or take specific patient-hemi\n",
    "subject_id_input = \"RCS02L\" # Example: This should be the patient-hemisphere ID\n",
    "print(f\"User specified subject-hemisphere ID: {subject_id_input}\")\n",
    "session_id = subject_id_input # session_id in this script context refers to the patient-hemisphere identifier\n",
    "\n",
    "project_base_path = \"/Users/robertho/Library/CloudStorage/OneDrive-Personal/Research UCSF\"\n",
    "\n",
    "# --- End of Cell 1 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9014a61c-3f1e-493d-a4ad-ff0699f7d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 2: Configuration ---\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from fooof import FOOOF # To print settings if needed\n",
    "import numpy as np # Required for np.inf\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Path Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "try:\n",
    "    # This assumes the notebook is in a 'scripts' or similar folder\n",
    "    current_script_path = os.path.dirname(os.path.abspath(__file__)) # For .py\n",
    "except NameError:\n",
    "    current_script_path = os.getcwd() # For .ipynb\n",
    "\n",
    "print(f\"Project base path determined as: {project_base_path}\")\n",
    "\n",
    "# --- Input Data Paths (derived from project_base_path and session_id from Cell 1) ---\n",
    "# session_id is patient-hemisphere, e.g., \"RCS20R\"\n",
    "patient_code = session_id[:-1] # e.g., \"RCS20\"\n",
    "hemisphere_code_short = session_id[-1] # e.g., \"R\"\n",
    "hemisphere_long = \"Right\" if hemisphere_code_short == \"R\" else \"Left\" if hemisphere_code_short == \"L\" else \"UnknownHemi\"\n",
    "\n",
    "step2_output_folder_name = f\"step2_preprocessed_data_120s_neural_aligned_{patient_code}{hemisphere_code_short}_{hemisphere_long}_AllSessions\"\n",
    "step2_output_path = os.path.join(project_base_path, 'Working', step2_output_folder_name)\n",
    "print(f\"Expecting Step 2 output CSV/JSON files in: {step2_output_path}\")\n",
    "\n",
    "\n",
    "# --- Output Configuration ---\n",
    "output_version_tag = \"neural_pkg_aligned\" # Updated tag\n",
    "fooof_output_folder_py_base = os.path.join(project_base_path, 'Working', f'step3_fooof_results_{output_version_tag}')\n",
    "if not os.path.exists(fooof_output_folder_py_base):\n",
    "    os.makedirs(fooof_output_folder_py_base)\n",
    "    print(f\"Created base output folder for new FOOOF results: {fooof_output_folder_py_base}\")\n",
    "else:\n",
    "    print(f\"Base output folder for new FOOOF results: {fooof_output_folder_py_base}\")\n",
    "\n",
    "# --- Analysis Setup (Defaults, will be refined by loaded params_for_python.json or CSV) ---\n",
    "freq_ranges_default = {\n",
    "    'LowFreq': [10, 40],\n",
    "    'MidFreq': [30, 90],\n",
    "    'WideFreq': [10, 90] # This is our default for Q1 and Q3 if C(FreqRangeLabel) is not used\n",
    "}\n",
    "channels_to_process_default = []\n",
    "electrode_labels_default = {}\n",
    "neural_hemisphere_default = hemisphere_long\n",
    "target_neural_segment_duration_default = 120.0\n",
    "pkg_interpolation_interval_default = 30.0\n",
    "\n",
    "# --- FOOOF Settings (MODIFIED AS PER YOUR REQUEST in original script) ---\n",
    "common_new_fooof_params = {\n",
    "    'peak_width_limits': [2.0, 8.0],\n",
    "    'max_n_peaks': np.inf,\n",
    "    'min_peak_height': 0.0,\n",
    "    'peak_threshold': 2.0,\n",
    "    'verbose': False\n",
    "}\n",
    "basic_fooof_settings = {**common_new_fooof_params, 'aperiodic_mode': 'fixed'}\n",
    "knee_fooof_settings = {**common_new_fooof_params, 'aperiodic_mode': 'knee'}\n",
    "\n",
    "print(\"\\n--- Basic FOOOF Settings (Fixed Mode) - UPDATED ---\")\n",
    "FOOOF(**basic_fooof_settings).print_settings()\n",
    "print(\"\\n--- Advanced FOOOF Settings (Knee Mode) - UPDATED ---\")\n",
    "FOOOF(**knee_fooof_settings).print_settings()\n",
    "\n",
    "\n",
    "# --- NEW: Beta/Gamma Peak Feature Extraction Parameters ---\n",
    "BETA_BAND = [13, 30]  # Hz\n",
    "GAMMA_BAND = [60, 90] # Hz\n",
    "BETA_BASELINE_FREQ_REGION = [10, 12] # Hz region to calculate baseline flat power for beta peaks\n",
    "GAMMA_BASELINE_FREQ_REGION = [55, 59] # Hz region to calculate baseline flat power for gamma peaks\n",
    "PEAK_SIG_SD_THRESHOLD = 1.0 # SDs above baseline region mean in flattened spectrum for a peak to be considered\n",
    "\n",
    "# --- Define Master Table Columns ---\n",
    "# UPDATED to include new metrics\n",
    "master_table_columns = [\n",
    "    'SessionID', 'Hemisphere', 'Channel', 'ElectrodeLabel',\n",
    "    'Neural_Segment_Start_Unixtime', 'Neural_Segment_End_Unixtime',\n",
    "    'Neural_Segment_Duration_Sec',\n",
    "    'FS',\n",
    "    'PSD_Data_Str', 'Frequency_Vector_Str',\n",
    "    'Aligned_PKG_UnixTimestamp', 'Aligned_PKG_DateTime_Str', 'Clinical_State_2min_Window',\n",
    "    'Aligned_BK', 'Aligned_DK', 'Aligned_Tremor_Score', 'Aligned_Tremor',\n",
    "    # NEW Metrics\n",
    "    'Total_Daily_LEDD_mg',\n",
    "    'Beta_Peak_Power_at_DominantFreq',\n",
    "    'Gamma_Peak_Power_at_DominantFreq',\n",
    "    # FOOOF Results\n",
    "    'FreqRangeLabel', 'FreqLow', 'FreqHigh',\n",
    "    'BestModel_AperiodicMode',\n",
    "    'Offset_BestModel', 'Knee_BestModel', 'Exponent_BestModel',\n",
    "    'R2_BestModel', 'Error_BestModel', 'Num_Peaks_BestModel',\n",
    "    'Offset_Fixed', 'Exponent_Fixed',\n",
    "    'R2_Fixed', 'Error_Fixed', 'Num_Peaks_Fixed',\n",
    "    'Offset_Knee', 'Knee_Knee', 'Exponent_Knee',\n",
    "    'R2_Knee', 'Error_Knee', 'Num_Peaks_Knee',\n",
    "    'ErrorMsg_FOOOF'\n",
    "]\n",
    "# fooof_object_columns = ['fm_fixed_obj', 'fm_knee_obj'] # No longer saving full FOOOF objects to master CSV\n",
    "\n",
    "# --- Plotting Configuration for Visualization Cells ---\n",
    "NUM_REPRESENTATIVE_SEGMENTS_PER_CHANNEL = 3\n",
    "APERIODIC_PLOT_TIME_BIN_MINUTES = 30\n",
    "HOURLY_AVG_FREQ = 'H'\n",
    "THIRTY_MIN_AVG_FREQ = '30T' # or '30min'\n",
    "BOXPLOT_PALETTE = \"Set2\"\n",
    "HISTOGRAM_BINS = 50\n",
    "\n",
    "REFINED_MOBILE_STATES = ['Dyskinetic Mobile', 'Non-Dyskinetic Mobile', 'Transitional Mobile']\n",
    "AGGREGATED_MOBILE_NAME = 'Mobile (All Types)'\n",
    "\n",
    "\n",
    "print(\"\\nCell 2: Configuration complete with updated FOOOF settings and new metric parameters.\")\n",
    "# --- End of Cell 2 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf7ef4-f9f6-4e7b-8653-3a19843d4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 3: Load Parameters and Data from CSV & JSON, Calculate Daily LEDD ---\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import pytz\n",
    "import re # Import regular expressions for parsing\n",
    "from datetime import datetime, timezone, time\n",
    "\n",
    "# --- Initialize with defaults (from Cell 2) ---\n",
    "params_from_matlab = {}\n",
    "loaded_freq_ranges = freq_ranges_default.copy()\n",
    "neural_hemisphere = neural_hemisphere_default # Derived from session_id in Cell 2\n",
    "target_neural_segment_duration = target_neural_segment_duration_default\n",
    "pkg_interpolation_interval = pkg_interpolation_interval_default\n",
    "\n",
    "# --- Construct expected filenames and paths (session_id is patient-hemisphere from Cell 1) ---\n",
    "target_csv_filename = f\"Step2_Aligned120sPSDs_{session_id}_Left_AllSessions.csv\"\n",
    "params_json_filename = f\"Step2_params_120sPSDs_{session_id}_Left_AllSessions.json\"\n",
    "\n",
    "csv_file_path = os.path.join(step2_output_path, target_csv_filename)\n",
    "params_json_path = os.path.join(step2_output_path, params_json_filename)\n",
    "\n",
    "# --- Check if files exist ---\n",
    "if not os.path.exists(csv_file_path):\n",
    "    print(f\"ERROR: Main data CSV file not found at {csv_file_path}. Cannot proceed.\")\n",
    "    sys.exit()\n",
    "print(f\"\\nTarget CSV file: {target_csv_filename}\")\n",
    "\n",
    "if not os.path.exists(params_json_path):\n",
    "    print(f\"Warning: Parameters JSON file not found at {params_json_path}. Using defaults for freq_ranges, segment durations.\")\n",
    "else:\n",
    "    print(f\"Target JSON_params file: {params_json_filename}\")\n",
    "\n",
    "# --- Load Main Data from Step 2 CSV file ---\n",
    "fooof_input_df = pd.DataFrame()\n",
    "try:\n",
    "    fooof_input_df = pd.read_csv(csv_file_path)\n",
    "    print(f\"Successfully loaded CSV from Step 2. Shape: {fooof_input_df.shape}\")\n",
    "    if fooof_input_df.empty:\n",
    "        print(\"ERROR: Loaded CSV is empty. Cannot proceed.\")\n",
    "        sys.exit()\n",
    "\n",
    "    # Use session_id (patient-hemisphere) from Cell 1 for consistency\n",
    "    fooof_input_df['SessionID_original_from_csv'] = fooof_input_df.get('PatientID', session_id) # Keep original if exists\n",
    "    fooof_input_df['SessionID'] = session_id # This is patient-hemisphere like RCS20R\n",
    "\n",
    "    if 'Hemisphere' in fooof_input_df.columns and not fooof_input_df['Hemisphere'].isnull().all():\n",
    "        csv_hemisphere = fooof_input_df['Hemisphere'].dropna().iloc[0] if not fooof_input_df['Hemisphere'].dropna().empty else neural_hemisphere_default\n",
    "        if csv_hemisphere.lower() != neural_hemisphere.lower(): # neural_hemisphere from Cell 2 (via session_id)\n",
    "            print(f\"Warning: Hemisphere in CSV ({csv_hemisphere}) differs from expected based on session_id ({neural_hemisphere}). Using value from session_id.\")\n",
    "        fooof_input_df['Hemisphere'] = neural_hemisphere\n",
    "    else:\n",
    "        print(\"Warning: 'Hemisphere' column not found or empty in CSV. Assigning based on session_id.\")\n",
    "        fooof_input_df['Hemisphere'] = neural_hemisphere\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not load or parse CSV file {csv_file_path}: {e}\")\n",
    "    print(traceback.format_exc())\n",
    "    sys.exit()\n",
    "\n",
    "# --- Load Parameters from JSON file (if found) ---\n",
    "electrode_info_matlab = {}\n",
    "if os.path.exists(params_json_path):\n",
    "    print(f\"\\nLoading parameters from JSON: {params_json_path}\")\n",
    "    try:\n",
    "        with open(params_json_path, 'r') as f:\n",
    "            params_from_matlab = json.load(f)\n",
    "        print(\"Parameters JSON loaded successfully.\")\n",
    "        loaded_freq_ranges = params_from_matlab.get('freq_ranges_defined_for_fooof', loaded_freq_ranges)\n",
    "        electrode_info_matlab = params_from_matlab.get('electrode_info_used', {})\n",
    "        target_neural_segment_duration = params_from_matlab.get('target_neural_segment_duration_sec', target_neural_segment_duration)\n",
    "        # ... (other params as in original script) ...\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not load or parse parameters JSON file {params_json_path}: {e}\")\n",
    "else:\n",
    "    print(f\"\\nParameters JSON file not found at {params_json_path}. Using defaults.\")\n",
    "\n",
    "ITERATIVE_FREQ_BANDS = loaded_freq_ranges\n",
    "print(f\"\\nUsing Session ID (Patient-Hemisphere): {session_id}\")\n",
    "print(f\"Using Hemisphere: {neural_hemisphere}\")\n",
    "print(f\"Using freq_ranges for FOOOF: {ITERATIVE_FREQ_BANDS}\")\n",
    "\n",
    "# --- Create dynamic Output Folders ---\n",
    "session_specific_output_folder = os.path.join(fooof_output_folder_py_base, str(session_id), str(neural_hemisphere))\n",
    "visualization_folder_session_specific = os.path.join(session_specific_output_folder, 'visualizations_step3')\n",
    "aperiodic_plot_output_folder_base = visualization_folder_session_specific\n",
    "FIGURES_OUTPUT_PATH_NEW_CELLS = os.path.join(session_specific_output_folder, 'new_analysis_figures') # For Cell 5a,b,c plots\n",
    "DATA_OUTPUT_PATH_NEW_CELLS = os.path.join(session_specific_output_folder, 'new_analysis_data') # For Cell 4b outputs\n",
    "for folder_path in [session_specific_output_folder, visualization_folder_session_specific, FIGURES_OUTPUT_PATH_NEW_CELLS, DATA_OUTPUT_PATH_NEW_CELLS]:\n",
    "    if not os.path.exists(folder_path): os.makedirs(folder_path)\n",
    "print(f\"Step 3 session-specific outputs will be in: {session_specific_output_folder}\")\n",
    "\n",
    "master_csv_filename_patient = f\"MASTER_FOOOF_PKG_results_{session_id}_{output_version_tag}.csv\"\n",
    "master_csv_path_patient_specific = os.path.join(fooof_output_folder_py_base, master_csv_filename_patient)\n",
    "print(f\"Master results CSV for {session_id} will be saved/updated at: {master_csv_path_patient_specific}\")\n",
    "\n",
    "# --- Parse PSD_Data and Frequency_Vector ---\n",
    "def parse_float_string(s):\n",
    "    try: return np.array(s.split(';'), dtype=float)\n",
    "    except: return np.array([]) # return empty if error\n",
    "\n",
    "if 'PSD_Data_Str' in fooof_input_df.columns:\n",
    "    fooof_input_df['PSD_Data'] = fooof_input_df['PSD_Data_Str'].apply(parse_float_string) # Linear power\n",
    "    print(\"Parsed 'PSD_Data_Str' into numpy arrays.\")\n",
    "else:\n",
    "    print(\"ERROR: 'PSD_Data_Str' column not found. Cannot run FOOOF.\"); sys.exit()\n",
    "\n",
    "if 'Frequency_Vector_Str' in fooof_input_df.columns:\n",
    "    fooof_input_df['Frequency_Vector_Raw'] = fooof_input_df['Frequency_Vector_Str'].apply(parse_float_string)\n",
    "    print(\"Parsed 'Frequency_Vector_Str' into numpy arrays (as Frequency_Vector_Raw).\")\n",
    "else:\n",
    "    print(\"ERROR: 'Frequency_Vector_Str' column not found. Cannot run FOOOF.\"); sys.exit()\n",
    "\n",
    "# --- Add/Verify Neural_Segment_Duration_Sec & DateTime columns ---\n",
    "# ... (rest of original Cell 3 for duration, datetime, electrode labels, channels to process) ...\n",
    "if 'Neural_Segment_Duration_Sec' not in fooof_input_df.columns:\n",
    "    if 'Neural_Segment_Start_Unixtime' in fooof_input_df.columns and 'Neural_Segment_End_Unixtime' in fooof_input_df.columns:\n",
    "        fooof_input_df['Neural_Segment_Duration_Sec'] = fooof_input_df['Neural_Segment_End_Unixtime'] - fooof_input_df['Neural_Segment_Start_Unixtime']\n",
    "        print(\"Derived 'Neural_Segment_Duration_Sec' from timestamps.\")\n",
    "    # ... (verification against target_neural_segment_duration) ...\n",
    "else:\n",
    "    fooof_input_df['Neural_Segment_Duration_Sec'] = pd.to_numeric(fooof_input_df['Neural_Segment_Duration_Sec'], errors='coerce')\n",
    "\n",
    "# Add readable DateTime columns\n",
    "if 'Neural_Segment_Start_Unixtime' in fooof_input_df.columns:\n",
    "    fooof_input_df['Neural_Segment_Start_DateTime_UTC'] = pd.to_datetime(fooof_input_df['Neural_Segment_Start_Unixtime'], unit='s', utc=True, errors='coerce')\n",
    "if 'Aligned_PKG_UnixTimestamp' in fooof_input_df.columns: # For clinical state alignment\n",
    "    fooof_input_df['Aligned_PKG_DateTime_UTC'] = pd.to_datetime(fooof_input_df['Aligned_PKG_UnixTimestamp'], unit='s', utc=True, errors='coerce')\n",
    "\n",
    "\n",
    "# Extract unique channels and their electrode labels\n",
    "if 'Channel' in fooof_input_df.columns and 'ElectrodeLabel' in fooof_input_df.columns:\n",
    "    unique_channels_df = fooof_input_df[['Channel', 'ElectrodeLabel']].drop_duplicates().set_index('Channel')\n",
    "    electrode_labels = unique_channels_df['ElectrodeLabel'].to_dict()\n",
    "    print(f\"Derived electrode_labels from CSV: {electrode_labels}\")\n",
    "    channels_to_process = list(electrode_labels.keys())\n",
    "    print(f\"Channels to process based on CSV: {channels_to_process}\")\n",
    "else:\n",
    "    print(\"Warning: 'Channel' or 'ElectrodeLabel' columns not found. Plotting labels might be generic.\")\n",
    "    channels_to_process = list(fooof_input_df['Channel'].unique()) if 'Channel' in fooof_input_df.columns else []\n",
    "    if not electrode_labels and channels_to_process:\n",
    "        electrode_labels = {ch: ch for ch in channels_to_process}\n",
    "\n",
    "\n",
    "print(f\"\\nSample of fooof_input_df head after initial processing (first 2 rows):\")\n",
    "print(fooof_input_df.head(2))\n",
    "print(f\"Columns in fooof_input_df: {fooof_input_df.columns.tolist()}\")\n",
    "\n",
    "print(\"\\nCell 3: Data loading, initial parsing, and Daily LEDD calculation complete.\")\n",
    "# --- End of Cell 3 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad8cad-1d50-414c-9d1a-7757fc231bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Assume pandas as pd and numpy as np are imported\n",
    "# Assume session_id is defined\n",
    "# Define REFINED_MOBILE_STATES and AGGREGATED_MOBILE_NAME\n",
    "REFINED_MOBILE_STATES = [\"Dyskinetic Mobile\", \"Non-Dyskinetic Mobile\", \"Transitional Mobile\"]\n",
    "AGGREGATED_MOBILE_NAME = \"Mobile (All Types)\"\n",
    "\n",
    "print(\"\\n--- Cell 3a: Clinical State Derivation (Point-by-Point Method) ---\")\n",
    "\n",
    "if 'fooof_input_df' not in locals() or fooof_input_df.empty:\n",
    "    print(\"fooof_input_df is empty or not defined. Skipping state derivation.\")\n",
    "    if 'fooof_input_df' in locals() and not fooof_input_df.empty:\n",
    "        fooof_input_df['Clinical_State_2min_Window'] = \"StateProcessingError\"\n",
    "        fooof_input_df['Clinical_State_Aggregated'] = \"StateProcessingError\"\n",
    "else:\n",
    "    required_pkg_cols = ['Aligned_BK', 'Aligned_DK', 'Aligned_PKG_UnixTimestamp']\n",
    "    if not all(col in fooof_input_df.columns for col in required_pkg_cols):\n",
    "        print(f\"ERROR: Missing one or more required PKG columns: {required_pkg_cols}\")\n",
    "        fooof_input_df['Clinical_State_2min_Window'] = \"DataMissingForPKGState\"\n",
    "        fooof_input_df['Clinical_State_Aggregated'] = \"DataMissingForPKGState\"\n",
    "    else:\n",
    "        # Ensure PKG scores are numeric\n",
    "        fooof_input_df['Aligned_BK'] = pd.to_numeric(fooof_input_df['Aligned_BK'], errors='coerce')\n",
    "        fooof_input_df['Aligned_DK'] = pd.to_numeric(fooof_input_df['Aligned_DK'], errors='coerce')\n",
    "\n",
    "        # --- Step 1: Calculate DK Percentiles for Mobile Candidates ---\n",
    "        # Define general mobile candidates based on BK <= 26 OR DK >= 7\n",
    "        is_general_mobile_candidate = (\n",
    "            (fooof_input_df['Aligned_BK'] <= 26) | \n",
    "            (fooof_input_df['Aligned_DK'] >= 7)\n",
    "        )\n",
    "        \n",
    "        # Get DK scores for mobile candidates only\n",
    "        mobile_candidate_dk_scores = fooof_input_df.loc[\n",
    "            is_general_mobile_candidate & fooof_input_df['Aligned_DK'].notna(), \n",
    "            'Aligned_DK'\n",
    "        ]\n",
    "        \n",
    "        if len(mobile_candidate_dk_scores) > 1:\n",
    "            p30_dk = np.percentile(mobile_candidate_dk_scores, 30)\n",
    "            p70_dk = np.percentile(mobile_candidate_dk_scores, 70)\n",
    "            print(f\"  DK percentiles for mobile candidates: 30th={p30_dk:.2f}, 70th={p70_dk:.2f}\")\n",
    "        else:\n",
    "            print(\"  Warning: Not enough mobile candidate data to calculate DK percentiles.\")\n",
    "            p30_dk = -np.inf\n",
    "            p70_dk = np.inf\n",
    "\n",
    "        # --- Step 2: Apply Point-by-Point State Assignment ---\n",
    "        # This method assigns states based on individual PKG values at each timepoint\n",
    "        def assign_clinical_state_point(row):\n",
    "            \"\"\"\n",
    "            Assigns clinical state based on PKG scores at a single timepoint.\n",
    "            This is a point-by-point method without temporal windowing.\n",
    "            \"\"\"\n",
    "            bk = row['Aligned_BK']\n",
    "            dk = row['Aligned_DK']\n",
    "            \n",
    "            if pd.isna(bk) or pd.isna(dk):\n",
    "                return \"Other\"\n",
    "            \n",
    "            # Sleep state: BK >= 80\n",
    "            if bk >= 80:\n",
    "                return \"Sleep\"\n",
    "            \n",
    "            # Immobile state: BK > 26 AND BK < 80 AND DK < 7\n",
    "            elif (bk > 26) and (bk < 80) and (dk < 7):\n",
    "                return \"Immobile\"\n",
    "            \n",
    "            # Mobile states: BK <= 26 OR DK >= 7\n",
    "            elif (bk <= 26) or (dk >= 7):\n",
    "                # Subdivide mobile states based on DK percentiles\n",
    "                if pd.notna(p30_dk) and pd.notna(p70_dk):\n",
    "                    if dk <= p30_dk:\n",
    "                        return \"Non-Dyskinetic Mobile\"\n",
    "                    elif dk > p70_dk:\n",
    "                        return \"Dyskinetic Mobile\"\n",
    "                    else:  # p30_dk < dk <= p70_dk\n",
    "                        return \"Transitional Mobile\"\n",
    "                else:\n",
    "                    # If percentiles couldn't be calculated, use generic mobile\n",
    "                    return \"Mobile (Generic)\"\n",
    "            \n",
    "            else:\n",
    "                return \"Other\"\n",
    "\n",
    "        # Apply the state assignment function to each row\n",
    "        fooof_input_df['Clinical_State_2min_Window'] = fooof_input_df.apply(\n",
    "            assign_clinical_state_point, axis=1\n",
    "        )\n",
    "        \n",
    "        print(f\"  Assigned clinical states using point-by-point method.\")\n",
    "        print(f\"  Note: Column is named 'Clinical_State_2min_Window' for compatibility,\")\n",
    "        print(f\"        but uses instantaneous PKG values, not temporal windowing.\")\n",
    "\n",
    "        # --- Step 3: Create Aggregated Clinical States ---\n",
    "        # Group all refined mobile states into one category\n",
    "        def create_aggregated_state(state):\n",
    "            \"\"\"\n",
    "            Aggregates refined mobile states into a single 'Mobile (All Types)' category.\n",
    "            Non-mobile states remain unchanged.\n",
    "            \"\"\"\n",
    "            if state in REFINED_MOBILE_STATES:\n",
    "                return AGGREGATED_MOBILE_NAME\n",
    "            elif state == \"Mobile (Generic)\":\n",
    "                # Also aggregate the generic mobile fallback\n",
    "                return AGGREGATED_MOBILE_NAME\n",
    "            else:\n",
    "                return state\n",
    "\n",
    "        fooof_input_df['Clinical_State_Aggregated'] = fooof_input_df['Clinical_State_2min_Window'].apply(\n",
    "            create_aggregated_state\n",
    "        )\n",
    "\n",
    "        # --- Step 4: Display Results ---\n",
    "        print(\"\\n  Clinical state distribution (Clinical_State_2min_Window):\")\n",
    "        print(fooof_input_df['Clinical_State_2min_Window'].value_counts(dropna=False))\n",
    "        \n",
    "        print(\"\\n  Aggregated clinical state distribution:\")\n",
    "        print(fooof_input_df['Clinical_State_Aggregated'].value_counts(dropna=False))\n",
    "\n",
    "        # --- Step 5: Verify Data Integrity ---\n",
    "        n_missing_states = fooof_input_df['Clinical_State_2min_Window'].isna().sum()\n",
    "        if n_missing_states > 0:\n",
    "            print(f\"\\n  Warning: {n_missing_states} rows have missing clinical states.\")\n",
    "\n",
    "# Define clinical state colors for plotting\n",
    "CLINICAL_STATE_COLORS = {\n",
    "    'Sleep': '#4169E1',                 # RoyalBlue\n",
    "    'Immobile': '#40E0D0',              # Turquoise\n",
    "    'Non-Dyskinetic Mobile': '#32CD32', # LimeGreen\n",
    "    'Transitional Mobile': '#FFD700',   # Gold\n",
    "    'Dyskinetic Mobile': '#FF6347',     # Tomato\n",
    "    'Mobile (All Types)': 'darkgreen',  # For aggregated view\n",
    "    'Mobile (Generic)': 'darkgreen',    # Fallback mobile state\n",
    "    'Other': '#C0C0C0',                 # Silver\n",
    "    'DataMissingForPKGState': '#F5F5F5',\n",
    "    'StateProcessingError': '#E0E0E0'\n",
    "}\n",
    "\n",
    "print(f\"\\nClinical state colors defined for plotting: {list(CLINICAL_STATE_COLORS.keys())}\")\n",
    "print(\"--- Cell 3a: Clinical State Derivation Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd4465-2302-453f-a2bd-55700e0ebac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- (NEW) Cell 4b: Beta/Gamma Peak Feature Extraction ---\n",
    "# This cell calculates Beta_Peak_Power_at_DominantFreq and Gamma_Peak_Power_at_DominantFreq\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "from fooof import FOOOF\n",
    "from fooof.sim.gen import gen_aperiodic\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "print(\"\\n--- Cell 4b: Starting Beta/Gamma Peak Feature Extraction ---\")\n",
    "\n",
    "if 'fooof_input_df' not in locals() or fooof_input_df.empty:\n",
    "    print(\"fooof_input_df is empty or not defined. Skipping Beta/Gamma feature extraction.\")\n",
    "    if 'fooof_input_df' in locals() and not fooof_input_df.empty:\n",
    "        fooof_input_df['Beta_Peak_Power_at_DominantFreq'] = np.nan\n",
    "        fooof_input_df['Gamma_Peak_Power_at_DominantFreq'] = np.nan\n",
    "else:\n",
    "    required_cols_for_cell4b = ['PSD_Data', 'Frequency_Vector_Raw', 'SessionID', 'Channel', 'ElectrodeLabel']\n",
    "    if not all(col in fooof_input_df.columns for col in required_cols_for_cell4b):\n",
    "        missing_cols = [col for col in required_cols_for_cell4b if col not in fooof_input_df.columns]\n",
    "        print(f\"ERROR: Missing required columns for Beta/Gamma extraction: {missing_cols}. Skipping.\")\n",
    "        fooof_input_df['Beta_Peak_Power_at_DominantFreq'] = np.nan\n",
    "        fooof_input_df['Gamma_Peak_Power_at_DominantFreq'] = np.nan\n",
    "    else:\n",
    "        debug_plot_folder = os.path.join(visualization_folder_session_specific, 'cell4b_debug_plots')\n",
    "        if not os.path.exists(debug_plot_folder):\n",
    "            os.makedirs(debug_plot_folder)\n",
    "        print(f\"Debug plots for Cell 4b will be saved to: {debug_plot_folder}\")\n",
    "        \n",
    "        dominant_beta_freqs_channel = {}\n",
    "        dominant_gamma_freqs_channel = {}\n",
    "\n",
    "        if 'Channel_Display' not in fooof_input_df.columns:\n",
    "            if 'ElectrodeLabel' in fooof_input_df.columns and electrode_labels:\n",
    "                 fooof_input_df['Channel_Display'] = fooof_input_df['Channel'].map(electrode_labels).fillna(fooof_input_df['Channel'])\n",
    "            else:\n",
    "                 fooof_input_df['Channel_Display'] = fooof_input_df['Channel']\n",
    "        \n",
    "        print(\"  Calculating dominant peak frequencies per channel (from flattened spectra)...\")\n",
    "        unique_channels_for_dom_freq = fooof_input_df['Channel'].unique()\n",
    "        \n",
    "        for channel_key in tqdm(unique_channels_for_dom_freq, desc=\"Processing Channels for Dom. Freq\"):\n",
    "            df_channel = fooof_input_df[fooof_input_df['Channel'] == channel_key].copy().reset_index()\n",
    "            el_label_for_channel = df_channel['ElectrodeLabel'].iloc[0]\n",
    "\n",
    "            num_segments_in_channel = len(df_channel)\n",
    "            indices_to_plot = []\n",
    "            if num_segments_in_channel > 0: indices_to_plot.append(0)\n",
    "            if num_segments_in_channel > 2: indices_to_plot.append(num_segments_in_channel // 2)\n",
    "            if num_segments_in_channel > 1: indices_to_plot.append(num_segments_in_channel - 1)\n",
    "            indices_to_plot = sorted(list(set(indices_to_plot)))\n",
    "\n",
    "            all_valid_beta_peak_freqs_channel, all_valid_gamma_peak_freqs_channel = [], []\n",
    "            temp_flattened_psds_log_channel, gamma_baseline_powers_flat_channel, beta_baseline_powers_flat_channel = [], [], []\n",
    "\n",
    "            for idx, segment_row in df_channel.iterrows():\n",
    "                psd_linear, freqs = segment_row['PSD_Data'], segment_row['Frequency_Vector_Raw']\n",
    "                if len(psd_linear) == 0 or np.isnan(psd_linear).any() or len(freqs) == 0: continue # Check freqs too\n",
    "\n",
    "                psd_log = np.log10(psd_linear.clip(min=1e-16))\n",
    "                temp_fooof_settings = common_new_fooof_params.copy()\n",
    "                temp_fooof_settings['aperiodic_mode'] = 'knee'\n",
    "                fm_temp = FOOOF(**temp_fooof_settings)\n",
    "                \n",
    "                try:\n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.filterwarnings('ignore', message=\"divide by zero encountered in power\", category=RuntimeWarning)\n",
    "                        warnings.filterwarnings('ignore', message=\"invalid value encountered in log10\", category=RuntimeWarning)\n",
    "                    fm_temp.fit(freqs, psd_linear, freq_range=[10, 90]) \n",
    "                    if fm_temp.has_model:\n",
    "                        # Generate the aperiodic fit across the FULL original frequency vector\n",
    "                        with warnings.catch_warnings():\n",
    "                            warnings.filterwarnings('ignore', r'invalid value encountered in log10', RuntimeWarning)\n",
    "                            ap_fit_log = gen_aperiodic(freqs, fm_temp.aperiodic_params_)\n",
    "                        \n",
    "                        flattened_psd_log = psd_log - ap_fit_log # This might now contain NaNs if ap_fit_log had NaNs\n",
    "                        \n",
    "                        temp_flattened_psds_log_channel.append({'freqs': freqs, 'flat_psd_log': flattened_psd_log, 'original_index': idx})\n",
    "                        \n",
    "                        gamma_baseline_mask = (freqs >= GAMMA_BASELINE_FREQ_REGION[0]) & (freqs <= GAMMA_BASELINE_FREQ_REGION[1])\n",
    "                        if np.any(gamma_baseline_mask):\n",
    "                            gamma_baseline_powers_flat_channel.append(np.mean(flattened_psd_log[gamma_baseline_mask])) # Keep np.mean for now, will use np.nanmean on the list\n",
    "                        \n",
    "                        beta_baseline_mask = (freqs >= BETA_BASELINE_FREQ_REGION[0]) & (freqs <= BETA_BASELINE_FREQ_REGION[1])\n",
    "                        if np.any(beta_baseline_mask):\n",
    "                            beta_baseline_powers_flat_channel.append(np.mean(flattened_psd_log[beta_baseline_mask]))\n",
    "                except Exception as e:\n",
    "                    continue \n",
    "            \n",
    "            if not temp_flattened_psds_log_channel:\n",
    "                dominant_beta_freqs_channel[channel_key], dominant_gamma_freqs_channel[channel_key] = np.nan, np.nan\n",
    "                print(f\"    Channel {el_label_for_channel}: No dominant beta/gamma peak found (no flattened spectra).\")\n",
    "                continue\n",
    "\n",
    "            mean_ch_flat_power_at_gamma_baseline = np.nanmean(gamma_baseline_powers_flat_channel) if gamma_baseline_powers_flat_channel else 0\n",
    "            std_ch_flat_power_at_gamma_baseline = np.nanstd(gamma_baseline_powers_flat_channel) if gamma_baseline_powers_flat_channel else 0\n",
    "            mean_ch_flat_power_at_beta_baseline = np.nanmean(beta_baseline_powers_flat_channel) if beta_baseline_powers_flat_channel else 0\n",
    "            std_ch_flat_power_at_beta_baseline = np.nanstd(beta_baseline_powers_flat_channel) if beta_baseline_powers_flat_channel else 0\n",
    "\n",
    "            # Check if baselines became NaN (e.g., if ALL segments had NaN in baseline regions)\n",
    "            if np.isnan(mean_ch_flat_power_at_beta_baseline) or np.isnan(std_ch_flat_power_at_beta_baseline):\n",
    "                print(f\"    Channel {el_label_for_channel}: Beta baseline calculation resulted in NaN. Skipping beta peak search for this channel.\")\n",
    "            if np.isnan(mean_ch_flat_power_at_gamma_baseline) or np.isnan(std_ch_flat_power_at_gamma_baseline):\n",
    "                 print(f\"    Channel {el_label_for_channel}: Gamma baseline calculation resulted in NaN. Skipping gamma peak search for this channel.\")\n",
    "\n",
    "            for flat_data in temp_flattened_psds_log_channel:\n",
    "                freqs, flattened_psd_log, original_idx = flat_data['freqs'], flat_data['flat_psd_log'], flat_data['original_index']\n",
    "                \n",
    "                # Initialize as no peaks found\n",
    "                current_seg_beta_peaks, current_seg_gamma_peaks = [], []\n",
    "                properties_beta, properties_gamma = {}, {}\n",
    "\n",
    "                # Beta Peak Finding\n",
    "                if not (np.isnan(mean_ch_flat_power_at_beta_baseline) or np.isnan(std_ch_flat_power_at_beta_baseline)):\n",
    "                    height_threshold_beta = mean_ch_flat_power_at_beta_baseline + PEAK_SIG_SD_THRESHOLD * std_ch_flat_power_at_beta_baseline\n",
    "                    if not np.isnan(height_threshold_beta): # Ensure threshold is valid\n",
    "                        beta_band_indices = (freqs >= BETA_BAND[0]) & (freqs <= BETA_BAND[1])\n",
    "                        valid_beta_data = flattened_psd_log[beta_band_indices]\n",
    "                        valid_beta_data = valid_beta_data[~np.isnan(valid_beta_data)] # Remove NaNs before find_peaks\n",
    "                        if valid_beta_data.size > 0:\n",
    "                            peaks_beta_indices_local, properties_beta = find_peaks(valid_beta_data, height=height_threshold_beta, prominence=0.02)\n",
    "                            if peaks_beta_indices_local.size > 0:\n",
    "                                original_beta_freqs = freqs[beta_band_indices][~np.isnan(flattened_psd_log[beta_band_indices])]\n",
    "                                all_valid_beta_peak_freqs_channel.append(original_beta_freqs[peaks_beta_indices_local[np.argmax(properties_beta['peak_heights'])]])\n",
    "                                current_seg_beta_peaks = original_beta_freqs[peaks_beta_indices_local] # For plotting\n",
    "\n",
    "                # Gamma Peak Finding\n",
    "                if not (np.isnan(mean_ch_flat_power_at_gamma_baseline) or np.isnan(std_ch_flat_power_at_gamma_baseline)):\n",
    "                    height_threshold_gamma = mean_ch_flat_power_at_gamma_baseline + PEAK_SIG_SD_THRESHOLD * std_ch_flat_power_at_gamma_baseline\n",
    "                    if not np.isnan(height_threshold_gamma): # Ensure threshold is valid\n",
    "                        gamma_band_indices = (freqs >= GAMMA_BAND[0]) & (freqs <= GAMMA_BAND[1])\n",
    "                        valid_gamma_data = flattened_psd_log[gamma_band_indices]\n",
    "                        valid_gamma_data = valid_gamma_data[~np.isnan(valid_gamma_data)] # Remove NaNs\n",
    "                        if valid_gamma_data.size > 0:\n",
    "                            peaks_gamma_indices_local, properties_gamma = find_peaks(valid_gamma_data, height=height_threshold_gamma, prominence=0.02)\n",
    "                            if peaks_gamma_indices_local.size > 0:\n",
    "                                original_gamma_freqs = freqs[gamma_band_indices][~np.isnan(flattened_psd_log[gamma_band_indices])]\n",
    "                                all_valid_gamma_peak_freqs_channel.append(original_gamma_freqs[peaks_gamma_indices_local[np.argmax(properties_gamma['peak_heights'])]])\n",
    "                                current_seg_gamma_peaks = original_gamma_freqs[peaks_gamma_indices_local] # For plotting\n",
    "                \n",
    "                if original_idx in indices_to_plot:\n",
    "                    plt.figure(figsize=(15, 7))\n",
    "                    plt.plot(freqs, flattened_psd_log, color='k', label='Flattened Spectrum (NaNs may be present)')\n",
    "                    if not (np.isnan(mean_ch_flat_power_at_beta_baseline) or np.isnan(std_ch_flat_power_at_beta_baseline) or np.isnan(height_threshold_beta)):\n",
    "                        plt.axvspan(BETA_BAND[0], BETA_BAND[1], color='red', alpha=0.1, label='Beta Band')\n",
    "                        plt.hlines(y=height_threshold_beta, xmin=BETA_BAND[0], xmax=BETA_BAND[1], color='r', linestyle='--', label=f'Beta Threshold ({height_threshold_beta:.3f})')\n",
    "                        if len(current_seg_beta_peaks) > 0 and 'peak_heights' in properties_beta: plt.scatter(current_seg_beta_peaks, properties_beta['peak_heights'], color='r', s=80, marker='x', label='Detected Beta Peaks')\n",
    "                    \n",
    "                    if not (np.isnan(mean_ch_flat_power_at_gamma_baseline) or np.isnan(std_ch_flat_power_at_gamma_baseline) or np.isnan(height_threshold_gamma)):\n",
    "                        plt.axvspan(GAMMA_BAND[0], GAMMA_BAND[1], color='green', alpha=0.1, label='Gamma Band')\n",
    "                        plt.hlines(y=height_threshold_gamma, xmin=GAMMA_BAND[0], xmax=GAMMA_BAND[1], color='g', linestyle='--', label=f'Gamma Threshold ({height_threshold_gamma:.3f})')\n",
    "                        if len(current_seg_gamma_peaks) > 0 and 'peak_heights' in properties_gamma: plt.scatter(current_seg_gamma_peaks, properties_gamma['peak_heights'], color='g', s=80, marker='x', label='Detected Gamma Peaks')\n",
    "                    \n",
    "                    plt.title(f'Debug: Flattened Spectrum - Ch: {el_label_for_channel} (Seg Idx: {original_idx}) - Knee Fit for Flattening')\n",
    "                    plt.xlabel('Frequency (Hz)'), plt.ylabel('Log Power (Aperiodic Removed)'), plt.xlim(0, 100)\n",
    "                    plt.grid(True, linestyle=':', alpha=0.6), plt.legend()\n",
    "                    plt.savefig(os.path.join(debug_plot_folder, f'Debug_{el_label_for_channel}_Seg{original_idx}_KneeFlatten_NaNRobust.png')), plt.close()\n",
    "\n",
    "            if all_valid_beta_peak_freqs_channel:\n",
    "                mode_res_beta = stats.mode(all_valid_beta_peak_freqs_channel, keepdims=False)\n",
    "                dominant_beta_freqs_channel[channel_key] = mode_res_beta.mode if mode_res_beta.count > 0 else np.nan\n",
    "            else: dominant_beta_freqs_channel[channel_key] = np.nan\n",
    "            if all_valid_gamma_peak_freqs_channel:\n",
    "                mode_res_gamma = stats.mode(all_valid_gamma_peak_freqs_channel, keepdims=False)\n",
    "                dominant_gamma_freqs_channel[channel_key] = mode_res_gamma.mode if mode_res_gamma.count > 0 else np.nan\n",
    "            else: dominant_gamma_freqs_channel[channel_key] = np.nan\n",
    "\n",
    "            if pd.isna(dominant_beta_freqs_channel[channel_key]): print(f\"    Channel {el_label_for_channel}: No dominant beta peak found.\")\n",
    "            else: print(f\"    Channel {el_label_for_channel}: Found dominant beta peak: {dominant_beta_freqs_channel[channel_key]:.2f} Hz.\")\n",
    "            if pd.isna(dominant_gamma_freqs_channel[channel_key]): print(f\"    Channel {el_label_for_channel}: No dominant gamma peak found.\")\n",
    "            else: print(f\"    Channel {el_label_for_channel}: Found dominant gamma peak: {dominant_gamma_freqs_channel[channel_key]:.2f} Hz.\")\n",
    "\n",
    "        fooof_input_df['Beta_Peak_Power_at_DominantFreq'], fooof_input_df['Gamma_Peak_Power_at_DominantFreq'] = np.nan, np.nan\n",
    "        print(\"  Extracting power at dominant frequencies from original log-scaled PSDs...\")\n",
    "        for index, row_seg in tqdm(fooof_input_df.iterrows(), total=fooof_input_df.shape[0], desc=\"Extracting Peak Powers\"):\n",
    "            channel_key_seg, psd_linear_seg, freqs_seg = row_seg['Channel'], row_seg['PSD_Data'], row_seg['Frequency_Vector_Raw']\n",
    "            if len(psd_linear_seg) == 0 or len(freqs_seg) == 0: continue\n",
    "            psd_log_seg = np.log10(psd_linear_seg.clip(min=1e-16)) # Original log PSD for power extraction\n",
    "            dom_beta_freq, dom_gamma_freq = dominant_beta_freqs_channel.get(channel_key_seg, np.nan), dominant_gamma_freqs_channel.get(channel_key_seg, np.nan)\n",
    "            if not pd.isna(dom_beta_freq):\n",
    "                fooof_input_df.loc[index, 'Beta_Peak_Power_at_DominantFreq'] = psd_log_seg[np.argmin(np.abs(freqs_seg - dom_beta_freq))]\n",
    "            if not pd.isna(dom_gamma_freq):\n",
    "                fooof_input_df.loc[index, 'Gamma_Peak_Power_at_DominantFreq'] = psd_log_seg[np.argmin(np.abs(freqs_seg - dom_gamma_freq))]\n",
    "        \n",
    "        print(\"  Finished extracting Beta/Gamma peak powers.\")\n",
    "        print(f\"  Example Beta Peak Powers: {fooof_input_df['Beta_Peak_Power_at_DominantFreq'].dropna().unique()[:5]}\")\n",
    "        print(f\"  Example Gamma Peak Powers: {fooof_input_df['Gamma_Peak_Power_at_DominantFreq'].dropna().unique()[:5]}\")\n",
    "\n",
    "print(\"\\n--- Cell 4b: Beta/Gamma Peak Feature Extraction Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a14dd8d-07d5-4d23-8ec3-f69c7bba0ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 4: Primary FOOOF Aperiodic Fitting & Hump Analysis ---\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "from fooof import FOOOF \n",
    "from fooof.sim.gen import gen_aperiodic\n",
    "\n",
    "print(\"Starting Primary FOOOF Aperiodic Fitting & Hump Analysis ---\")\n",
    "start_time_cell4_modified = time.time()\n",
    "\n",
    "# Helper Function to find all continuous oscillatory humps\n",
    "def find_oscillatory_humps(fm):\n",
    "    if not fm.has_model: return []\n",
    "    aperiodic_fit = gen_aperiodic(fm.freqs, fm.aperiodic_params_, fm.aperiodic_mode)\n",
    "    periodic_component = fm.fooofed_spectrum_ - aperiodic_fit # fooofed_spectrum_ is log P, ap fit is log P\n",
    "    positive_indices = np.where(periodic_component > 1e-2)[0]\n",
    "    if positive_indices.size == 0: return []\n",
    "    humps = []\n",
    "    group_boundaries = np.where(np.diff(positive_indices) > 1)[0]\n",
    "    start_idx = 0\n",
    "    for boundary in group_boundaries:\n",
    "        hump_indices = positive_indices[start_idx : boundary + 1]\n",
    "        max_power_in_hump_idx = hump_indices[np.argmax(periodic_component[hump_indices])]\n",
    "        humps.append({\n",
    "            'hump_start_freq': fm.freqs[hump_indices[0]], 'hump_end_freq': fm.freqs[hump_indices[-1]],\n",
    "            'hump_width': fm.freqs[hump_indices[-1]] - fm.freqs[hump_indices[0]],\n",
    "            'hump_max_power_freq': fm.freqs[max_power_in_hump_idx],\n",
    "            'hump_max_power_val': periodic_component[max_power_in_hump_idx] # This is height above aperiodic\n",
    "        })\n",
    "        start_idx = boundary + 1\n",
    "    last_hump_indices = positive_indices[start_idx:]\n",
    "    if last_hump_indices.size > 0:\n",
    "        max_power_in_hump_idx = last_hump_indices[np.argmax(periodic_component[last_hump_indices])]\n",
    "        humps.append({\n",
    "            'hump_start_freq': fm.freqs[last_hump_indices[0]], 'hump_end_freq': fm.freqs[last_hump_indices[-1]],\n",
    "            'hump_width': fm.freqs[last_hump_indices[-1]] - fm.freqs[last_hump_indices[0]],\n",
    "            'hump_max_power_freq': fm.freqs[max_power_in_hump_idx],\n",
    "            'hump_max_power_val': periodic_component[max_power_in_hump_idx]\n",
    "        })\n",
    "    return humps\n",
    "\n",
    "if 'fooof_input_df' not in locals() or fooof_input_df.empty:\n",
    "    sys.exit(\"ERROR: fooof_input_df not defined or empty in Cell 4. Run previous cells.\")\n",
    "if 'ITERATIVE_FREQ_BANDS' not in locals(): # from Cell 3 (via Cell 2 defaults)\n",
    "    sys.exit(\"ERROR: ITERATIVE_FREQ_BANDS not defined. Run previous cells.\")\n",
    "\n",
    "collected_hump_results_cell4 = []\n",
    "fine_grain_aperiodic_results_cell4 = []\n",
    "all_raw_psds_for_averaging_cell4 = []\n",
    "\n",
    "print(f\"Processing {len(fooof_input_df)} PSD segments from fooof_input_df (for aperiodic params & humps).\")\n",
    "# Total iterations: segments * num_freq_bands_to_fooof_over * num_aperiodic_modes\n",
    "num_freq_bands_to_fooof = len(ITERATIVE_FREQ_BANDS)\n",
    "num_ap_modes_to_fooof = 2 # fixed and knee\n",
    "progress_bar_cell4 = tqdm(total=len(fooof_input_df) * num_freq_bands_to_fooof * num_ap_modes_to_fooof, desc=\"Main FOOOF Fitting\")\n",
    "\n",
    "for index, segment_row in fooof_input_df.iterrows():\n",
    "    psd_segment_linear = segment_row['PSD_Data']\n",
    "    freq_vector_raw = segment_row['Frequency_Vector_Raw']\n",
    "    current_channel_key = segment_row['Channel']\n",
    "    current_electrode_label = electrode_labels.get(current_channel_key, current_channel_key) \n",
    "    \n",
    "    segment_timestamp_unix = segment_row['Neural_Segment_Start_Unixtime']\n",
    "    pkg_timestamp_unix = segment_row['Aligned_PKG_UnixTimestamp'] # For merging with clinical state later\n",
    "    segment_datetime_utc = segment_row.get('Neural_Segment_Start_DateTime_UTC', pd.NaT)\n",
    "\n",
    "\n",
    "    if not isinstance(psd_segment_linear, np.ndarray) or psd_segment_linear.size == 0 or len(psd_segment_linear) != len(freq_vector_raw):\n",
    "        progress_bar_cell4.update(num_freq_bands_to_fooof * num_ap_modes_to_fooof)\n",
    "        continue\n",
    "\n",
    "    # Collect raw PSDs (as in original script)\n",
    "    all_raw_psds_for_averaging_cell4.append({\n",
    "        'timestamp_unix': segment_timestamp_unix, 'datetime_utc': segment_datetime_utc,\n",
    "        'channel': current_channel_key, 'electrode_label': current_electrode_label,\n",
    "        'freqs': freq_vector_raw.copy(), 'psd': psd_segment_linear.copy() # Store linear psd\n",
    "    })\n",
    "\n",
    "    for band_label, band_range in ITERATIVE_FREQ_BANDS.items():\n",
    "        for ap_mode_setting_key, current_ap_settings in [('fixed', basic_fooof_settings), ('knee', knee_fooof_settings)]:\n",
    "            fm_obj = FOOOF(**current_ap_settings)\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings('ignore', message=\"divide by zero encountered in power\", category=RuntimeWarning)\n",
    "                    warnings.filterwarnings('ignore', message=\"invalid value encountered in log10\", category=RuntimeWarning)\n",
    "                try:\n",
    "                    # FOOOF expects linear power spectra for fitting\n",
    "                    fm_obj.fit(freq_vector_raw, psd_segment_linear, freq_range=band_range)\n",
    "                except Exception as e_fit:\n",
    "                    # print(f\"Warning: FOOOF fit failed for seg {index}, ch {current_channel_key}, band {band_label}, mode {ap_mode_setting_key}. Error: {e_fit}\")\n",
    "                    pass # fm_obj.has_model will be False\n",
    "    \n",
    "                if fm_obj.has_model:\n",
    "                    ap_params_fit = fm_obj.aperiodic_params_ # Offset, [Knee], Exponent (these are for log-log space)\n",
    "                    \n",
    "                    # Aperiodic results\n",
    "                    aperiodic_result_entry = {\n",
    "                        'timestamp_unix': pkg_timestamp_unix, # Using PKG timestamp for alignment\n",
    "                        'channel': current_channel_key,\n",
    "                        'electrode_label': current_electrode_label,\n",
    "                        'freq_band_label': band_label,\n",
    "                        'aperiodic_mode': ap_mode_setting_key, # 'fixed' or 'knee'\n",
    "                        'r_squared': fm_obj.r_squared_,\n",
    "                        'fit_error': fm_obj.error_,\n",
    "                        'aperiodic_offset': ap_params_fit[0],\n",
    "                        'aperiodic_exponent': ap_params_fit[1] if ap_mode_setting_key == 'fixed' else ap_params_fit[2],\n",
    "                        'aperiodic_knee': ap_params_fit[1] if ap_mode_setting_key == 'knee' else np.nan,\n",
    "                        'num_model_peaks': len(fm_obj.peak_params_) if fm_obj.peak_params_ is not None and fm_obj.peak_params_.ndim == 2 else 0\n",
    "                    }\n",
    "                    fine_grain_aperiodic_results_cell4.append(aperiodic_result_entry)\n",
    "    \n",
    "                    # Hump results\n",
    "                    base_hump_result_entry = {\n",
    "                        'timestamp_unix': pkg_timestamp_unix, 'channel': current_channel_key,\n",
    "                        'electrode_label': current_electrode_label,\n",
    "                        'session_id': session_id, 'hemisphere': neural_hemisphere, # session_id is patient-hemi\n",
    "                        'freq_band_label': band_label, 'aperiodic_mode': ap_mode_setting_key,\n",
    "                        'r_squared': fm_obj.r_squared_, 'fit_error': fm_obj.error_,\n",
    "                    }\n",
    "                    humps_found = find_oscillatory_humps(fm_obj)\n",
    "                    if humps_found:\n",
    "                        for hump_data_item in humps_found:\n",
    "                            hump_result_item = base_hump_result_entry.copy()\n",
    "                            hump_result_item.update(hump_data_item)\n",
    "                            collected_hump_results_cell4.append(hump_result_item)\n",
    "                    else: \n",
    "                        no_hump_item = base_hump_result_entry.copy()\n",
    "                        no_hump_item.update({'hump_start_freq': np.nan, 'hump_end_freq': np.nan, 'hump_width': np.nan,\n",
    "                                             'hump_max_power_freq': np.nan, 'hump_max_power_val': np.nan})\n",
    "                        collected_hump_results_cell4.append(no_hump_item)\n",
    "            \n",
    "            progress_bar_cell4.update(1)\n",
    "progress_bar_cell4.close()\n",
    "\n",
    "# Convert results to DataFrames and Save\n",
    "df_hump_results_cell4 = pd.DataFrame(collected_hump_results_cell4)\n",
    "if not df_hump_results_cell4.empty:\n",
    "    print(f\"\\nSuccessfully processed and found {len(df_hump_results_cell4[df_hump_results_cell4['hump_width'].notna()])} oscillatory humps (out of {len(df_hump_results_cell4)} total entries).\")\n",
    "    hump_results_filename_cell4 = os.path.join(DATA_OUTPUT_PATH_NEW_CELLS, f\"{session_id}_{neural_hemisphere}_fooof_hump_results_from_cell4.csv\")\n",
    "    df_hump_results_cell4.to_csv(hump_results_filename_cell4, index=False)\n",
    "    print(f\"Saved oscillatory hump results to: {hump_results_filename_cell4}\")\n",
    "else:\n",
    "    print(\"\\nNo hump results generated in Cell 4.\")\n",
    "\n",
    "\n",
    "# 2. Aperiodic Results (this is the key input for Cell 8 master table generation)\n",
    "df_fine_grain_results_cell4 = pd.DataFrame(fine_grain_aperiodic_results_cell4)\n",
    "if not df_fine_grain_results_cell4.empty:\n",
    "    print(f\"\\nSuccessfully collected {len(df_fine_grain_results_cell4)} aperiodic model fits (fixed & knee per band).\")\n",
    "    fine_grain_results_filepath_cell4 = os.path.join(DATA_OUTPUT_PATH_NEW_CELLS, f\"{session_id}_{neural_hemisphere}_fooof_aperiodic_fits_from_cell4.csv\")\n",
    "    df_fine_grain_results_cell4.to_csv(fine_grain_results_filepath_cell4, index=False)\n",
    "    print(f\"Saved fine-grained aperiodic results to: {fine_grain_results_filepath_cell4}\")\n",
    "else:\n",
    "    print(\"\\nNo fine-grain aperiodic results generated in Cell 4.\")\n",
    "\n",
    "\n",
    "# 3. Raw PSDs (for original Cells 5b, 5c if they are to be run)\n",
    "df_all_raw_psds_cell4 = pd.DataFrame(all_raw_psds_for_averaging_cell4)\n",
    "if not df_all_raw_psds_cell4.empty:\n",
    "    print(f\"\\nCollected {len(df_all_raw_psds_cell4)} raw PSD segments for potential averaging.\")\n",
    "    raw_psds_filename_cell4 = os.path.join(DATA_OUTPUT_PATH_NEW_CELLS, f\"{session_id}_{neural_hemisphere}_raw_psds_for_averaging_from_cell4.parquet\")\n",
    "    df_all_raw_psds_cell4.to_parquet(raw_psds_filename_cell4, index=False) # Parquet is efficient\n",
    "    print(f\"Saved raw PSDs for averaging to: {raw_psds_filename_cell4}\")\n",
    "else:\n",
    "    print(\"\\nNo raw PSDs collected in Cell 4.\")\n",
    "\n",
    "\n",
    "end_time_cell4_modified = time.time()\n",
    "print(f\"\\nCell 4  execution time: {end_time_cell4_modified - start_time_cell4_modified:.2f} seconds.\")\n",
    "print(\"--- Cell 4 : Primary FOOOF Aperiodic Fitting & Hump Analysis Complete ---\")\n",
    "# --- End of Cell 4  ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a250af-8150-4586-8bee-33fd33424e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 5a1: Processing and Summarizing Hump Data ---\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys # For sys.exit\n",
    "\n",
    "print(\"\\n--- Cell 5a1: Starting Hump Data Processing ---\")\n",
    "\n",
    "# Load Data Generated by MODIFIED Cell 4\n",
    "hump_results_input_filename = os.path.join(DATA_OUTPUT_PATH_NEW_CELLS, f\"{session_id}_{neural_hemisphere}_fooof_hump_results_from_cell4.csv\")\n",
    "summary_stats_output_filename = os.path.join(DATA_OUTPUT_PATH_NEW_CELLS, f\"{session_id}_{neural_hemisphere}_hump_width_summary_stats_from_cell5a1.csv\")\n",
    "\n",
    "if not os.path.exists(hump_results_input_filename):\n",
    "    print(f\"Warning: Hump results file from MODIFIED Cell 4 not found: {hump_results_input_filename}. Skipping Cell 5a1.\")\n",
    "    df_hump_results_for_5a1 = pd.DataFrame() \n",
    "else:\n",
    "    try:\n",
    "        df_hump_results_for_5a1 = pd.read_csv(hump_results_input_filename)\n",
    "        print(f\"Successfully loaded hump results from: {hump_results_input_filename}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Hump results file not found at {hump_results_input_filename}. Cannot create plots. Please run MODIFIED Cell 4.\")\n",
    "        sys.exit()\n",
    "\n",
    "    if not df_hump_results_for_5a1.empty and 'hump_width' in df_hump_results_for_5a1.columns:\n",
    "        print(\"\\nSummary Statistics for Oscillatory Hump Width (Hz):\")\n",
    "        group_by_cols_5a1 = ['electrode_label', 'freq_band_label', 'aperiodic_mode']\n",
    "        if 'electrode_label' not in df_hump_results_for_5a1.columns:\n",
    "            if 'channel' in df_hump_results_for_5a1.columns:\n",
    "                print(\"Warning: 'electrode_label' not found, grouping by 'channel' instead for hump stats.\")\n",
    "                group_by_cols_5a1[0] = 'channel'\n",
    "            else:\n",
    "                print(\"Warning: Neither 'electrode_label' nor 'channel' found for grouping hump stats. Skipping.\")\n",
    "                df_hump_results_for_5a1 = pd.DataFrame() # Make it empty\n",
    "\n",
    "        if not df_hump_results_for_5a1.empty:\n",
    "            summary_df_widths_5a1 = df_hump_results_for_5a1.dropna(subset=['hump_width'])\n",
    "            if not summary_df_widths_5a1.empty:\n",
    "                summary_stats_df_5a1 = summary_df_widths_5a1.groupby(\n",
    "                    group_by_cols_5a1\n",
    "                )['hump_width'].describe()\n",
    "                print(\"Note: '50%' in the table below represents the Median.\")\n",
    "                print(summary_stats_df_5a1)\n",
    "                summary_stats_df_5a1.to_csv(summary_stats_output_filename)\n",
    "                print(f\"\\nSaved hump width summary statistics to: {summary_stats_output_filename}\")\n",
    "            else:\n",
    "                print(\"No valid hump widths (non-NaN) found to generate summary statistics.\")\n",
    "    elif df_hump_results_for_5a1.empty:\n",
    "        print(\"Loaded hump results DataFrame (df_hump_results_for_5a1) is empty.\")\n",
    "    else: # df_hump_results_for_5a1 not empty, but 'hump_width' missing\n",
    "        print(\"Warning: 'hump_width' column missing in loaded hump results. Cannot generate summary.\")\n",
    "\n",
    "print(\"\\n--- Cell 5a1: Hump Data Processing Complete ---\")\n",
    "# --- End of Cell 5a1 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a934c4-07ac-4d7b-ba25-ee92c9714288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 5a2: Plots of Hump Width ---\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys # For sys.exit\n",
    "import time # For timing\n",
    "\n",
    "print(\"\\n--- Cell 5a2: Generating Hump Width Plots ---\")\n",
    "start_time_cell5a2 = time.time()\n",
    "\n",
    "WIDTH_LIMIT_HZ_5A2 = 60.0\n",
    "HISTOGRAM_BINS_5A2 = 60\n",
    "\n",
    "hump_results_input_filename_5a2 = os.path.join(DATA_OUTPUT_PATH_NEW_CELLS, f\"{session_id}_{neural_hemisphere}_fooof_hump_results_from_cell4.csv\")\n",
    "histogram_save_path_5a2 = os.path.join(FIGURES_OUTPUT_PATH_NEW_CELLS, 'histograms_hump_width_cell5a2') # Specific subfolder\n",
    "if not os.path.exists(histogram_save_path_5a2): os.makedirs(histogram_save_path_5a2)\n",
    "\n",
    "if not os.path.exists(hump_results_input_filename_5a2):\n",
    "    print(f\"Warning: Hump results file from MODIFIED Cell 4 not found: {hump_results_input_filename_5a2}. Skipping Cell 5a2.\")\n",
    "    df_hump_results_for_5a2 = pd.DataFrame()\n",
    "else:\n",
    "    try:\n",
    "        df_hump_results_for_5a2 = pd.read_csv(hump_results_input_filename_5a2)\n",
    "        print(f\"Successfully loaded hump results from: {hump_results_input_filename_5a2}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Hump results file not found at {hump_results_input_filename_5a2}. Cannot create plots.\")\n",
    "        sys.exit()\n",
    "\n",
    "if not df_hump_results_for_5a2.empty and 'hump_width' in df_hump_results_for_5a2.columns:\n",
    "    print(f\"\\nGenerating histograms with universal smoothing...\")\n",
    "    df_plot_5a2 = df_hump_results_for_5a2.dropna(subset=['hump_width']).copy()\n",
    "    df_plot_5a2 = df_plot_5a2[df_plot_5a2['hump_width'] <= WIDTH_LIMIT_HZ_5A2]\n",
    "\n",
    "    hue_col_5a2 = None\n",
    "    if 'electrode_label' in df_plot_5a2.columns:\n",
    "        hue_col_5a2 = 'electrode_label'\n",
    "    elif 'channel' in df_plot_5a2.columns:\n",
    "        hue_col_5a2 = 'channel'\n",
    "    else:\n",
    "        print(\"Warning: Neither 'electrode_label' nor 'channel' found for hue in hump width plots. Plots may be incorrect.\")\n",
    "\n",
    "    if not df_plot_5a2.empty and hue_col_5a2:\n",
    "        g = sns.FacetGrid(df_plot_5a2, \n",
    "                          col=\"freq_band_label\", row=\"aperiodic_mode\", \n",
    "                          hue=hue_col_5a2, # Use determined hue column\n",
    "                          margin_titles=True, height=4, aspect=1.2, \n",
    "                          sharey=False, legend_out=True)\n",
    "        g.map(sns.histplot, \"hump_width\", bins=HISTOGRAM_BINS_5A2, kde=True)\n",
    "        g.set_axis_labels(\"Oscillatory Hump Width (Hz)\", \"Count\")\n",
    "        g.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\n",
    "        g.set(xlim=(0, WIDTH_LIMIT_HZ_5A2))\n",
    "        g.add_legend(title=hue_col_5a2.replace('_', ' ').title()) # Make legend title nicer\n",
    "        g.fig.suptitle(f'{session_id} - Distribution of Oscillatory Hump Widths (Humps from Cell 4)', y=1.03)\n",
    "        g.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "        \n",
    "        plot_filename_final_5a2 = os.path.join(histogram_save_path_5a2, f\"{session_id}_smoothed_hump_width_histogram_cell5a2.png\")\n",
    "        g.savefig(plot_filename_final_5a2, dpi=300) # Save with 300 dpi for better quality\n",
    "        plt.close(g.fig)\n",
    "        print(f\"Presentation-ready histogram saved to: {plot_filename_final_5a2}\")\n",
    "    elif not hue_col_5a2:\n",
    "        print(\"Skipping hump width plot generation as no suitable hue column was found.\")\n",
    "    else: # df_plot_5a2 is empty\n",
    "        print(\"No data left to plot for hump widths after filtering.\")\n",
    "elif df_hump_results_for_5a2.empty:\n",
    "    print(\"Loaded hump results DataFrame (df_hump_results_for_5a2) is empty.\")\n",
    "else:\n",
    "    print(\"Warning: 'hump_width' column missing in loaded hump results. Cannot create histograms.\")\n",
    "\n",
    "end_time_cell5a2 = time.time()\n",
    "print(f\"\\nCell 5a2 execution time: {end_time_cell5a2 - start_time_cell5a2:.2f} seconds.\")\n",
    "print(\"--- Cell 5a2: Hump Width Plotting Complete ---\")\n",
    "# --- End of Cell 5a2 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d2f2b-80df-4f69-ac3e-e45fc8b2adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 5b: Visualizing Average PSDs by Clinical State ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(\"\\n--- Cell 5b: Starting Average PSD Visualization by Clinical State ---\")\n",
    "\n",
    "# --- Load raw PSDs collected in Cell 4 ---\n",
    "raw_psds_input_filename_c5b = os.path.join(DATA_OUTPUT_PATH_NEW_CELLS, f\"{session_id}_{neural_hemisphere}_raw_psds_for_averaging_from_cell4.parquet\")\n",
    "if not os.path.exists(raw_psds_input_filename_c5b):\n",
    "    print(f\"ERROR: Raw PSDs file from Cell 4 not found: {raw_psds_input_filename_c5b}. Skipping Cell 5b.\")\n",
    "    df_all_raw_psds_for_c5b = pd.DataFrame() # Create empty to allow script to run\n",
    "else:\n",
    "    try:\n",
    "        df_all_raw_psds_for_c5b = pd.read_parquet(raw_psds_input_filename_c5b)\n",
    "        print(f\"Successfully loaded raw PSDs from: {raw_psds_input_filename_c5b}. Shape: {df_all_raw_psds_for_c5b.shape}\")\n",
    "        if 'psd' not in df_all_raw_psds_for_c5b.columns or 'freqs' not in df_all_raw_psds_for_c5b.columns:\n",
    "             print(\"ERROR: 'psd' or 'freqs' column missing in loaded raw PSDs. Cannot proceed with Cell 5b.\")\n",
    "             df_all_raw_psds_for_c5b = pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR loading raw PSDs parquet for Cell 5b: {e}\")\n",
    "        df_all_raw_psds_for_c5b = pd.DataFrame()\n",
    "\n",
    "if df_all_raw_psds_for_c5b.empty:\n",
    "    print(\"No raw PSD data available for Cell 5b. Skipping averaging and plotting.\")\n",
    "elif 'fooof_input_df' not in locals() or fooof_input_df.empty:\n",
    "    print(\"ERROR: fooof_input_df (for clinical states) not available in Cell 5b. Skipping.\")\n",
    "else:\n",
    "    # --- Merge raw PSDs with Clinical State Information ---\n",
    "    print(\"Merging raw PSDs with clinical state information...\")\n",
    "    # Select relevant columns from fooof_input_df for merging\n",
    "    # 'Aligned_PKG_UnixTimestamp' in fooof_input_df corresponds to 'timestamp_unix' in df_all_raw_psds_for_c5b\n",
    "    # 'Channel' in fooof_input_df corresponds to 'channel' in df_all_raw_psds_for_c5b\n",
    "    clinical_cols_to_merge = ['Aligned_PKG_UnixTimestamp', 'Channel',\n",
    "                              'Clinical_State_2min_Window', 'Clinical_State_Aggregated']\n",
    "    if not all(col in fooof_input_df.columns for col in clinical_cols_to_merge):\n",
    "        print(f\"ERROR: One or more clinical columns missing from fooof_input_df: {clinical_cols_to_merge}. Skipping merge.\")\n",
    "        df_merged_psds_for_avg = pd.DataFrame()\n",
    "    else:\n",
    "        df_clinical_states_c5b = fooof_input_df[clinical_cols_to_merge].drop_duplicates()\n",
    "        \n",
    "        # Rename columns for merge if necessary\n",
    "        df_all_raw_psds_for_c5b_renamed = df_all_raw_psds_for_c5b.rename(\n",
    "            columns={'timestamp_unix': 'Aligned_PKG_UnixTimestamp', 'channel': 'Channel'}\n",
    "        )\n",
    "\n",
    "        # Ensure merge keys are of the same type\n",
    "        df_all_raw_psds_for_c5b_renamed['Aligned_PKG_UnixTimestamp'] = df_all_raw_psds_for_c5b_renamed['Aligned_PKG_UnixTimestamp'].astype(int)\n",
    "        df_clinical_states_c5b['Aligned_PKG_UnixTimestamp'] = df_clinical_states_c5b['Aligned_PKG_UnixTimestamp'].astype(int)\n",
    "        df_all_raw_psds_for_c5b_renamed['Channel'] = df_all_raw_psds_for_c5b_renamed['Channel'].astype(str)\n",
    "        df_clinical_states_c5b['Channel'] = df_clinical_states_c5b['Channel'].astype(str)\n",
    "\n",
    "        df_merged_psds_for_avg = pd.merge(\n",
    "            df_all_raw_psds_for_c5b_renamed,\n",
    "            df_clinical_states_c5b,\n",
    "            on=['Aligned_PKG_UnixTimestamp', 'Channel'],\n",
    "            how='left'\n",
    "        )\n",
    "        if 'electrode_label' not in df_merged_psds_for_avg.columns and electrode_labels:\n",
    "             df_merged_psds_for_avg['electrode_label'] = df_merged_psds_for_avg['Channel'].map(electrode_labels)\n",
    "\n",
    "        if df_merged_psds_for_avg.empty:\n",
    "            print(\"No data after merging PSDs with clinical states.\")\n",
    "        else:\n",
    "            print(f\"Successfully merged. Shape of merged data for averaging: {df_merged_psds_for_avg.shape}\")\n",
    "            # Fill NaN clinical states with 'Unknown' for grouping\n",
    "            df_merged_psds_for_avg['Clinical_State_2min_Window'].fillna('Unknown', inplace=True)\n",
    "\n",
    "    if not df_merged_psds_for_avg.empty:\n",
    "        # --- Calculate Average PSDs ---\n",
    "        print(\"Calculating average PSDs per channel and clinical state...\")\n",
    "        example_freqs_c5b = df_merged_psds_for_avg['freqs'].iloc[0]\n",
    "        if isinstance(example_freqs_c5b, str):\n",
    "            example_freqs_c5b = np.array(example_freqs_c5b.split(';'), dtype=float) if ';' in example_freqs_c5b else np.fromstring(example_freqs_c5b.strip('[]'), sep=' ')\n",
    "\n",
    "\n",
    "        # Function to average list of PSD arrays\n",
    "        def average_psds(psd_list):\n",
    "            # Ensure all PSDs are numpy arrays\n",
    "            psd_arrays = []\n",
    "            for item in psd_list:\n",
    "                if isinstance(item, np.ndarray):\n",
    "                    psd_arrays.append(item)\n",
    "                elif isinstance(item, str):\n",
    "                     psd_arrays.append(np.array(item.split(';'), dtype=float) if ';' in item else np.fromstring(item.strip('[]'), sep=' '))\n",
    "            if not psd_arrays:\n",
    "                return None, 0\n",
    "            return np.mean(np.array(psd_arrays), axis=0), len(psd_arrays)\n",
    "\n",
    "        # Group by channel and clinical state, then average PSDs\n",
    "        grouping_cols_c5b = ['Channel', 'electrode_label', 'Clinical_State_2min_Window']\n",
    "        if 'electrode_label' not in df_merged_psds_for_avg.columns:\n",
    "            print(\"Warning: 'electrode_label' not found for grouping in Cell 5b. Using 'Channel'.\")\n",
    "            grouping_cols_c5b = ['Channel', 'Clinical_State_2min_Window']\n",
    "            df_merged_psds_for_avg['electrode_label'] = df_merged_psds_for_avg['Channel'] # temp for loop\n",
    "\n",
    "        \n",
    "        averaged_psd_results_c5b = []\n",
    "        for name, group in tqdm(df_merged_psds_for_avg.groupby(grouping_cols_c5b, observed=True), desc=\"Averaging PSDs\"):\n",
    "            channel_key, el_label, clinical_state = name[0], name[1], name[2]\n",
    "            \n",
    "            avg_psd_linear, n_segments = average_psds(group['psd'].tolist())\n",
    "            if avg_psd_linear is not None:\n",
    "                averaged_psd_results_c5b.append({\n",
    "                    'Channel': channel_key,\n",
    "                    'ElectrodeLabel': el_label if el_label else channel_key, # Fallback if el_label is NaN\n",
    "                    'Clinical_State': clinical_state,\n",
    "                    'Average_PSD_Linear': avg_psd_linear,\n",
    "                    'Frequencies': example_freqs_c5b, # Assumes all segments share this\n",
    "                    'Num_Segments_Averaged': n_segments\n",
    "                })\n",
    "        \n",
    "        df_averaged_psds_c5b = pd.DataFrame(averaged_psd_results_c5b)\n",
    "\n",
    "        if df_averaged_psds_c5b.empty:\n",
    "            print(\"No averaged PSDs were generated.\")\n",
    "        else:\n",
    "            print(f\"Generated {len(df_averaged_psds_c5b)} averaged PSDs.\")\n",
    "            \n",
    "            # --- Plot Average PSDs ---\n",
    "            # One plot per channel, with different clinical states as lines\n",
    "            output_folder_c5b_avg_psd_plots = os.path.join(FIGURES_OUTPUT_PATH_NEW_CELLS, f'average_psds_by_state_cell5b')\n",
    "            if not os.path.exists(output_folder_c5b_avg_psd_plots):\n",
    "                os.makedirs(output_folder_c5b_avg_psd_plots)\n",
    "            print(f\"Average PSD plots will be saved in: {output_folder_c5b_avg_psd_plots}\")\n",
    "\n",
    "            unique_channels_to_plot_c5b = df_averaged_psds_c5b['Channel'].unique()\n",
    "            for ch_key in unique_channels_to_plot_c5b:\n",
    "                df_channel_avg = df_averaged_psds_c5b[df_averaged_psds_c5b['Channel'] == ch_key]\n",
    "                if df_channel_avg.empty: continue\n",
    "\n",
    "                el_label_for_plot = df_channel_avg['ElectrodeLabel'].iloc[0]\n",
    "                \n",
    "                plt.figure(figsize=(12, 7))\n",
    "                for idx, row_avg in df_channel_avg.iterrows():\n",
    "                    state = row_avg['Clinical_State']\n",
    "                    freqs = row_avg['Frequencies']\n",
    "                    avg_psd_log = np.log10(row_avg['Average_PSD_Linear']) # Plot in log10 power\n",
    "                    n_seg = row_avg['Num_Segments_Averaged']\n",
    "                    \n",
    "                    color = NEW_CLINICAL_STATE_COLORS.get(state, '#808080') # Default to gray\n",
    "                    plt.plot(freqs, avg_psd_log, label=f\"{state} (N={n_seg})\", color=color, linewidth=2)\n",
    "                \n",
    "                plt.title(f\"Average PSD by Clinical State - {session_id} - Channel {el_label_for_plot}\")\n",
    "                plt.xlabel(\"Frequency (Hz)\")\n",
    "                plt.ylabel(\"Log10 Power Spectral Density\")\n",
    "                plt.xlim(0, 100) # Typical range, adjust if needed\n",
    "                plt.legend(title=\"Clinical State (10-min window)\")\n",
    "                plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "                plt.tight_layout()\n",
    "                \n",
    "                plot_filename = os.path.join(output_folder_c5b_avg_psd_plots, f\"{session_id}_{el_label_for_plot}_avg_psd_by_state.png\")\n",
    "                plt.savefig(plot_filename)\n",
    "                plt.close()\n",
    "            print(\"Finished plotting average PSDs by clinical state.\")\n",
    "\n",
    "if 'df_averaged_psds_c5b' in locals() and not df_averaged_psds_c5b.empty:\n",
    "    print(\"Cell 5b: Average PSDs DataFrame is available for Cell 5c.\")\n",
    "else:\n",
    "    print(\"Cell 5b: Average PSDs DataFrame is NOT available for Cell 5c.\")\n",
    "    df_averaged_psds_c5b = pd.DataFrame() # Ensure it's defined for 5c check\n",
    "\n",
    "print(\"\\n--- Cell 5b: Average PSD Visualization Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8339ec-fe1c-4070-b1fa-d7b58f36e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 5c: Run FOOOF on Averaged PSDs and Plot ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from fooof import FOOOF # Ensure FOOOF and add_metrics_to_plot are available\n",
    "\n",
    "print(\"\\n--- Cell 5c: Starting FOOOF on Averaged PSDs ---\")\n",
    "\n",
    "if 'df_averaged_psds_c5b' not in locals() or df_averaged_psds_c5b.empty:\n",
    "    print(\"ERROR: Averaged PSDs DataFrame (df_averaged_psds_c5b) not available from Cell 5b. Skipping Cell 5c.\")\n",
    "else:\n",
    "    print(f\"Processing {len(df_averaged_psds_c5b)} averaged PSDs for FOOOF fitting.\")\n",
    "\n",
    "    # Define output folder for FOOOF plots on averaged PSDs\n",
    "    output_folder_c5c_fooof_avg_plots = os.path.join(FIGURES_OUTPUT_PATH_NEW_CELLS, f'fooof_on_average_psds_cell5c')\n",
    "    if not os.path.exists(output_folder_c5c_fooof_avg_plots):\n",
    "        os.makedirs(output_folder_c5c_fooof_avg_plots)\n",
    "    print(f\"FOOOF plots on averaged PSDs will be saved in: {output_folder_c5c_fooof_avg_plots}\")\n",
    "\n",
    "    # Using 'WideFreq' from ITERATIVE_FREQ_BANDS as the default fitting range for these averaged spectra\n",
    "    # You can adapt this if you want to iterate over multiple bands for averaged spectra too.\n",
    "    default_fit_range_label_c5c = 'WideFreq' # Example\n",
    "    if default_fit_range_label_c5c in ITERATIVE_FREQ_BANDS:\n",
    "        current_freq_range_c5c = ITERATIVE_FREQ_BANDS[default_fit_range_label_c5c]\n",
    "    else: # Fallback if 'WideFreq' isn't defined, use the first available or a hardcoded default\n",
    "        current_freq_range_c5c = list(ITERATIVE_FREQ_BANDS.values())[0] if ITERATIVE_FREQ_BANDS else [1, 90]\n",
    "        if ITERATIVE_FREQ_BANDS: default_fit_range_label_c5c = list(ITERATIVE_FREQ_BANDS.keys())[0]\n",
    "        else: default_fit_range_label_c5c = f\"{current_freq_range_c5c[0]}-{current_freq_range_c5c[1]}Hz\"\n",
    "        print(f\"Warning: '{default_fit_range_label_c5c}' not found in ITERATIVE_FREQ_BANDS. Using: {current_freq_range_c5c}\")\n",
    "\n",
    "\n",
    "    fooofed_average_results_c5c = []\n",
    "\n",
    "    for index, row_avg_psd in tqdm(df_averaged_psds_c5b.iterrows(), total=len(df_averaged_psds_c5b), desc=\"FOOOFing Avg PSDs\"):\n",
    "        channel_key = row_avg_psd['Channel']\n",
    "        el_label = row_avg_psd['ElectrodeLabel']\n",
    "        clinical_state = row_avg_psd['Clinical_State']\n",
    "        avg_psd_linear = row_avg_psd['Average_PSD_Linear']\n",
    "        freqs = row_avg_psd['Frequencies']\n",
    "        n_segments = row_avg_psd['Num_Segments_Averaged']\n",
    "\n",
    "        if avg_psd_linear is None or freqs is None or len(avg_psd_linear) == 0:\n",
    "            continue\n",
    "\n",
    "        # --- Prepare Plot for this Averaged Spectrum ---\n",
    "        fig_avg, axes_avg = plt.subplots(1, 2, figsize=(15, 6), gridspec_kw={'width_ratios': [1,1]}) # Two subplots: fixed and knee\n",
    "        fig_avg.suptitle(f\"FOOOF on Averaged PSD: {session_id} - Ch {el_label} - State: {clinical_state} (N={n_segments})\\nFit Range: {default_fit_range_label_c5c} ({current_freq_range_c5c[0]}-{current_freq_range_c5c[1]} Hz)\", fontsize=12)\n",
    "        \n",
    "        models_fitted_this_spectrum = 0\n",
    "        \n",
    "        # --- Fit with 'fixed' aperiodic mode ---\n",
    "        fm_fixed_avg = FOOOF(**basic_fooof_settings) # basic_fooof_settings from Cell 2\n",
    "        try:\n",
    "            fm_fixed_avg.fit(freqs, avg_psd_linear, freq_range=current_freq_range_c5c)\n",
    "            if fm_fixed_avg.has_model:\n",
    "                fm_fixed_avg.plot(ax=axes_avg[0], plt_log=True) # FOOOF plots log power by default\n",
    "                add_metrics_to_plot(axes_avg[0], fm_fixed_avg, model_choice=\"Fixed\", best_model_flag=False) # Using generic colors\n",
    "                axes_avg[0].set_title(\"Aperiodic Mode: Fixed\")\n",
    "                axes_avg[0].grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "                models_fitted_this_spectrum +=1\n",
    "                 # Store results (optional, if you need them later)\n",
    "                fooofed_average_results_c5c.append({\n",
    "                    'Channel': channel_key, 'ElectrodeLabel': el_label, 'Clinical_State': clinical_state,\n",
    "                    'AperiodicMode': 'fixed', 'R2': fm_fixed_avg.r_squared_, 'Error': fm_fixed_avg.error_,\n",
    "                    'Offset': fm_fixed_avg.aperiodic_params_[0], 'Exponent': fm_fixed_avg.aperiodic_params_[1],\n",
    "                    'NumPeaks': len(fm_fixed_avg.peak_params_)\n",
    "                })\n",
    "        except Exception as e_fit_fixed:\n",
    "            print(f\"  Warning: FOOOF 'fixed' fit failed for avg PSD Ch {el_label}, State {clinical_state}. Error: {e_fit_fixed}\")\n",
    "            add_metrics_to_plot(axes_avg[0], None, model_choice=\"Fixed (No Fit)\")\n",
    "            axes_avg[0].set_title(\"Aperiodic Mode: Fixed (No Fit)\")\n",
    "\n",
    "        # --- Fit with 'knee' aperiodic mode ---\n",
    "        fm_knee_avg = FOOOF(**knee_fooof_settings) # knee_fooof_settings from Cell 2\n",
    "        try:\n",
    "            fm_knee_avg.fit(freqs, avg_psd_linear, freq_range=current_freq_range_c5c)\n",
    "            if fm_knee_avg.has_model:\n",
    "                fm_knee_avg.plot(ax=axes_avg[1], plt_log=True)\n",
    "                add_metrics_to_plot(axes_avg[1], fm_knee_avg, model_choice=\"Knee\", best_model_flag=False)\n",
    "                axes_avg[1].set_title(\"Aperiodic Mode: Knee\")\n",
    "                axes_avg[1].grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "                models_fitted_this_spectrum +=1\n",
    "                fooofed_average_results_c5c.append({\n",
    "                    'Channel': channel_key, 'ElectrodeLabel': el_label, 'Clinical_State': clinical_state,\n",
    "                    'AperiodicMode': 'knee', 'R2': fm_knee_avg.r_squared_, 'Error': fm_knee_avg.error_,\n",
    "                    'Offset': fm_knee_avg.aperiodic_params_[0], 'Knee': fm_knee_avg.aperiodic_params_[1], \n",
    "                    'Exponent': fm_knee_avg.aperiodic_params_[2],\n",
    "                    'NumPeaks': len(fm_knee_avg.peak_params_)\n",
    "                })\n",
    "        except Exception as e_fit_knee:\n",
    "            print(f\"  Warning: FOOOF 'knee' fit failed for avg PSD Ch {el_label}, State {clinical_state}. Error: {e_fit_knee}\")\n",
    "            add_metrics_to_plot(axes_avg[1], None, model_choice=\"Knee (No Fit)\")\n",
    "            axes_avg[1].set_title(\"Aperiodic Mode: Knee (No Fit)\")\n",
    "\n",
    "        # Save the combined plot if any model was fitted\n",
    "        if models_fitted_this_spectrum > 0:\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make space for suptitle\n",
    "            plot_filename_avg_fooof = os.path.join(output_folder_c5c_fooof_avg_plots, f\"{session_id}_{el_label}_{clinical_state.replace(' ', '_')}_avg_psd_fooof.png\")\n",
    "            fig_avg.savefig(plot_filename_avg_fooof)\n",
    "        plt.close(fig_avg)\n",
    "\n",
    "    df_fooofed_average_results_c5c = pd.DataFrame(fooofed_average_results_c5c)\n",
    "    if not df_fooofed_average_results_c5c.empty:\n",
    "        print(f\"\\nGenerated {len(df_fooofed_average_results_c5c)} FOOOF model fits for averaged PSDs.\")\n",
    "        avg_fooof_results_filename = os.path.join(DATA_OUTPUT_PATH_NEW_CELLS, f\"{session_id}_{neural_hemisphere}_fooof_fits_on_average_psds_from_cell5c.csv\")\n",
    "        df_fooofed_average_results_c5c.to_csv(avg_fooof_results_filename, index=False)\n",
    "        print(f\"Saved FOOOF results on averaged PSDs to: {avg_fooof_results_filename}\")\n",
    "    else:\n",
    "        print(\"\\nNo FOOOF models were successfully fitted to the averaged PSDs.\")\n",
    "\n",
    "print(\"\\n--- Cell 5c: FOOOF on Averaged PSDs Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1365b273-869e-4759-9880-49d21b242f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 8: Generate and Save Master DataFrame ---\n",
    "# This cell now combines:\n",
    "# 1. Aperiodic parameters (fixed, knee, best) from df_fine_grain_results_cell4\n",
    "# 2. Original segment info, Total_Daily_LEDD_mg, Beta_Peak_Power, Gamma_Peak_Power from fooof_input_df\n",
    "\n",
    "import pandas as pd # Ensure pandas is imported for pd.isna\n",
    "import numpy as np  # Ensure numpy is imported for np.nan\n",
    "import sys          # For sys.exit\n",
    "\n",
    "print(\"\\n--- Cell 8: Starting Master DataFrame Generation (with new metrics) ---\")\n",
    "\n",
    "# Prerequisite DataFrames:\n",
    "# - fooof_input_df (from Cell 3, now with LEDD, Beta_Peak_Power, Gamma_Peak_Power)\n",
    "# - df_fine_grain_results_cell4 (from MODIFIED Cell 4, with detailed aperiodic fits)\n",
    "\n",
    "if 'fooof_input_df' not in locals() or fooof_input_df.empty:\n",
    "    print(\"CRITICAL WARNING in Cell 8: fooof_input_df is not available or empty. Creating a dummy DataFrame for LEDD prompt testing.\")\n",
    "    fooof_input_df = pd.DataFrame({'Total_Daily_LEDD_mg': [np.nan, np.nan, np.nan]}) # Dummy for testing\n",
    "    # sys.exit(\"ERROR in Cell 8: fooof_input_df is not available or empty. Cannot create master table.\")\n",
    "\n",
    "if 'df_fine_grain_results_cell4' not in locals() or ('df_fine_grain_results_cell4' in locals() and df_fine_grain_results_cell4.empty):\n",
    "    print(\"Warning in Cell 8: df_fine_grain_results_cell4 not available or empty. Master table may lack detailed FOOOF results.\")\n",
    "    # Create an empty df with expected columns to allow merge to proceed but result in NaNs for FOOOF columns\n",
    "    df_fine_grain_results_cell4 = pd.DataFrame(columns=['timestamp_unix', 'channel', 'electrode_label', 'freq_band_label', 'aperiodic_mode',\n",
    "                                                        'r_squared', 'fit_error', 'aperiodic_offset', 'aperiodic_knee', \n",
    "                                                        'aperiodic_exponent', 'num_model_peaks'])\n",
    "\n",
    "\n",
    "trigger_ledd_input_prompt = True\n",
    "if 'fooof_input_df' in locals() and ('Total_Daily_LEDD_mg' not in fooof_input_df.columns):\n",
    "    print(\"Warning: 'Total_Daily_LEDD_mg' column missing from fooof_input_df. Cannot prompt for LEDD override.\")\n",
    "    fooof_input_df['Total_Daily_LEDD_mg'] = np.nan # Add the column as NaNs\n",
    "\n",
    "if trigger_ledd_input_prompt:\n",
    "    while True:\n",
    "        try:\n",
    "            user_ledd_value_str = input(\"Please enter a default LEDD value to propagate for the entire 'Total_Daily_LEDD_mg' column (e.g., 0 or 500), or type 'skip' to leave as is: \")\n",
    "            if user_ledd_value_str.lower() == 'skip':\n",
    "                print(\"Skipping LEDD override. 'Total_Daily_LEDD_mg' will remain as is (likely NaNs).\")\n",
    "                break\n",
    "            user_ledd_value = float(user_ledd_value_str)\n",
    "            fooof_input_df['Total_Daily_LEDD_mg'] = user_ledd_value\n",
    "            print(f\"'Total_Daily_LEDD_mg' column has been filled with {user_ledd_value}.\")\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a numeric value for LEDD or 'skip'.\")\n",
    "\n",
    "expected_pivot_values = ['r_squared', 'fit_error', 'aperiodic_offset', 'aperiodic_knee', 'aperiodic_exponent', 'num_model_peaks']\n",
    "actual_pivot_values = [val for val in expected_pivot_values if val in df_fine_grain_results_cell4.columns]\n",
    "\n",
    "if not actual_pivot_values:\n",
    "    print(\"Warning: No value columns found in df_fine_grain_results_cell4 for pivoting. FOOOF params will be empty.\")\n",
    "    df_pivot_foof_params = pd.DataFrame(columns=['Aligned_PKG_UnixTimestamp', 'Channel', 'electrode_label', 'FreqRangeLabel']) # Create empty with index cols\n",
    "    # Add placeholder columns that would have been created by pivot, filled with NaN\n",
    "    pivoted_cols_to_add = []\n",
    "    for mode in ['fixed', 'knee']:\n",
    "        for val_col in expected_pivot_values:\n",
    "            pivoted_cols_to_add.append(f'{val_col}_{mode}')\n",
    "    for col in pivoted_cols_to_add:\n",
    "        df_pivot_foof_params[col] = np.nan\n",
    "\n",
    "else:\n",
    "    df_pivot_foof_params = df_fine_grain_results_cell4.pivot_table(\n",
    "        index=['timestamp_unix', 'channel', 'electrode_label', 'freq_band_label'], \n",
    "        columns='aperiodic_mode',\n",
    "        values=actual_pivot_values,\n",
    "        aggfunc='first' \n",
    "    ).reset_index()\n",
    "    df_pivot_foof_params.columns = [f'{col[0]}_{col[1]}'.rstrip('_') if col[1] else col[0] for col in df_pivot_foof_params.columns]\n",
    "\n",
    "\n",
    "rename_dict_cell8 = { \n",
    "    'r_squared_fixed': 'R2_Fixed', 'fit_error_fixed': 'Error_Fixed',\n",
    "    'aperiodic_offset_fixed': 'Offset_Fixed', 'aperiodic_exponent_fixed': 'Exponent_Fixed',\n",
    "    'num_model_peaks_fixed': 'Num_Peaks_Fixed',\n",
    "    'r_squared_knee': 'R2_Knee', 'fit_error_knee': 'Error_Knee',\n",
    "    'aperiodic_offset_knee': 'Offset_Knee', 'aperiodic_knee_knee': 'Knee_Knee',\n",
    "    'aperiodic_exponent_knee': 'Exponent_Knee',\n",
    "    'num_model_peaks_knee': 'Num_Peaks_Knee',\n",
    "    'channel': 'Channel', 'freq_band_label': 'FreqRangeLabel',\n",
    "    'timestamp_unix': 'Aligned_PKG_UnixTimestamp' \n",
    "}\n",
    "df_pivot_foof_params.rename(columns=rename_dict_cell8, inplace=True)\n",
    "\n",
    "# --- 2. Determine the \"Best Model\" from pivoted FOOOF params ---\n",
    "print(\"Determining best aperiodic model based on R-squared...\")\n",
    "best_model_param_cols = ['BestModel_AperiodicMode', 'Offset_BestModel', 'Exponent_BestModel', \n",
    "                         'Knee_BestModel', 'R2_BestModel', 'Error_BestModel', 'Num_Peaks_BestModel']\n",
    "\n",
    "if 'R2_Fixed' in df_pivot_foof_params.columns and 'R2_Knee' in df_pivot_foof_params.columns:\n",
    "    r2_fixed_fillna = df_pivot_foof_params['R2_Fixed'].fillna(-np.inf)\n",
    "    r2_knee_fillna = df_pivot_foof_params['R2_Knee'].fillna(-np.inf)\n",
    "    \n",
    "    conditions_best_model = [ r2_knee_fillna > r2_fixed_fillna, r2_fixed_fillna >= r2_knee_fillna ]\n",
    "    choices_mode_best = ['knee', 'fixed']\n",
    "    df_pivot_foof_params['BestModel_AperiodicMode'] = np.select(conditions_best_model, choices_mode_best, default='n/a')\n",
    "\n",
    "    for mode in ['Fixed', 'Knee']:\n",
    "        for param in ['Offset', 'Exponent', 'Knee', 'R2', 'Error', 'Num_Peaks']:\n",
    "            col_name = f\"{param}_{mode}\"\n",
    "            if col_name not in df_pivot_foof_params:\n",
    "                df_pivot_foof_params[col_name] = np.nan\n",
    "    \n",
    "    df_pivot_foof_params['Offset_BestModel'] = np.where(df_pivot_foof_params['BestModel_AperiodicMode'] == 'knee', df_pivot_foof_params['Offset_Knee'], df_pivot_foof_params['Offset_Fixed'])\n",
    "    df_pivot_foof_params['Exponent_BestModel'] = np.where(df_pivot_foof_params['BestModel_AperiodicMode'] == 'knee', df_pivot_foof_params['Exponent_Knee'], df_pivot_foof_params['Exponent_Fixed'])\n",
    "    df_pivot_foof_params['Knee_BestModel'] = np.where(df_pivot_foof_params['BestModel_AperiodicMode'] == 'knee', df_pivot_foof_params['Knee_Knee'], np.nan)\n",
    "    df_pivot_foof_params['R2_BestModel'] = np.where(df_pivot_foof_params['BestModel_AperiodicMode'] == 'knee', df_pivot_foof_params['R2_Knee'], df_pivot_foof_params['R2_Fixed'])\n",
    "    df_pivot_foof_params['Error_BestModel'] = np.where(df_pivot_foof_params['BestModel_AperiodicMode'] == 'knee', df_pivot_foof_params['Error_Knee'], df_pivot_foof_params['Error_Fixed'])\n",
    "    df_pivot_foof_params['Num_Peaks_BestModel'] = np.where(df_pivot_foof_params['BestModel_AperiodicMode'] == 'knee', df_pivot_foof_params['Num_Peaks_Knee'], df_pivot_foof_params['Num_Peaks_Fixed'])\n",
    "else: \n",
    "    print(\"Warning: R2_Fixed or R2_Knee not found in pivoted FOOOF data. Best model columns will be NaN.\")\n",
    "    for col in best_model_param_cols:\n",
    "        df_pivot_foof_params[col] = np.nan\n",
    "df_pivot_foof_params['ErrorMsg_FOOOF'] = '' \n",
    "\n",
    "# --- 3. Merge FOOOF results with original segment info from fooof_input_df ---\n",
    "print(\"Merging pivoted FOOOF results with main segment data (including LEDD, Beta, Gamma)...\")\n",
    "segment_base_cols = [\n",
    "    'Aligned_PKG_UnixTimestamp', 'Channel', \n",
    "    'SessionID', 'Hemisphere', \n",
    "    'Neural_Segment_Start_Unixtime', 'Neural_Segment_End_Unixtime',\n",
    "    'Neural_Segment_Duration_Sec', 'FS', 'PSD_Data_Str', 'Frequency_Vector_Str',\n",
    "    'Aligned_PKG_DateTime_Str', 'Clinical_State_2min_Window', 'Clinical_State_Aggregated',\n",
    "    'Aligned_BK', 'Aligned_DK', 'Aligned_Tremor_Score', 'Aligned_Tremor',\n",
    "    'Total_Daily_LEDD_mg',\n",
    "    'Beta_Peak_Power_at_DominantFreq',\n",
    "    'Gamma_Peak_Power_at_DominantFreq'\n",
    "]\n",
    "segment_base_cols_present = [col for col in segment_base_cols if col in fooof_input_df.columns]\n",
    "df_segment_info_to_merge = fooof_input_df[segment_base_cols_present].drop_duplicates(subset=['Aligned_PKG_UnixTimestamp', 'Channel'])\n",
    "\n",
    "# Ensure merge keys exist and are of correct type in both dataframes\n",
    "if 'Aligned_PKG_UnixTimestamp' not in df_pivot_foof_params.columns:\n",
    "    df_pivot_foof_params['Aligned_PKG_UnixTimestamp'] = np.nan # Add if missing\n",
    "if 'Channel' not in df_pivot_foof_params.columns:\n",
    "    df_pivot_foof_params['Channel'] = np.nan\n",
    "\n",
    "df_pivot_foof_params['Aligned_PKG_UnixTimestamp'] = pd.to_numeric(df_pivot_foof_params['Aligned_PKG_UnixTimestamp'], errors='coerce').astype('Int64')\n",
    "df_segment_info_to_merge['Aligned_PKG_UnixTimestamp'] = pd.to_numeric(df_segment_info_to_merge['Aligned_PKG_UnixTimestamp'], errors='coerce').astype('Int64')\n",
    "df_pivot_foof_params['Channel'] = df_pivot_foof_params['Channel'].astype(str)\n",
    "df_segment_info_to_merge['Channel'] = df_segment_info_to_merge['Channel'].astype(str)\n",
    "\n",
    "\n",
    "master_df_final = pd.merge(\n",
    "    df_pivot_foof_params,\n",
    "    df_segment_info_to_merge,\n",
    "    on=['Aligned_PKG_UnixTimestamp', 'Channel'],\n",
    "    how='left' \n",
    ")\n",
    "\n",
    "if 'ITERATIVE_FREQ_BANDS' in locals() and isinstance(ITERATIVE_FREQ_BANDS, dict):\n",
    "    band_map_low = {k: v[0] for k, v in ITERATIVE_FREQ_BANDS.items()} \n",
    "    band_map_high = {k: v[1] for k, v in ITERATIVE_FREQ_BANDS.items()}\n",
    "    if 'FreqRangeLabel' in master_df_final.columns:\n",
    "        master_df_final['FreqLow'] = master_df_final['FreqRangeLabel'].map(band_map_low)\n",
    "        master_df_final['FreqHigh'] = master_df_final['FreqRangeLabel'].map(band_map_high)\n",
    "    else:\n",
    "        master_df_final['FreqLow'], master_df_final['FreqHigh'] = np.nan, np.nan\n",
    "else:\n",
    "    print(\"Warning: ITERATIVE_FREQ_BANDS not defined or not a dict, FreqLow/High cannot be mapped.\")\n",
    "    master_df_final['FreqLow'], master_df_final['FreqHigh'] = np.nan, np.nan\n",
    "\n",
    "\n",
    "# --- 4. Finalize and Save Master Table ---\n",
    "final_columns_ordered = [col for col in master_table_columns if col in master_df_final.columns]\n",
    "# Add any columns that might be in master_df_final but not in master_table_columns (e.g. if new ones were missed)\n",
    "# or if some columns from master_table_columns were not generated\n",
    "existing_cols_in_master_df = set(master_df_final.columns)\n",
    "final_ordered_and_existing_cols = []\n",
    "for col in master_table_columns:\n",
    "    if col in existing_cols_in_master_df:\n",
    "        final_ordered_and_existing_cols.append(col)\n",
    "    else:\n",
    "        print(f\"Info: Column '{col}' from master_table_columns definition is not in the generated master_df_final. It will be missing.\")\n",
    "\n",
    "# Ensure all columns from master_df_final are included, even if not in master_table_columns initially\n",
    "for col in master_df_final.columns:\n",
    "    if col not in final_ordered_and_existing_cols:\n",
    "        final_ordered_and_existing_cols.append(col) # Add to end\n",
    "\n",
    "master_df_to_save = master_df_final[final_ordered_and_existing_cols].copy()\n",
    "\n",
    "# UserSessionName from Cell 1 (session_id)\n",
    "if 'session_id' in locals() and 'UserSessionName' not in master_df_to_save.columns :\n",
    "    master_df_to_save.insert(0, 'UserSessionName', session_id)\n",
    "\n",
    "if not master_df_to_save.empty:\n",
    "    print(f\"Master DataFrame for {session_id} prepared. Shape: {master_df_to_save.shape}\")\n",
    "    try:\n",
    "        # master_csv_path_patient_specific is defined in Cell 3\n",
    "        master_df_to_save.to_csv(master_csv_path_patient_specific, index=False) \n",
    "        print(f\"Successfully saved master data for {session_id} to: {master_csv_path_patient_specific}\")\n",
    "        print(\"\\nSample of the final Master DataFrame (first 5 rows):\")\n",
    "        print(master_df_to_save.head())\n",
    "    except Exception as e_save_master:\n",
    "        print(f\"ERROR saving the master CSV for {session_id}: {e_save_master}\")\n",
    "else:\n",
    "    print(f\"Warning: Master DataFrame for {session_id} is empty. Nothing to save.\")\n",
    "\n",
    "print(\"\\n--- Cell 8: Master DataFrame Generation Complete (with new metrics and LEDD override prompt) ---\")\n",
    "# --- End of Cell 8 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c284b-1998-4b77-9649-3b5d59e3bb96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fooof_env",
   "language": "python",
   "name": "fooof_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
