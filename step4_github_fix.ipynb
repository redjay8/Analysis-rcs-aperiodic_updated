{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29f43b35-ba44-4cb5-b9e1-a8afc93dd13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 1: All imports and global parameters have been defined.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 1: Centralized Imports and Global Configuration ---\n",
    "\n",
    "# --- Part 1: All Library Imports ---\n",
    "# Python Core Libraries\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime, time\n",
    "\n",
    "# Data Handling & Scientific Computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from scipy.stats import (pearsonr, spearmanr, mannwhitneyu, t, kruskal)\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Statistical Modeling\n",
    "import pingouin as pg\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.graphics.regressionplots import plot_partregress_grid\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Plotting & Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Degrees of freedom <= 0 for slice\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"p-value may not be accurate for N > 5000\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in scalar divide\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Confidence interval might not be reliable for bootstrap samples with fewer than 50 elements.\")\n",
    "\n",
    "# --- Part 3: User Input and Path Configuration ---\n",
    "patient_hemisphere_id = \"COHORT_RCS02_05_06\"  # merged cohort label for outputs\n",
    "\n",
    "project_base_path = \"/home/jackson/step2_final\"\n",
    "step3_output_version_tag = \"neural_pkg_aligned_finalstep3_bushlab5000\" # <<< USER: Ensure this matches Step 3's tag\n",
    "\n",
    "# Derived Paths (no user input needed below this line)\n",
    "step3_master_csv_base_folder = os.path.join(project_base_path, f'step3_fooof_results_{step3_output_version_tag}')\n",
    "master_csv_filename = f\"MASTER_FOOOF_PKG_results_{patient_hemisphere_id}_{step3_output_version_tag}.csv\"\n",
    "master_csv_path_to_load = os.path.join(step3_master_csv_base_folder, master_csv_filename)\n",
    "step4_analysis_root_folder = os.path.join(step3_master_csv_base_folder, 'step4_within_subject')\n",
    "os.makedirs(step4_analysis_root_folder, exist_ok=True)\n",
    "current_datetime_str_step4 = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "session_plot_folder_name_step4 = f\"{patient_hemisphere_id}_plots_{current_datetime_str_step4}\"\n",
    "analysis_session_plot_folder_step4 = os.path.join(step4_analysis_root_folder, session_plot_folder_name_step4)\n",
    "os.makedirs(analysis_session_plot_folder_step4, exist_ok=True)\n",
    "\n",
    "# --- Part 4: Column Name and Metric Definitions ---\n",
    "# Metric Column Dictionaries\n",
    "APERIODIC_METRICS_COLS = {\n",
    "    'Exponent_BestModel': 'Aperiodic Exponent',\n",
    "    'Offset_BestModel': 'Aperiodic Offset',\n",
    "}\n",
    "PKG_METRICS_COLS = {\n",
    "    'Aligned_BK': 'PKG BK Score',\n",
    "    'Aligned_DK': 'PKG DK Score',\n",
    "    'Aligned_Tremor_Score': 'PKG Tremor Score'\n",
    "}\n",
    "OSCILLATORY_METRICS_COLS = {\n",
    "    'Beta_Peak_Power_at_DominantFreq': 'Beta Peak Power',\n",
    "    'Gamma_Peak_Power_at_DominantFreq': 'Gamma Peak Power'\n",
    "}\n",
    "APERIODIC_METRICS_TO_PLOT = ['Exponent_BestModel'] # Used in daily exponent plots\n",
    "\n",
    "# Key Column Names\n",
    "CHANNEL_COL = 'Channel'\n",
    "CHANNEL_DISPLAY_COL = 'Channel_Display'\n",
    "FOOOF_FREQ_BAND_COL = 'FreqRangeLabel'\n",
    "CLINICAL_STATE_COL = 'Clinical_State_2min_Window'\n",
    "CLINICAL_STATE_AGGREGATED_COL = 'Clinical_State_Aggregated'\n",
    "\n",
    "# --- Part 5: Analysis and Plotting Parameters ---\n",
    "# Ordering for Iterations and Plots\n",
    "ORDERED_FREQ_LABELS = [\"LowFreq\", \"MidFreq\", \"WideFreq\"]\n",
    "# Normalized contact labels (works for Contact_*_* and keyX_contact_*_*)\n",
    "CHANNEL_ORDER_LIST = ['Contact_2_0', 'Contact_3_0', 'Contact_3_1', 'Contact_10_8', 'Contact_11_9']  # keep any that exist in data\n",
    "CHANNEL_ORDER_MAP = {lab: i for i, lab in enumerate(CHANNEL_ORDER_LIST)}\n",
    "CHANNEL_GROUP_MAP = {\n",
    "    'STN': ['Contact_2_0', 'Contact_3_0', 'Contact_3_1'],\n",
    "    'M1':  ['Contact_10_8', 'Contact_11_9']\n",
    "}\n",
    "\n",
    "# Statistical Thresholds\n",
    "P_VALUE_THRESHOLD = 0.05\n",
    "MIN_SAMPLES_FOR_CORR = 5\n",
    "MIN_SAMPLES_FOR_GROUP_COMPARISON = 5\n",
    "R2_FILTER_THRESHOLD = 0.5\n",
    "\n",
    "# Clinical State Definitions and Ordering\n",
    "TARGET_CLINICAL_STATES_ORDERED = [\"Immobile\", \"Non-Dyskinetic Mobile\", \"Transitional Mobile\", \"Dyskinetic Mobile\"]\n",
    "ALL_CLINICAL_STATES_ORDERED = [\"Sleep\", \"Immobile\", \"Non-Dyskinetic Mobile\", \"Transitional Mobile\", \"Dyskinetic Mobile\"]\n",
    "SYMPTOM_ORDER = ['PKG BK Score', 'PKG DK Score', 'PKG Tremor Score']\n",
    "SYMPTOM_LEGEND_MAP = {'PKG BK Score': 'Bradykinesia', 'PKG DK Score': 'Dyskinesia'} #, 'PKG Tremor Score': 'Tremor'}\n",
    "SYMPTOM_DISPLAY_ORDER = ['Bradykinesia', 'Dyskinesia']#, 'Tremor']\n",
    "\n",
    "# Daily Plot Parameters\n",
    "SF_TZ = pytz.timezone('America/Los_Angeles')\n",
    "PLOTTING_INTERVAL_MINUTES = 10\n",
    "MIN_POINTS_FOR_CI = 2\n",
    "CONFIDENCE_LEVEL_CI = 0.95\n",
    "GAP_THRESHOLD_BINS = 2\n",
    "\n",
    "# MLR Analysis Toggles\n",
    "ANALYZE_ALL_FREQ_BANDS_GLOBAL = False\n",
    "TARGET_FREQ_BAND_GLOBAL = \"WideFreq\"\n",
    "ANALYZE_ALL_FREQ_BANDS_STATE_SPECIFIC = False\n",
    "TARGET_FREQ_BAND_STATE_SPECIFIC = \"WideFreq\"\n",
    "\n",
    "# --- Part 6: Global Plotting Style Configuration ---\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['figure.titlesize'] = 18\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 600\n",
    "\n",
    "# Color Palettes\n",
    "BASE_COLOR_PALETTE = {\n",
    "    'Exponent_BestModel': 'darkslateblue',\n",
    "    'Offset_BestModel': 'mediumseagreen',\n",
    "    'Beta_Peak_Power_at_DominantFreq': 'goldenrod',\n",
    "    'Gamma_Peak_Power_at_DominantFreq': 'firebrick',\n",
    "    'Aligned_BK': 'steelblue',\n",
    "    'Aligned_DK': 'orangered',\n",
    "    'Aligned_Tremor_Score': 'mediumpurple'\n",
    "}\n",
    "CLINICAL_STATE_COLORS = {\n",
    "    'Immobile': '#40E0D0',              # Turquoise\n",
    "    'Non-Dyskinetic Mobile': '#32CD32', # LimeGreen\n",
    "    'Transitional Mobile': '#FFD700',   # Gold\n",
    "    'Dyskinetic Mobile': '#FF6347',     # Tomato\n",
    "    'Sleep': '#4169E1',                 # RoyalBlue\n",
    "    'Other': '#C0C0C0',                 # Silver\n",
    "    'Mobile (All Types)': 'darkgreen'\n",
    "}\n",
    "PKG_SYMPTOM_COLORS = {\n",
    "    'Aligned_BK': BASE_COLOR_PALETTE.get('Aligned_BK', 'steelblue'),\n",
    "    'Aligned_DK': BASE_COLOR_PALETTE.get('Aligned_DK', 'orangered'),\n",
    "    'Aligned_Tremor_Score': BASE_COLOR_PALETTE.get('Aligned_Tremor_Score', 'mediumpurple')\n",
    "}\n",
    "\n",
    "# Other Plotting Style Constants\n",
    "DOT_ALPHA = 0.5\n",
    "REG_CI_ALPHA = 0.15\n",
    "BOX_FILL_ALPHA = 0.6\n",
    "BOXPLOT_LINE_THICKNESS = 2.25\n",
    "REG_LINE_THICKNESS = 2.0\n",
    "SIGNIFICANT_P_VAL_BG_COLOR = 'khaki'\n",
    "DEFAULT_P_VAL_BG_COLOR = 'ivory'\n",
    "\n",
    "# ==== Global analysis toggles (for region-only outputs, minimal plotting) ====\n",
    "ANALYSIS_LEVEL = 'region'      # 'region' or 'contact'\n",
    "EXCLUDE_MIXED = True           # drop cross-pair bins labeled 'Mixed' when ANALYSIS_LEVEL == 'region'\n",
    "ENABLE_PLOTS = True            # master switch for plotting; set False to skip all plots\n",
    "PLOT_GROUPS = ['STN', 'M1']    # which regions to include in any plots\n",
    "DISABLE_CONTACT_PLOTS = True   # enforce: never generate per-contact plots\n",
    "MIN_SAMPLES_PER_BIN = 2        # 10-min bin must have at least this many rows to be kept\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Cell 1: All imports and global parameters have been defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038abc2-3f26-4f29-aced-01b77e808705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a495aa0-35dc-4435-b1ab-4ec9505351cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /home/jackson\n",
      "project_base_path: /home/jackson/step2_final\n",
      "resolved base: /home/jackson/step2_final\n",
      "tag: neural_pkg_aligned_finalstep3_bushlab5000\n",
      "step3 folder: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000\n",
      "exists? True is_dir? True\n",
      "parent writable? True\n",
      "step3 folder writable? True\n"
     ]
    }
   ],
   "source": [
    "import os, pathlib\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"project_base_path:\", project_base_path)\n",
    "print(\"resolved base:\", pathlib.Path(project_base_path).resolve())\n",
    "\n",
    "print(\"tag:\", step3_output_version_tag)\n",
    "print(\"step3 folder:\", os.path.abspath(step3_master_csv_base_folder))\n",
    "print(\"exists?\", os.path.exists(step3_master_csv_base_folder), \n",
    "      \"is_dir?\", os.path.isdir(step3_master_csv_base_folder))\n",
    "\n",
    "parent = pathlib.Path(step3_master_csv_base_folder).resolve().parent\n",
    "print(\"parent writable?\", os.access(str(parent), os.W_OK))\n",
    "print(\"step3 folder writable?\", os.access(str(pathlib.Path(step3_master_csv_base_folder)), os.W_OK))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5c2fa4-d63e-4b52-bf13-195f0aaf1f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for Patient-Hemisphere ID: COHORT_RCS02_05_06\n",
      "Project base path determined as: /home/jackson/step2_final\n",
      "Attempting to load master data from: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/MASTER_FOOOF_PKG_results_COHORT_RCS02_05_06_neural_pkg_aligned_finalstep3_bushlab5000.csv\n",
      "Step 4 plots will be saved in: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044\n",
      "\n",
      "=== Step 4 Analysis Config ===\n",
      "Analysis level         : region  (region -> STN vs M1; contact -> per-contact)\n",
      "Exclude 'Mixed' bins   : True\n",
      "Min samples per 10-min : 2\n",
      "Enable plotting        : True\n",
      "==============================\n",
      "\n",
      "Step 4 analysis parameters and paths configured for COHORT_RCS02_05_06.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 2: User Input, File Paths, and Analysis Parameter Definitions ---\n",
    "\n",
    "# --- User Input ---\n",
    "# This script processes ONE patient-hemisphere at a time.\n",
    "patient_hemisphere_id = \"COHORT_RCS02_05_06\"  # merged cohort label for outputs\n",
    "\n",
    "print(f\"Processing data for Patient-Hemisphere ID: {patient_hemisphere_id}\")\n",
    "\n",
    "if not patient_hemisphere_id:\n",
    "    raise ValueError(\"Patient-Hemisphere ID cannot be empty.\")\n",
    "\n",
    "# --- Path Configuration ---\n",
    "print(f\"Project base path determined as: {project_base_path}\")\n",
    "print(f\"Attempting to load master data from: {master_csv_path_to_load}\")\n",
    "print(f\"Step 4 plots will be saved in: {analysis_session_plot_folder_step4}\")\n",
    "\n",
    "# Plot styling used downstream (kept here to avoid surprises)\n",
    "DOT_ALPHA_STEP4 = 0.5\n",
    "REG_CI_ALPHA_STEP4 = 0.15\n",
    "BOX_FILL_ALPHA_STEP4 = 0.6\n",
    "REG_LINE_THICKNESS_STEP4 = 2.0\n",
    "\n",
    "# --- Echo core analysis toggles so logs are explicit ---\n",
    "try:\n",
    "    _lvl = ANALYSIS_LEVEL\n",
    "except NameError:\n",
    "    _lvl = 'contact'\n",
    "    print(\"WARNING: ANALYSIS_LEVEL not defined in Cell 1; defaulting to 'contact'.\")\n",
    "\n",
    "try:\n",
    "    _exclude_mixed = EXCLUDE_MIXED\n",
    "except NameError:\n",
    "    _exclude_mixed = False\n",
    "\n",
    "try:\n",
    "    _min_per_bin = MIN_SAMPLES_PER_BIN\n",
    "except NameError:\n",
    "    _min_per_bin = 1\n",
    "\n",
    "try:\n",
    "    _enable_plots = ENABLE_PLOTS\n",
    "except NameError:\n",
    "    _enable_plots = True\n",
    "\n",
    "print(\"\\n=== Step 4 Analysis Config ===\")\n",
    "print(f\"Analysis level         : {_lvl}  (region -> STN vs M1; contact -> per-contact)\")\n",
    "print(f\"Exclude 'Mixed' bins   : {_exclude_mixed}\")\n",
    "print(f\"Min samples per 10-min : {_min_per_bin}\")\n",
    "print(f\"Enable plotting        : {_enable_plots}\")\n",
    "print(\"==============================\\n\")\n",
    "\n",
    "print(f\"Step 4 analysis parameters and paths configured for {patient_hemisphere_id}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c32f9f-b3f7-41c9-991b-ad61c00369f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polars detected: using multi-threaded aggregation.\n",
      "Successfully loaded /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/MASTER_FOOOF_PKG_results_COHORT_RCS02_05_06_neural_pkg_aligned_finalstep3_bushlab5000.csv. Initial shape: (429660, 46)\n",
      "Built 'Channel_Display' from column 'Channel'.\n",
      "Derived ORDERED_CHANNEL_LABELS for plots: ['Contact_2_0', 'Contact_3_0', 'Contact_3_1', 'Contact_10_8', 'Contact_11_9']\n",
      "Dropped rows with NaNs in any of ['Exponent_BestModel', 'Offset_BestModel', 'Aligned_BK', 'Aligned_DK', 'Aligned_Tremor_Score', 'Beta_Peak_Power_at_DominantFreq', 'Gamma_Peak_Power_at_DominantFreq']. Rows 429660 -> 429564.\n",
      "Final master_df (pre-binning) shape: (429564, 47)\n",
      "Step 4.5 complete. 10-min binned shape: (32436, 42)\n",
      "\n",
      "Preview (first 5 rows):\n",
      "  Channel_Display Region FreqRangeLabel Clinical_State_2min_Window  \\\n",
      "0     Contact_2_0    STN        MidFreq                      Other   \n",
      "1    Contact_10_8     M1        LowFreq      Non-Dyskinetic Mobile   \n",
      "2    Contact_10_8     M1        LowFreq                   Immobile   \n",
      "3     Contact_3_1    STN        LowFreq                      Sleep   \n",
      "4     Contact_3_1    STN        LowFreq                   Immobile   \n",
      "\n",
      "             Datetime_10min  Exponent_BestModel  Offset_BestModel  Aligned_BK  \\\n",
      "0 2019-05-17 20:40:00-07:00            2.534877         -2.589243   40.487500   \n",
      "1 2019-10-13 19:00:00-07:00            2.401817         -2.492242   19.270455   \n",
      "2 2019-05-20 23:40:00-07:00            4.797258          2.007333   55.161667   \n",
      "3 2019-10-11 02:50:00-07:00            1.751874         -4.684834   94.294118   \n",
      "4 2019-05-20 16:30:00-07:00            7.482851          5.654461   45.010000   \n",
      "\n",
      "   Aligned_DK  Aligned_Tremor_Score  Beta_Peak_Power_at_DominantFreq  \\\n",
      "0   16.837500                   0.0                        -5.366648   \n",
      "1    1.890909                   0.0                        -4.961255   \n",
      "2    0.000000                   0.0                        -4.431713   \n",
      "3    0.004412                   0.0                        -7.010956   \n",
      "4    0.048333                   0.0                        -4.451549   \n",
      "\n",
      "   Gamma_Peak_Power_at_DominantFreq  Total_Daily_LEDD_mg  \n",
      "0                         -6.876424                  NaN  \n",
      "1                         -6.232628                  NaN  \n",
      "2                         -6.237028                  NaN  \n",
      "3                         -7.525161                  NaN  \n",
      "4                         -6.558173                  NaN  \n",
      "\n",
      "Cell 3: SF-aligned per-contact/state 10-min aggregation complete.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 3: Data Loading and Initial Preprocessing (Stable, fast, SF-aligned bins) ---\n",
    "import traceback\n",
    "\n",
    "# Diagnostics: 'off' | 'fast' | 'full'\n",
    "DIAG_MODE = 'off'\n",
    "\n",
    "# Detect Polars once (module-scope). Do NOT reassign this inside functions.\n",
    "try:\n",
    "    import polars as pl\n",
    "    HAS_POLARS = True\n",
    "    print(\"Polars detected: using multi-threaded aggregation.\")\n",
    "except Exception:\n",
    "    HAS_POLARS = False\n",
    "    print(\"Polars not available: using optimized pandas path.\")\n",
    "\n",
    "def _first_contact_label(s: str):\n",
    "    s = '' if s is None else str(s)\n",
    "    m = re.search(r'(?:^|_)contact_(\\d+)_(\\d+)', s, flags=re.IGNORECASE)\n",
    "    return f\"Contact_{m.group(1)}_{m.group(2)}\" if m else None\n",
    "\n",
    "def _normalize_contact_label(s: str) -> str:\n",
    "    return _first_contact_label(s) or str(s)\n",
    "\n",
    "def _ensure_channel_display(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_out = df_in.copy()\n",
    "    if CHANNEL_DISPLAY_COL in df_out.columns:\n",
    "        df_out[CHANNEL_DISPLAY_COL] = df_out[CHANNEL_DISPLAY_COL].map(_normalize_contact_label)\n",
    "        return df_out\n",
    "\n",
    "    candidate_cols = [\n",
    "        CHANNEL_COL, 'electrode_label', 'electrode', 'ChannelLabel',\n",
    "        'Channel_Name', 'ChannelDisplay'\n",
    "    ]\n",
    "    candidate_cols += [c for c in df_out.columns if 'contact' in c.lower() or 'electrode' in c.lower()]\n",
    "\n",
    "    for c in candidate_cols:\n",
    "        if c in df_out.columns:\n",
    "            tmp = df_out[c].map(_first_contact_label)\n",
    "            if tmp.notna().any():\n",
    "                df_out[CHANNEL_DISPLAY_COL] = tmp.fillna(df_out[c].astype(str))\n",
    "                print(f\"Built '{CHANNEL_DISPLAY_COL}' from column '{c}'.\")\n",
    "                return df_out\n",
    "\n",
    "    for c in [c for c in df_out.columns if df_out[c].dtype == object]:\n",
    "        tmp = df_out[c].map(_first_contact_label)\n",
    "        if tmp.notna().any():\n",
    "            df_out[CHANNEL_DISPLAY_COL] = tmp.fillna(df_out[c].astype(str))\n",
    "            print(f\"Built '{CHANNEL_DISPLAY_COL}' by scanning column '{c}'.\")\n",
    "            return df_out\n",
    "\n",
    "    raise KeyError(\n",
    "        f\"Could not construct '{CHANNEL_DISPLAY_COL}'. \"\n",
    "        f\"None of the columns contained contact_#_# patterns. \"\n",
    "        f\"Please set CHANNEL_COL to the correct source.\"\n",
    "    )\n",
    "\n",
    "def load_and_preprocess_step4_data(file_path, patient_hemisphere_id_val):\n",
    "    \"\"\"Loads Step 3 CSV and returns: (master_df_step4 [10-min per-contact/state bins], ORDERED_CHANNEL_LABELS).\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"ERROR: Master CSV file from Step 3 not found at {file_path}\")\n",
    "        return None, []\n",
    "\n",
    "    try:\n",
    "        # Read ALL columns to keep schema identical to the original (~46 cols)\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded {file_path}. Initial shape: {df.shape}\")\n",
    "\n",
    "        # Ensure Patient ID presence (non-fatal)\n",
    "        if 'SessionID' in df.columns and df['SessionID'].nunique() == 1:\n",
    "            csv_session_id = df['SessionID'].iloc[0]\n",
    "            if csv_session_id != patient_hemisphere_id_val:\n",
    "                print(f\"Warning: SessionID in CSV ({csv_session_id}) != expected ({patient_hemisphere_id_val}). Proceeding.\")\n",
    "        elif 'SessionID' not in df.columns:\n",
    "            df['SessionID'] = patient_hemisphere_id_val\n",
    "\n",
    "        # Build Channel_Display robustly\n",
    "        df = _ensure_channel_display(df)\n",
    "\n",
    "        # Cast numeric metrics\n",
    "        cols_to_numeric = (\n",
    "            list(APERIODIC_METRICS_COLS.keys()) +\n",
    "            list(PKG_METRICS_COLS.keys()) +\n",
    "            list(OSCILLATORY_METRICS_COLS.keys()) +\n",
    "            ['Total_Daily_LEDD_mg', 'R2_BestModel', 'Error_BestModel', 'Num_Peaks_BestModel']\n",
    "        )\n",
    "        for col in cols_to_numeric:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "        # Ensure key categoricals are strings\n",
    "        for col in [CHANNEL_COL, CHANNEL_DISPLAY_COL, FOOOF_FREQ_BAND_COL,\n",
    "                    CLINICAL_STATE_COL, CLINICAL_STATE_AGGREGATED_COL, 'Hemisphere', 'BestModel_AperiodicMode']:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(str)\n",
    "\n",
    "        # Establish ordered channel list (prefer preset; append leftovers)\n",
    "        if CHANNEL_DISPLAY_COL in df.columns:\n",
    "            preferred = CHANNEL_ORDER_LIST\n",
    "            present = list(pd.Index(df[CHANNEL_DISPLAY_COL].dropna().unique()))\n",
    "            ordered_ch = [c for c in preferred if c in present]\n",
    "            leftovers = [c for c in present if c not in ordered_ch]\n",
    "            def _natkey(s): return [int(t) if t.isdigit() else t.lower() for t in re.split('([0-9]+)', str(s))]\n",
    "            ordered_ch.extend(sorted(leftovers, key=_natkey))\n",
    "            ORDERED_CHANNEL_LABELS = ordered_ch\n",
    "            print(f\"Derived ORDERED_CHANNEL_LABELS for plots: {ORDERED_CHANNEL_LABELS}\")\n",
    "        else:\n",
    "            ORDERED_CHANNEL_LABELS = []\n",
    "            print(f\"ERROR: '{CHANNEL_DISPLAY_COL}' not found. ORDERED_CHANNEL_LABELS empty.\")\n",
    "\n",
    "        # Drop rows missing any key analysis metrics\n",
    "        key_metrics_for_analysis = (\n",
    "            list(APERIODIC_METRICS_COLS.keys()) +\n",
    "            list(PKG_METRICS_COLS.keys()) +\n",
    "            list(OSCILLATORY_METRICS_COLS.keys())\n",
    "        )\n",
    "        present_keys = [c for c in key_metrics_for_analysis if c in df.columns]\n",
    "        before = len(df)\n",
    "        if present_keys:\n",
    "            df.dropna(subset=present_keys, how='any', inplace=True)\n",
    "            print(f\"Dropped rows with NaNs in any of {present_keys}. Rows {before} -> {len(df)}.\")\n",
    "        else:\n",
    "            print(\"Warning: No key metrics found to NaN-filter; proceeding.\")\n",
    "\n",
    "        print(f\"Final master_df (pre-binning) shape: {df.shape}\")\n",
    "\n",
    "        # =========================\n",
    "        # 10-min Aggregation (SF wall-clock aligned; Polars or pandas)\n",
    "        # =========================\n",
    "        if 'Aligned_PKG_UnixTimestamp' not in df.columns:\n",
    "            raise KeyError(\"'Aligned_PKG_UnixTimestamp' not found in dataframe\")\n",
    "\n",
    "        # Group keys for independent timelines: per-contact × freq × clinical state\n",
    "        group_keys = [CHANNEL_DISPLAY_COL, FOOOF_FREQ_BAND_COL, CLINICAL_STATE_COL]\n",
    "\n",
    "        # Prefer Polars, but use a local flag so we don't shadow the module constant\n",
    "        use_polars = HAS_POLARS\n",
    "\n",
    "        # Ensure no duplicate column names before any engine conversion\n",
    "        if df.columns.duplicated().any():\n",
    "            df = df.loc[:, ~df.columns.duplicated()].copy()\n",
    "            print(\"Deduplicated pandas columns before aggregation.\")\n",
    "\n",
    "        # Choose categorical passthrough columns you want to keep after aggregation\n",
    "        passthru_cat_cols = [\n",
    "            'SessionID', 'Hemisphere', 'BestModel_AperiodicMode',\n",
    "            CLINICAL_STATE_AGGREGATED_COL\n",
    "        ]\n",
    "        passthru_cat_cols = [c for c in passthru_cat_cols if c in df.columns]\n",
    "\n",
    "        if use_polars:\n",
    "            try:\n",
    "                # Build a minimal frame for Polars with unique columns\n",
    "                num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "                # Remove raw timestamp from numeric aggregation list\n",
    "                for _drop in ['Aligned_PKG_UnixTimestamp']:\n",
    "                    if _drop in num_cols:\n",
    "                        num_cols.remove(_drop)\n",
    "\n",
    "                cols_keep = []\n",
    "                for c in (group_keys + ['Aligned_PKG_UnixTimestamp'] + num_cols):\n",
    "                    if c in df.columns and c not in cols_keep:\n",
    "                        cols_keep.append(c)\n",
    "\n",
    "                # To Polars (no index)\n",
    "                pl_df = pl.from_pandas(df[cols_keep], include_index=False)\n",
    "\n",
    "                # Create SF-local 10-min bin via timezone-aware datetime & truncate\n",
    "                pl_df = pl_df.with_columns(\n",
    "                    pl.from_epoch(pl.col(\"Aligned_PKG_UnixTimestamp\"), time_unit=\"s\")\n",
    "                      .dt.replace_time_zone(\"UTC\")\n",
    "                      .dt.convert_time_zone(\"America/Los_Angeles\")\n",
    "                      .dt.truncate(\"10m\")\n",
    "                      .alias(\"_bin_dt\")\n",
    "                )\n",
    "\n",
    "                # Aggregate: mean of numerics + count\n",
    "                agg_exprs = [pl.col(c).mean().alias(c) for c in num_cols] + [pl.len().alias(\"_count\")]\n",
    "                grouped = (\n",
    "                    pl_df.group_by(group_keys + [\"_bin_dt\"], maintain_order=False)\n",
    "                         .agg(agg_exprs)\n",
    "                         .filter(pl.col(\"_count\") >= MIN_SAMPLES_PER_BIN)\n",
    "                ).to_pandas()\n",
    "\n",
    "                grouped = grouped.rename(columns={\"_bin_dt\": \"Datetime_10min\"})\n",
    "\n",
    "                # ---- carry-through categorical/meta columns via first() per bin ----\n",
    "                if passthru_cat_cols:\n",
    "                    keep_cols_for_cats = []\n",
    "                    for c in (group_keys + ['Aligned_PKG_UnixTimestamp'] + passthru_cat_cols):\n",
    "                        if c in df.columns and c not in keep_cols_for_cats:\n",
    "                            keep_cols_for_cats.append(c)\n",
    "\n",
    "                    pl_cat = pl.from_pandas(df[keep_cols_for_cats], include_index=False).with_columns(\n",
    "                        pl.from_epoch(pl.col(\"Aligned_PKG_UnixTimestamp\"), time_unit=\"s\")\n",
    "                          .dt.replace_time_zone(\"UTC\")\n",
    "                          .dt.convert_time_zone(\"America/Los_Angeles\")\n",
    "                          .dt.truncate(\"10m\")\n",
    "                          .alias(\"_bin_dt\")\n",
    "                    )\n",
    "                    cat_grouped = (\n",
    "                        pl_cat.group_by(group_keys + [\"_bin_dt\"], maintain_order=False)\n",
    "                             .agg([pl.col(c).first().alias(c) for c in passthru_cat_cols])\n",
    "                    ).to_pandas().rename(columns={\"_bin_dt\": \"Datetime_10min\"})\n",
    "\n",
    "                    grouped = grouped.merge(\n",
    "                        cat_grouped,\n",
    "                        on=group_keys + [\"Datetime_10min\"],\n",
    "                        how=\"left\",\n",
    "                        validate=\"one_to_one\"\n",
    "                    )\n",
    "\n",
    "                # Region mapping (vectorized)\n",
    "                _m = grouped[CHANNEL_DISPLAY_COL].str.extract(r'Contact_(\\d+)_(\\d+)', expand=True)\n",
    "                _a = pd.to_numeric(_m[0], errors='coerce')\n",
    "                _b = pd.to_numeric(_m[1], errors='coerce')\n",
    "                grouped['Region'] = np.where((_a <= 3) & (_b <= 3), 'STN',\n",
    "                                      np.where((_a >= 4) & (_b >= 4), 'M1', 'Mixed'))\n",
    "\n",
    "                master_df_step4 = grouped\n",
    "\n",
    "            except Exception as e_polars:\n",
    "                print(f\"Polars path failed ({type(e_polars).__name__}: {e_polars}). Falling back to pandas path...\")\n",
    "                use_polars = False  # local flag only\n",
    "\n",
    "        if not use_polars:\n",
    "            # ---------- PANDAS FAST PATH (same SF-aligned semantics) ----------\n",
    "            # SF-local datetime and floor to 10-minute bins\n",
    "            _dt_sf = (\n",
    "                pd.to_datetime(df['Aligned_PKG_UnixTimestamp'], unit='s', utc=True, errors='coerce')\n",
    "                  .dt.tz_convert(SF_TZ)\n",
    "            )\n",
    "            df['_bin_dt'] = _dt_sf.dt.floor('10T')\n",
    "\n",
    "            num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "            for _drop in ['Aligned_PKG_UnixTimestamp']:\n",
    "                if _drop in num_cols:\n",
    "                    num_cols.remove(_drop)\n",
    "\n",
    "            gb = df.groupby(group_keys + ['_bin_dt'], observed=True, sort=False)\n",
    "            num_mean = gb[num_cols].mean()\n",
    "            counts = gb[num_cols[0]].count().rename('_count') if num_cols else gb.size().rename('_count')\n",
    "            agg_df = num_mean.join(counts)\n",
    "            agg_df = agg_df[agg_df['_count'] >= MIN_SAMPLES_PER_BIN].reset_index()\n",
    "\n",
    "            agg_df = agg_df.rename(columns={'_bin_dt': 'Datetime_10min'})\n",
    "\n",
    "            # ---- carry-through categorical/meta columns via mode/first per bin ----\n",
    "            if passthru_cat_cols:\n",
    "                def _mode_or_first(s):\n",
    "                    m = s.mode(dropna=True)\n",
    "                    if not m.empty:\n",
    "                        return m.iat[0]\n",
    "                    s = s.dropna()\n",
    "                    return s.iloc[0] if not s.empty else np.nan\n",
    "\n",
    "                cats = (\n",
    "                    df.groupby(group_keys + ['_bin_dt'], observed=True, sort=False)[passthru_cat_cols]\n",
    "                      .agg(_mode_or_first)\n",
    "                      .reset_index()\n",
    "                      .rename(columns={'_bin_dt': 'Datetime_10min'})\n",
    "                )\n",
    "                agg_df = agg_df.merge(\n",
    "                    cats,\n",
    "                    on=group_keys + ['Datetime_10min'],\n",
    "                    how='left',\n",
    "                    validate='one_to_one'\n",
    "                )\n",
    "\n",
    "            # Region mapping\n",
    "            _m = agg_df[CHANNEL_DISPLAY_COL].str.extract(r'Contact_(\\d+)_(\\d+)', expand=True)\n",
    "            _a = pd.to_numeric(_m[0], errors='coerce')\n",
    "            _b = pd.to_numeric(_m[1], errors='coerce')\n",
    "            agg_df['Region'] = np.where((_a <= 3) & (_b <= 3), 'STN',\n",
    "                                 np.where((_a >= 4) & (_b >= 4), 'M1', 'Mixed'))\n",
    "\n",
    "            master_df_step4 = agg_df\n",
    "\n",
    "        print(f\"Step 4.5 complete. 10-min binned shape: {master_df_step4.shape}\")\n",
    "\n",
    "        # ------------------------------\n",
    "        # Diagnostics (light & optional)\n",
    "        # ------------------------------\n",
    "        if DIAG_MODE != 'off':\n",
    "            print(\"\\n=== 10-min Aggregation Diagnostics ===\")\n",
    "            try:\n",
    "                print(f\"Raw rows: {len(df):,} | Aggregated rows: {len(master_df_step4):,}\")\n",
    "                raw_t = pd.to_datetime(df['Aligned_PKG_UnixTimestamp'], unit='s', utc=True, errors='coerce').dt.tz_convert(SF_TZ)\n",
    "                agg_t = pd.to_datetime(master_df_step4['Datetime_10min'], errors='coerce')\n",
    "                print(f\"RAW span: {raw_t.min()} -> {raw_t.max()}\")\n",
    "                print(f\"AGG span: {agg_t.min()} -> {agg_t.max()}\")\n",
    "\n",
    "                print(\"\\nPer-contact 10-min bin counts (top 10):\")\n",
    "                print(\n",
    "                    master_df_step4.groupby(CHANNEL_DISPLAY_COL)['Datetime_10min']\n",
    "                        .nunique().sort_values(ascending=False).head(10)\n",
    "                )\n",
    "\n",
    "                if DIAG_MODE == 'full':\n",
    "                    raw_counts = (\n",
    "                        df.assign(_dt=raw_t)\n",
    "                          .groupby([CHANNEL_DISPLAY_COL, FOOOF_FREQ_BAND_COL, CLINICAL_STATE_COL])['_dt'].count()\n",
    "                          .rename('N_raw').reset_index()\n",
    "                    )\n",
    "                    agg_counts = (\n",
    "                        master_df_step4\n",
    "                          .groupby([CHANNEL_DISPLAY_COL, FOOOF_FREQ_BAND_COL, CLINICAL_STATE_COL])['Datetime_10min'].nunique()\n",
    "                          .rename('N_bins_10min').reset_index()\n",
    "                    )\n",
    "                    diag = raw_counts.merge(agg_counts, how='outer')\n",
    "                    diag['N_raw'] = diag['N_raw'].fillna(0).astype(int)\n",
    "                    diag['N_bins_10min'] = diag['N_bins_10min'].fillna(0).astype(int)\n",
    "                    print(\"\\nLowest 10 groups by N_bins_10min:\")\n",
    "                    print(diag.sort_values('N_bins_10min').head(10))\n",
    "            except Exception as _e:\n",
    "                print(\"Diagnostics skipped:\", _e)\n",
    "\n",
    "        # --- Preview a few rows for sanity (cheap) ---\n",
    "        if not master_df_step4.empty:\n",
    "            cols_to_show = [CHANNEL_DISPLAY_COL, 'Region', FOOOF_FREQ_BAND_COL, CLINICAL_STATE_COL, 'Datetime_10min'] \\\n",
    "                           + list(APERIODIC_METRICS_COLS.keys()) \\\n",
    "                           + list(PKG_METRICS_COLS.keys()) \\\n",
    "                           + list(OSCILLATORY_METRICS_COLS.keys()) \\\n",
    "                           + ['Total_Daily_LEDD_mg']\n",
    "            cols_to_show = [c for c in cols_to_show if c in master_df_step4.columns]\n",
    "            print(\"\\nPreview (first 5 rows):\")\n",
    "            print(master_df_step4[cols_to_show].head())\n",
    "        else:\n",
    "            print(\"Warning: Aggregated master_df_step4 is empty.\")\n",
    "\n",
    "        return master_df_step4, ORDERED_CHANNEL_LABELS\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing the CSV file '{file_path}' for Step 4: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "        return None, []\n",
    "\n",
    "# --- Load and Preprocess Data ---\n",
    "master_df_step4, ORDERED_CHANNEL_LABELS = load_and_preprocess_step4_data(master_csv_path_to_load, patient_hemisphere_id)\n",
    "\n",
    "if master_df_step4 is not None and not master_df_step4.empty:\n",
    "    print(\"\\nCell 3: SF-aligned per-contact/state 10-min aggregation complete.\")\n",
    "else:\n",
    "    print(\"Halting Step 4 script as master data could not be loaded or is empty after preprocessing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe6b8a5c-369e-4ab0-a96e-5b893b88dc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 4: Helper functions for Step 4 defined (region-aware, plotting guarded).\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 4: Helper Functions for Step 4 (region-aware, safe for STN vs M1) ---\n",
    "# ---- GLOBAL: exclude tremor everywhere ----\n",
    "EXCLUDE_TREMOR = True\n",
    "TREMOR_LABELS = {'PKG Tremor Score', 'Tremor'}\n",
    "TREMOR_COL_KEYS = {'Aligned_Tremor_Score', 'Aligned_Tremor'}   # any PKG tremor columns in your DF\n",
    "\n",
    "def print_10min_agg_diagnostics(df_raw, df_10, group_keys=(CHANNEL_DISPLAY_COL, FOOOF_FREQ_BAND_COL, CLINICAL_STATE_COL)):\n",
    "    \"\"\"Diagnostics for 10-min binning. Adapts group_keys if ANALYSIS_LEVEL='region'.\"\"\"\n",
    "    if ANALYSIS_LEVEL == 'region':\n",
    "        group_keys = ('Region', FOOOF_FREQ_BAND_COL, CLINICAL_STATE_COL)\n",
    "\n",
    "    print(\"\\n=== 10-min Aggregation Diagnostics ===\")\n",
    "    # Raw counts per group\n",
    "    raw_counts = (\n",
    "        df_raw\n",
    "        .assign(dt=pd.to_datetime(df_raw['Aligned_PKG_UnixTimestamp'], unit='s', utc=True, errors='coerce').dt.tz_convert(SF_TZ))\n",
    "        .dropna(subset=['Aligned_PKG_UnixTimestamp'])\n",
    "        .groupby(list(group_keys))['Aligned_PKG_UnixTimestamp'].count()\n",
    "        .rename('N_raw')\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Aggregated counts per group\n",
    "    if 'Datetime_10min' not in df_10.columns:\n",
    "        raise KeyError(\"Expected 'Datetime_10min' in aggregated dataframe\")\n",
    "    agg_counts = (\n",
    "        df_10\n",
    "        .groupby(list(group_keys))['Datetime_10min'].nunique()\n",
    "        .rename('N_bins_10min')\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    diag = raw_counts.merge(agg_counts, on=list(group_keys), how='outer')\n",
    "    diag['N_raw'] = diag['N_raw'].fillna(0).astype(int)\n",
    "    diag['N_bins_10min'] = diag['N_bins_10min'].fillna(0).astype(int)\n",
    "    diag['approx_cov_pct'] = (diag['N_bins_10min'] / np.maximum(diag['N_raw'] / 20.0, 1)) * 100.0\n",
    "\n",
    "    print(diag.sort_values('approx_cov_pct').head(10))\n",
    "    print(\"\\nLowest coverage groups shown above (good to spot where data go missing).\")\n",
    "\n",
    "    vanished = diag[(diag['N_raw'] > 0) & (diag['N_bins_10min'] == 0)]\n",
    "    if not vanished.empty:\n",
    "        print(\"\\nWARNING: groups with raw data but 0 aggregated bins (likely due to MIN_SAMPLES_PER_BIN):\")\n",
    "        print(vanished.head(20))\n",
    "\n",
    "    print(f\"\\nRaw rows: {len(df_raw):,} | Aggregated rows (10-min bins): {len(df_10):,}\")\n",
    "    for key_name, d in [('RAW', df_raw), ('AGG', df_10)]:\n",
    "        try:\n",
    "            col = 'Datetime_10min' if key_name == 'AGG' else 'Aligned_PKG_UnixTimestamp'\n",
    "            if key_name == 'RAW':\n",
    "                t = pd.to_datetime(d[col], unit='s', utc=True, errors='coerce').dt.tz_convert(SF_TZ)\n",
    "            else:\n",
    "                t = pd.to_datetime(d[col], errors='coerce')\n",
    "            print(f\"{key_name} time span: {t.min()}  ->  {t.max()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{key_name} time span: unavailable ({e})\")\n",
    "\n",
    "\n",
    "def calculate_spearman_with_n(data_df, col1, col2, min_samples=MIN_SAMPLES_FOR_CORR):\n",
    "    \"\"\"Calculates Spearman correlation if N >= min_samples.\"\"\"\n",
    "    pair_data = data_df[[col1, col2]].dropna()\n",
    "    n_points = len(pair_data)\n",
    "    if n_points < min_samples:\n",
    "        return np.nan, np.nan, n_points\n",
    "    try:\n",
    "        rho, p_value = spearmanr(pair_data[col1], pair_data[col2])\n",
    "        if np.isnan(rho):\n",
    "            return np.nan, np.nan, n_points\n",
    "        return rho, p_value, n_points\n",
    "    except ValueError:\n",
    "        return np.nan, np.nan, n_points\n",
    "\n",
    "\n",
    "def calculate_partial_spearman(data_df, x_col, y_col, covar_cols, min_samples=MIN_SAMPLES_FOR_CORR):\n",
    "    \"\"\"Calculates partial Spearman correlation if N >= min_samples.\"\"\"\n",
    "    all_cols_for_partial = [x_col, y_col] + covar_cols\n",
    "    partial_data = data_df[all_cols_for_partial].dropna()\n",
    "    n_points = len(partial_data)\n",
    "    if n_points < min_samples:\n",
    "        return np.nan, np.nan, n_points\n",
    "    try:\n",
    "        if not all(partial_data[col].nunique() > 1 for col in all_cols_for_partial if col in partial_data):\n",
    "            return np.nan, np.nan, n_points\n",
    "        pcorr_result = pg.partial_corr(data=partial_data, x=x_col, y=y_col, covar=covar_cols, method='spearman')\n",
    "        rho = pcorr_result['r'].iloc[0]\n",
    "        p_value = pcorr_result['p-val'].iloc[0]\n",
    "        return rho, p_value, n_points\n",
    "    except Exception:\n",
    "        return np.nan, np.nan, n_points\n",
    "\n",
    "\n",
    "def annotate_correlation_on_plot(ax, rho, p_value, N_val, test_type=\"Spearman ρ\",\n",
    "                                 x_pos=0.97, y_pos=0.97, fontsize=9,\n",
    "                                 sig_threshold=P_VALUE_THRESHOLD):\n",
    "    \"\"\"Annotates correlation statistics on a plot axis. Will auto-skip if ENABLE_PLOTS=False.\"\"\"\n",
    "    if not ENABLE_PLOTS:\n",
    "        return\n",
    "    if pd.isna(rho) or pd.isna(p_value):\n",
    "        stat_text = f\"{test_type}: N/A (N={N_val})\"\n",
    "        bg_color = DEFAULT_P_VAL_BG_COLOR\n",
    "    else:\n",
    "        stars = \"\"\n",
    "        if p_value < 0.001: stars = \"***\"\n",
    "        elif p_value < 0.01: stars = \"**\"\n",
    "        elif p_value < sig_threshold: stars = \"*\"\n",
    "        stat_text = f\"{test_type}={rho:.2f}{stars}\\np={p_value:.3g}\\n(N={N_val})\"\n",
    "        bg_color = SIGNIFICANT_P_VAL_BG_COLOR if p_value < sig_threshold else DEFAULT_P_VAL_BG_COLOR\n",
    "\n",
    "    ax.text(x_pos, y_pos, stat_text, transform=ax.transAxes, fontsize=fontsize,\n",
    "            verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', fc=bg_color, alpha=0.85, edgecolor='darkgrey'))\n",
    "\n",
    "\n",
    "def get_safe_filename_step4(base_name):\n",
    "    \"\"\"Creates a filesystem-safe filename.\"\"\"\n",
    "    return re.sub(r'[^\\w\\s-]', '', str(base_name)).strip().replace(' ', '_').replace('-', '_')\n",
    "\n",
    "\n",
    "def trim_data_for_boxplot_visualization(df_group, value_col):\n",
    "    \"\"\"Trims outliers based on IQR for cleaner boxplot visualization (doesn't affect stats).\"\"\"\n",
    "    if df_group.empty or df_group[value_col].isnull().all() or len(df_group) < 2:\n",
    "        return df_group\n",
    "    Q1 = df_group[value_col].quantile(0.25)\n",
    "    Q3 = df_group[value_col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    if IQR == 0:\n",
    "        return df_group\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df_group[(df_group[value_col] >= lower_bound) & (df_group[value_col] <= upper_bound)]\n",
    "\n",
    "\n",
    "print(\"Cell 4: Helper functions for Step 4 defined (region-aware, plotting guarded).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "882e498b-0341-4a81-bd36-f40089d1efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 5_PREAMBLE: Definitions for state-specific analyses (region-level, 4 motor states) are set.\n",
      "Target clinical states: ['Immobile', 'Non-Dyskinetic Mobile', 'Transitional Mobile', 'Dyskinetic Mobile']\n",
      "Colors for clinical states: {'Immobile': '#40E0D0', 'Non-Dyskinetic Mobile': '#32CD32', 'Transitional Mobile': '#FFD700', 'Dyskinetic Mobile': '#FF6347', 'Sleep': '#4169E1', 'Other': '#C0C0C0', 'Mobile (All Types)': 'darkgreen'}\n",
      "Grouping key: Region, Labels: ['STN', 'M1']\n",
      "State-specific outputs will be saved in: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 5_PREAMBLE: Definitions for State-Specific Analyses (Region-level, Revised Order) ---\n",
    "\n",
    "# --- Define Target Clinical States and their Order (exclude Sleep, keep 4 motor states) ---\n",
    "TARGET_CLINICAL_STATES_ORDERED = [\n",
    "    \"Immobile\",\n",
    "    \"Non-Dyskinetic Mobile\",\n",
    "    \"Transitional Mobile\",\n",
    "    \"Dyskinetic Mobile\"\n",
    "]\n",
    "\n",
    "ORIGINAL_STATES_FOR_ANALYSIS = TARGET_CLINICAL_STATES_ORDERED[:]\n",
    "\n",
    "# No combining needed for this setup\n",
    "STATES_TO_COMBINE_MAPPING = {}\n",
    "NEW_COMBINED_STATE_NAME = None\n",
    "\n",
    "# --- Define Clinical State Colors (using distinct colors, excluding Sleep) ---\n",
    "NEW_CLINICAL_STATE_COLORS_FOR_PLOTTING = {\n",
    "    'Immobile': '#40E0D0',              # Turquoise\n",
    "    'Non-Dyskinetic Mobile': '#32CD32', # LimeGreen\n",
    "    'Transitional Mobile': '#FFD700',   # Gold\n",
    "    'Dyskinetic Mobile': '#FF6347',     # Tomato\n",
    "    # Fallbacks for unexpected states\n",
    "    'Sleep': '#4169E1',                 # RoyalBlue (excluded)\n",
    "    'Other': '#C0C0C0',                 # Silver\n",
    "    'Mobile (All Types)': 'darkgreen'   # For aggregated view if ever used\n",
    "}\n",
    "\n",
    "# --- PKG Symptom Colors (unchanged) ---\n",
    "PKG_SYMPTOM_COLORS = {\n",
    "    'Aligned_BK': BASE_COLOR_PALETTE.get('Aligned_BK', 'steelblue'),\n",
    "    'Aligned_DK': BASE_COLOR_PALETTE.get('Aligned_DK', 'orangered'),\n",
    "    'Aligned_Tremor_Score': BASE_COLOR_PALETTE.get('Aligned_Tremor_Score', 'mediumpurple')\n",
    "}\n",
    "\n",
    "# --- Output Directory for State-Specific Analyses ---\n",
    "STATE_SPECIFIC_ANALYSIS_DIR = os.path.join(analysis_session_plot_folder_step4)\n",
    "os.makedirs(STATE_SPECIFIC_ANALYSIS_DIR, exist_ok=True)\n",
    "\n",
    "# --- Region-level enforcement ---\n",
    "GROUP_KEY_COL = 'Region' if ANALYSIS_LEVEL == 'region' else CHANNEL_DISPLAY_COL\n",
    "ORDERED_GROUP_LABELS = ['STN', 'M1'] if ANALYSIS_LEVEL == 'region' else ORDERED_CHANNEL_LABELS\n",
    "if ANALYSIS_LEVEL == 'region' and EXCLUDE_MIXED:\n",
    "    ORDERED_GROUP_LABELS = [g for g in ORDERED_GROUP_LABELS if g in ['STN', 'M1']]\n",
    "\n",
    "print(\"Cell 5_PREAMBLE: Definitions for state-specific analyses (region-level, 4 motor states) are set.\")\n",
    "print(f\"Target clinical states: {TARGET_CLINICAL_STATES_ORDERED}\")\n",
    "print(f\"Colors for clinical states: {NEW_CLINICAL_STATE_COLORS_FOR_PLOTTING}\")\n",
    "print(f\"Grouping key: {GROUP_KEY_COL}, Labels: {ORDERED_GROUP_LABELS}\")\n",
    "print(f\"State-specific outputs will be saved in: {STATE_SPECIFIC_ANALYSIS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df28e92-33a3-4a24-9544-6334616c6e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 5A (Region-level): Starting State-Specific Correlation Calculations with FDR Correction ---\n",
      "Filtered region-level data for target states. Shape: (24996, 42)\n",
      "\n",
      "Collected 384 tests for FDR correction.\n",
      "FDR correction applied.\n",
      "Saved Bivar_AP_PKG results to /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/Correlation_CSVs_by_State_FDR_Corrected/COHORT_RCS02_05_06_Bivariate_AP_vs_PKG_ByState_FDR_Region.csv\n",
      "Saved Partial_AP_PKG results to /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/Correlation_CSVs_by_State_FDR_Corrected/COHORT_RCS02_05_06_Partial_AP_vs_PKG_ByState_FDR_Region.csv\n",
      "Saved Bivar_AP_Osc results to /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/Correlation_CSVs_by_State_FDR_Corrected/COHORT_RCS02_05_06_Bivariate_AP_vs_Oscillatory_ByState_FDR_Region.csv\n",
      "\n",
      "Sample of FDR-corrected Bivariate AP vs PKG results:\n",
      "       TestType ClinicalState Channel FreqBand             Metric1  \\\n",
      "0  Bivar_AP_PKG      Immobile     STN  LowFreq  Aperiodic Exponent   \n",
      "1  Bivar_AP_PKG      Immobile     STN  LowFreq  Aperiodic Exponent   \n",
      "2  Bivar_AP_PKG      Immobile     STN  LowFreq  Aperiodic Exponent   \n",
      "3  Bivar_AP_PKG      Immobile     STN  LowFreq    Aperiodic Offset   \n",
      "4  Bivar_AP_PKG      Immobile     STN  LowFreq    Aperiodic Offset   \n",
      "\n",
      "            Metric2       Rho  P_Value_Original     N  P_Value_FDR_Adjusted  \\\n",
      "0      PKG BK Score -0.107337      2.373929e-05  1544          7.791356e-05   \n",
      "1      PKG DK Score -0.166027      5.232595e-11  1544          3.348861e-10   \n",
      "2  PKG Tremor Score  0.099061      9.661911e-05  1544          2.832194e-04   \n",
      "3      PKG BK Score -0.112038      1.020805e-05  1544          3.499904e-05   \n",
      "4      PKG DK Score -0.172704      8.368723e-12  1544          6.301156e-11   \n",
      "\n",
      "   Significant_FDR_0.05  \n",
      "0                  True  \n",
      "1                  True  \n",
      "2                  True  \n",
      "3                  True  \n",
      "4                  True  \n",
      "\n",
      "--- Cell 5A (Region-level, FDR Correction) Complete ---\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 5A (Region-level, Revised): State-Specific Correlations with FDR Correction ---\n",
    "# Only STN vs M1 (no per-contact loops). Applies BH FDR across all tests.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "print(\"\\n--- Cell 5A (Region-level): Starting State-Specific Correlation Calculations with FDR Correction ---\")\n",
    "\n",
    "# --- Safety checks ---\n",
    "if 'master_df_step4' not in locals() or master_df_step4.empty:\n",
    "    print(\"CRITICAL ERROR: master_df_step4 not available or empty. Cannot proceed with Cell 5A.\")\n",
    "else:\n",
    "    # Ensure grouping is region-level\n",
    "    df_analysis = master_df_step4.copy()\n",
    "    if EXCLUDE_MIXED and 'Region' in df_analysis.columns:\n",
    "        df_analysis = df_analysis[df_analysis['Region'].isin(['STN', 'M1'])]\n",
    "\n",
    "    # Filter by states of interest\n",
    "    df_analysis = df_analysis[df_analysis[CLINICAL_STATE_COL].isin(TARGET_CLINICAL_STATES_ORDERED)].copy()\n",
    "    if df_analysis.empty:\n",
    "        print(f\"No data found for states {TARGET_CLINICAL_STATES_ORDERED}. Skipping Cell 5A.\")\n",
    "    else:\n",
    "        # Categorical state ordering\n",
    "        df_analysis[CLINICAL_STATE_COL] = pd.Categorical(\n",
    "            df_analysis[CLINICAL_STATE_COL],\n",
    "            categories=TARGET_CLINICAL_STATES_ORDERED,\n",
    "            ordered=True\n",
    "        )\n",
    "\n",
    "        print(f\"Filtered region-level data for target states. Shape: {df_analysis.shape}\")\n",
    "\n",
    "        # Output directory\n",
    "        state_corr_csv_dir = os.path.join(STATE_SPECIFIC_ANALYSIS_DIR, \"Correlation_CSVs_by_State_FDR_Corrected\")\n",
    "        os.makedirs(state_corr_csv_dir, exist_ok=True)\n",
    "\n",
    "        # --- Step 1: Collect all correlation results ---\n",
    "        all_results = []\n",
    "        for state_current in TARGET_CLINICAL_STATES_ORDERED:\n",
    "            df_state = df_analysis[df_analysis[CLINICAL_STATE_COL] == state_current]\n",
    "            if df_state.empty:\n",
    "                continue\n",
    "\n",
    "            for region in ORDERED_GROUP_LABELS:\n",
    "                if region not in df_state['Region'].unique():\n",
    "                    continue\n",
    "                df_region_state = df_state[df_state['Region'] == region]\n",
    "\n",
    "                for freq_label in ORDERED_FREQ_LABELS:\n",
    "                    df_region_freq = df_region_state[df_region_state[FOOOF_FREQ_BAND_COL] == freq_label].copy()\n",
    "                    if df_region_freq.empty:\n",
    "                        continue\n",
    "\n",
    "                    # --- Bivariate Aperiodic vs PKG ---\n",
    "                    for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "                        for pkg_col, pkg_name in PKG_METRICS_COLS.items():\n",
    "                            if ap_col in df_region_freq.columns and pkg_col in df_region_freq.columns:\n",
    "                                rho, p_val, N = calculate_spearman_with_n(df_region_freq, ap_col, pkg_col)\n",
    "                                all_results.append({\n",
    "                                    'TestType': 'Bivar_AP_PKG',\n",
    "                                    'ClinicalState': state_current,\n",
    "                                    'Channel': region,\n",
    "                                    'FreqBand': freq_label,\n",
    "                                    'Metric1': ap_name,\n",
    "                                    'Metric2': pkg_name,\n",
    "                                    'Rho': rho,\n",
    "                                    'P_Value_Original': p_val,\n",
    "                                    'N': N\n",
    "                                })\n",
    "\n",
    "                    # --- Partial Aperiodic vs PKG (controlling for oscillatory) ---\n",
    "                    covars = [c for c in OSCILLATORY_METRICS_COLS.keys() if c in df_region_freq.columns]\n",
    "                    if len(covars) == 2:\n",
    "                        for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "                            for pkg_col, pkg_name in PKG_METRICS_COLS.items():\n",
    "                                if ap_col in df_region_freq.columns and pkg_col in df_region_freq.columns:\n",
    "                                    prho, ppval, Np = calculate_partial_spearman(df_region_freq, ap_col, pkg_col, covars)\n",
    "                                    all_results.append({\n",
    "                                        'TestType': 'Partial_AP_PKG',\n",
    "                                        'ClinicalState': state_current,\n",
    "                                        'Channel': region,\n",
    "                                        'FreqBand': freq_label,\n",
    "                                        'Metric1': ap_name,\n",
    "                                        'Metric2': pkg_name,\n",
    "                                        'Rho': prho,\n",
    "                                        'P_Value_Original': ppval,\n",
    "                                        'N': Np\n",
    "                                    })\n",
    "\n",
    "                    # --- Bivariate Aperiodic vs Oscillatory ---\n",
    "                    for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "                        for osc_col, osc_name in OSCILLATORY_METRICS_COLS.items():\n",
    "                            if ap_col in df_region_freq.columns and osc_col in df_region_freq.columns:\n",
    "                                rho2, p2, N2 = calculate_spearman_with_n(df_region_freq, ap_col, osc_col)\n",
    "                                all_results.append({\n",
    "                                    'TestType': 'Bivar_AP_Osc',\n",
    "                                    'ClinicalState': state_current,\n",
    "                                    'Channel': region,\n",
    "                                    'FreqBand': freq_label,\n",
    "                                    'Metric1': ap_name,\n",
    "                                    'Metric2': osc_name,\n",
    "                                    'Rho': rho2,\n",
    "                                    'P_Value_Original': p2,\n",
    "                                    'N': N2\n",
    "                                })\n",
    "\n",
    "        print(f\"\\nCollected {len(all_results)} tests for FDR correction.\")\n",
    "\n",
    "        # --- Step 2: Apply FDR correction ---\n",
    "        if not all_results:\n",
    "            print(\"No correlation results generated. Skipping FDR.\")\n",
    "        else:\n",
    "            df_all = pd.DataFrame(all_results)\n",
    "            valid_mask = df_all['P_Value_Original'].notna()\n",
    "            if valid_mask.sum() == 0:\n",
    "                df_all['P_Value_FDR_Adjusted'] = np.nan\n",
    "                df_all['Significant_FDR_0.05'] = False\n",
    "            else:\n",
    "                rej, pvals_corr = fdrcorrection(df_all.loc[valid_mask, 'P_Value_Original'], alpha=0.05)\n",
    "                df_all['P_Value_FDR_Adjusted'] = np.nan\n",
    "                df_all.loc[valid_mask, 'P_Value_FDR_Adjusted'] = pvals_corr\n",
    "                df_all['Significant_FDR_0.05'] = df_all['P_Value_FDR_Adjusted'] < 0.05\n",
    "\n",
    "            print(\"FDR correction applied.\")\n",
    "\n",
    "            # --- Step 3: Split and save ---\n",
    "            out_map = {\n",
    "                'Bivar_AP_PKG': (\"Bivariate_AP_vs_PKG\", 'AperiodicMetric', 'PKGMetric', 'SpearmanRho'),\n",
    "                'Partial_AP_PKG': (\"Partial_AP_vs_PKG\", 'AperiodicMetric', 'PKGMetric', 'PartialSpearmanRho_vs_BetaGamma'),\n",
    "                'Bivar_AP_Osc': (\"Bivariate_AP_vs_Oscillatory\", 'AperiodicMetric', 'OscillatoryMetric', 'SpearmanRho')\n",
    "            }\n",
    "\n",
    "            for ttype, (fname, m1, m2, rho_name) in out_map.items():\n",
    "                sub = df_all[df_all['TestType'] == ttype].copy()\n",
    "                if sub.empty:\n",
    "                    continue\n",
    "                sub.rename(columns={'Metric1': m1, 'Metric2': m2, 'Rho': rho_name}, inplace=True)\n",
    "                sub = sub.drop(columns='TestType')\n",
    "                outpath = os.path.join(state_corr_csv_dir, f\"{patient_hemisphere_id}_{fname}_ByState_FDR_Region.csv\")\n",
    "                sub.to_csv(outpath, index=False)\n",
    "                print(f\"Saved {ttype} results to {outpath}\")\n",
    "\n",
    "            print(\"\\nSample of FDR-corrected Bivariate AP vs PKG results:\")\n",
    "            print(df_all[df_all['TestType'] == 'Bivar_AP_PKG'].head())\n",
    "\n",
    "print(\"\\n--- Cell 5A (Region-level, FDR Correction) Complete ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b70c2f-b0dd-4c6e-9b93-eee0dd4cfc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime_for_avg ready. NaT rows: 0\n",
      "\n",
      "5B-prep preview:\n",
      "  Region Channel_Display FreqRangeLabel Clinical_State_2min_Window  \\\n",
      "1     M1    Contact_10_8        LowFreq      Non-Dyskinetic Mobile   \n",
      "2     M1    Contact_10_8        LowFreq                   Immobile   \n",
      "4    STN     Contact_3_1        LowFreq                   Immobile   \n",
      "\n",
      "           datetime_for_avg  Exponent_BestModel  Aligned_BK  Aligned_DK  \\\n",
      "1 2019-10-13 19:00:00-07:00            2.401817   19.270455    1.890909   \n",
      "2 2019-05-20 23:40:00-07:00            4.797258   55.161667    0.000000   \n",
      "4 2019-05-20 16:30:00-07:00            7.482851   45.010000    0.048333   \n",
      "\n",
      "   Aligned_Tremor_Score  \n",
      "1                   0.0  \n",
      "2                   0.0  \n",
      "4                   0.0  \n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 5B-prep: Build datetime_for_avg robustly (Region-level, no plotting here) ---\n",
    "\n",
    "# Start from the aggregated master_df_step4 produced in Cell 3\n",
    "if 'master_df_step4' not in locals() or master_df_step4 is None or master_df_step4.empty:\n",
    "    raise RuntimeError(\"master_df_step4 is not available. Run Cell 3 first.\")\n",
    "\n",
    "# Region-level subset (respect EXCLUDE_MIXED) and keep only target states\n",
    "df_for_5b = master_df_step4.copy()\n",
    "if EXCLUDE_MIXED and 'Region' in df_for_5b.columns:\n",
    "    df_for_5b = df_for_5b[df_for_5b['Region'].isin(['STN', 'M1'])]\n",
    "\n",
    "if CLINICAL_STATE_COL not in df_for_5b.columns:\n",
    "    raise KeyError(f\"'{CLINICAL_STATE_COL}' not found in aggregated dataframe.\")\n",
    "\n",
    "df_for_5b = df_for_5b[df_for_5b[CLINICAL_STATE_COL].isin(TARGET_CLINICAL_STATES_ORDERED)].copy()\n",
    "df_for_5b[CLINICAL_STATE_COL] = pd.Categorical(\n",
    "    df_for_5b[CLINICAL_STATE_COL],\n",
    "    categories=TARGET_CLINICAL_STATES_ORDERED,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Prefer raw seconds if available (rare here), else reuse the 10-min bins from Cell 3\n",
    "if 'Aligned_PKG_UnixTimestamp' in df_for_5b.columns:\n",
    "    # Build SF-local tz-aware timestamps, then floor to 10-min to match bin edges\n",
    "    dt_sf = (\n",
    "        pd.to_datetime(df_for_5b['Aligned_PKG_UnixTimestamp'], unit='s', utc=True, errors='coerce')\n",
    "          .dt.tz_convert(SF_TZ)\n",
    "          .dt.floor('10T')\n",
    "    )\n",
    "    df_for_5b['datetime_for_avg'] = dt_sf\n",
    "elif 'Datetime_10min' in df_for_5b.columns:\n",
    "    # Reuse the existing bins; ensure tz-awareness and SF timezone\n",
    "    dt_any = pd.to_datetime(df_for_5b['Datetime_10min'], errors='coerce')\n",
    "    # If timezone-naive, localize to SF; if UTC or other tz-aware, convert to SF\n",
    "    if dt_any.dt.tz is None:\n",
    "        dt_any = dt_any.dt.tz_localize(SF_TZ)\n",
    "    else:\n",
    "        dt_any = dt_any.dt.tz_convert(SF_TZ)\n",
    "    df_for_5b['datetime_for_avg'] = dt_any\n",
    "else:\n",
    "    raise KeyError(\"Neither 'Aligned_PKG_UnixTimestamp' nor 'Datetime_10min' is present. \"\n",
    "                   \"Cannot construct 'datetime_for_avg'.\")\n",
    "\n",
    "print(\"datetime_for_avg ready. NaT rows:\", df_for_5b['datetime_for_avg'].isna().sum())\n",
    "\n",
    "# Make this the canonical filtered frame for any downstream use (e.g., optional plots or summaries)\n",
    "master_df_step4_filtered_states = df_for_5b\n",
    "\n",
    "# (Optional, fast) sanity: show the earliest 3 rows to confirm tz and columns\n",
    "_preview_cols = [\n",
    "    'Region', CHANNEL_DISPLAY_COL, FOOOF_FREQ_BAND_COL, CLINICAL_STATE_COL,\n",
    "    'datetime_for_avg'\n",
    "] + [c for c in ['Exponent_BestModel','Aligned_BK','Aligned_DK','Aligned_Tremor_Score'] if c in master_df_step4_filtered_states.columns]\n",
    "print(\"\\n5B-prep preview:\")\n",
    "print(master_df_step4_filtered_states[_preview_cols].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef4c3778-f82a-46f0-a3f5-8bb2c959bb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating overview plots for: Aperiodic Exponent vs. PKG BK Score (Region-level)\n",
      "\n",
      "Generating overview plots for: Aperiodic Exponent vs. PKG DK Score (Region-level)\n",
      "\n",
      "Generating overview plots for: Aperiodic Exponent vs. PKG Tremor Score (Region-level)\n",
      "\n",
      "Generating overview plots for: Aperiodic Offset vs. PKG BK Score (Region-level)\n",
      "\n",
      "Generating overview plots for: Aperiodic Offset vs. PKG DK Score (Region-level)\n",
      "\n",
      "Generating overview plots for: Aperiodic Offset vs. PKG Tremor Score (Region-level)\n",
      "\n",
      "Generating overview plots for: Beta Peak Power vs. PKG BK Score (Region-level)\n",
      "\n",
      "Generating overview plots for: Gamma Peak Power vs. PKG DK Score (Region-level)\n",
      "\n",
      "--- Cell 5B (Region-level, Extended with Beta vs BK & Gamma vs DK) Complete ---\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 5B (Region-level, Extended): Overview Scatter Plots ---\n",
    "# Adds Beta vs BK and Gamma vs DK plots (in addition to Aperiodic vs PKG).\n",
    "# Plots STN vs M1 only, one figure per (metric pair, region, freq band).\n",
    "# Scatter points = 10-min averages, regression line = all available points.\n",
    "\n",
    "if not ENABLE_PLOTS:\n",
    "    print(\"ENABLE_PLOTS=False -> skipping Cell 5B entirely.\")\n",
    "elif 'master_df_step4_filtered_states' not in locals() or master_df_step4_filtered_states.empty:\n",
    "    print(\"master_df_step4_filtered_states not available/empty. Skipping Cell 5B.\")\n",
    "elif 'datetime_for_avg' not in master_df_step4_filtered_states.columns:\n",
    "    print(\"ERROR: 'datetime_for_avg' missing. Run 5B-prep first.\")\n",
    "else:\n",
    "    df_plot_src = master_df_step4_filtered_states.copy()\n",
    "    if EXCLUDE_MIXED and 'Region' in df_plot_src.columns:\n",
    "        df_plot_src = df_plot_src[df_plot_src['Region'].isin(['STN', 'M1'])]\n",
    "\n",
    "    plot_subdir = os.path.join(STATE_SPECIFIC_ANALYSIS_DIR, \"Overview_Scatter_AllPairs_Region\")\n",
    "    os.makedirs(plot_subdir, exist_ok=True)\n",
    "\n",
    "    # --- Build pairs to plot ---\n",
    "    # 1. Aperiodic vs PKG (original loop)\n",
    "    pairs_to_plot = []\n",
    "    for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "        for pkg_col, pkg_name in PKG_METRICS_COLS.items():\n",
    "            pairs_to_plot.append((ap_col, ap_name, pkg_col, pkg_name))\n",
    "\n",
    "    # 2. Explicit Beta vs BK\n",
    "    if 'Beta_Peak_Power_at_DominantFreq' in df_plot_src.columns and 'Aligned_BK' in df_plot_src.columns:\n",
    "        pairs_to_plot.append(('Beta_Peak_Power_at_DominantFreq', 'Beta Peak Power',\n",
    "                              'Aligned_BK', 'PKG BK Score'))\n",
    "\n",
    "    # 3. Explicit Gamma vs DK\n",
    "    if 'Gamma_Peak_Power_at_DominantFreq' in df_plot_src.columns and 'Aligned_DK' in df_plot_src.columns:\n",
    "        pairs_to_plot.append(('Gamma_Peak_Power_at_DominantFreq', 'Gamma Peak Power',\n",
    "                              'Aligned_DK', 'PKG DK Score'))\n",
    "\n",
    "    # --- Loop through all pairs ---\n",
    "    for x_col, x_name, y_col, y_name in pairs_to_plot:\n",
    "        if x_col not in df_plot_src.columns or y_col not in df_plot_src.columns:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nGenerating overview plots for: {x_name} vs. {y_name} (Region-level)\")\n",
    "        for region_label in ['STN', 'M1']:\n",
    "            df_region = df_plot_src[df_plot_src['Region'] == region_label]\n",
    "            if df_region.empty:\n",
    "                continue\n",
    "\n",
    "            for freq_label in ORDERED_FREQ_LABELS:\n",
    "                df_rf = df_region[df_region[FOOOF_FREQ_BAND_COL] == freq_label].copy()\n",
    "                if df_rf.empty:\n",
    "                    continue\n",
    "\n",
    "                # Standardize y-axis across states\n",
    "                all_y_vals = []\n",
    "                for state in TARGET_CLINICAL_STATES_ORDERED:\n",
    "                    sub = df_rf[df_rf[CLINICAL_STATE_COL] == state].dropna(subset=[x_col, y_col, 'datetime_for_avg'])\n",
    "                    if not sub.empty and len(sub) >= MIN_SAMPLES_FOR_CORR:\n",
    "                        pts = (sub.set_index('datetime_for_avg')\n",
    "                                 .groupby(pd.Grouper(freq='10T'))[[x_col, y_col]]\n",
    "                                 .mean()\n",
    "                                 .dropna())\n",
    "                        if not pts.empty:\n",
    "                            all_y_vals.extend(pts[x_col].tolist())\n",
    "                y_min, y_max = (np.nan, np.nan)\n",
    "                if len(all_y_vals) > 0:\n",
    "                    _mn, _mx = float(np.nanmin(all_y_vals)), float(np.nanmax(all_y_vals))\n",
    "                    pad = (max(_mx - _mn, 1e-6)) * 0.10\n",
    "                    y_min, y_max = _mn - pad, _mx + pad\n",
    "\n",
    "                # Figure with 4 subplots (states)\n",
    "                fig, axes = plt.subplots(1, len(TARGET_CLINICAL_STATES_ORDERED),\n",
    "                                         figsize=(max(15, 4*len(TARGET_CLINICAL_STATES_ORDERED)), 5.5),\n",
    "                                         sharey=False)\n",
    "                if len(TARGET_CLINICAL_STATES_ORDERED) == 1:\n",
    "                    axes = [axes]\n",
    "                fig.suptitle(f\"{x_name} vs. {y_name}\\nRegion: {region_label} - Freq: {freq_label} - Patient: {patient_hemisphere_id}\",\n",
    "                             fontsize=plt.rcParams['figure.titlesize']*0.85, y=1.05)\n",
    "\n",
    "                any_valid = False\n",
    "                for i, state in enumerate(TARGET_CLINICAL_STATES_ORDERED):\n",
    "                    ax = axes[i]\n",
    "                    sub = df_rf[df_rf[CLINICAL_STATE_COL] == state].dropna(subset=[x_col, y_col, 'datetime_for_avg'])\n",
    "\n",
    "                    if not sub.empty and len(sub) >= MIN_SAMPLES_FOR_CORR:\n",
    "                        any_valid = True\n",
    "                        # 10-min averaged points\n",
    "                        pts = (sub.set_index('datetime_for_avg')\n",
    "                                 .groupby(pd.Grouper(freq='10T'))[[x_col, y_col]]\n",
    "                                 .mean()\n",
    "                                 .dropna())\n",
    "                        if not pts.empty:\n",
    "                            sns.scatterplot(data=pts, x=y_col, y=x_col,\n",
    "                                            color=NEW_CLINICAL_STATE_COLORS_FOR_PLOTTING.get(state, 'grey'),\n",
    "                                            alpha=DOT_ALPHA+0.2, s=40, edgecolor='black', linewidths=0.5, ax=ax, legend=False)\n",
    "                        # Regression\n",
    "                        sns.regplot(data=sub, x=y_col, y=x_col, scatter=False, ax=ax,\n",
    "                                    line_kws={'color': 'black','linewidth':1.5,'alpha':0.6})\n",
    "                        # Annotate rho/p\n",
    "                        rho, p_val, N_val = calculate_spearman_with_n(sub, x_col, y_col)\n",
    "                        annotate_correlation_on_plot(ax, rho, p_val, N_val, fontsize=8)\n",
    "                        if not pd.isna(y_min) and not pd.isna(y_max):\n",
    "                            ax.set_ylim(y_min, y_max)\n",
    "                    else:\n",
    "                        ax.text(0.5,0.5,\"N < min_samples\" if len(sub)<MIN_SAMPLES_FOR_CORR else \"No Data\",\n",
    "                                ha='center',va='center',transform=ax.transAxes,fontsize=9)\n",
    "\n",
    "                    ax.set_title(state, fontsize=plt.rcParams['axes.titlesize']*0.8)\n",
    "                    if i==0: ax.set_ylabel(x_name)\n",
    "                    else:\n",
    "                        ax.set_ylabel(\"\"); ax.set_yticklabels([])\n",
    "                    ax.set_xlabel(y_name if i==len(TARGET_CLINICAL_STATES_ORDERED)//2 else \"\")\n",
    "                    ax.tick_params(axis='x', labelsize=plt.rcParams['xtick.labelsize']*0.9)\n",
    "                    ax.tick_params(axis='y', labelsize=plt.rcParams['ytick.labelsize']*0.9)\n",
    "\n",
    "                if any_valid:\n",
    "                    plt.tight_layout(rect=[0,0.03,1,0.93])\n",
    "                    fname = f\"Overview_{get_safe_filename_step4(x_name)}_vs_{get_safe_filename_step4(y_name)}_{region_label}_{freq_label}.png\"\n",
    "                    plt.savefig(os.path.join(plot_subdir, fname))\n",
    "                plt.close(fig)\n",
    "\n",
    "print(\"\\n--- Cell 5B (Region-level, Extended with Beta vs BK & Gamma vs DK) Complete ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d527b13-d2fd-4c9a-9d2a-2b5f26ba9614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 5 (Region-level, FDR): Starting Correlation Analyses ---\n",
      "\n",
      "Collected 96 p-values for FDR correction.\n",
      "FDR correction applied.\n",
      "Saved: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/COHORT_RCS02_05_06_Bivariate_AP_vs_PKG_byRegion_FDR.csv\n",
      "Saved: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/COHORT_RCS02_05_06_Partial_AP_vs_PKG_byRegion_FDR.csv\n",
      "Saved: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/COHORT_RCS02_05_06_Bivariate_AP_vs_Osc_byRegion_FDR.csv\n",
      "Saved: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/COHORT_RCS02_05_06_Bivariate_Osc_vs_PKG_byRegion_FDR.csv\n",
      "\n",
      "--- Cell 5 (Region-level, FDR): Correlation Analyses Complete ---\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 5 (Region-level, FDR, minimal plots): Bivariate & Partial Correlations ---\n",
    "# Runs tests per Region (STN/M1) and FreqRangeLabel. No contact-level logic.\n",
    "\n",
    "print(\"\\n--- Cell 5 (Region-level, FDR): Starting Correlation Analyses ---\")\n",
    "\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "# ============ Config ============\n",
    "try:\n",
    "    ENABLE_PLOTS\n",
    "except NameError:\n",
    "    ENABLE_PLOTS = False  # default: off unless you turned it on earlier\n",
    "\n",
    "# Exclude Tremor everywhere in Cell 5\n",
    "EXCLUDE_TREMOR = True\n",
    "TREMOR_COL_KEYS = ['Aligned_Tremor', 'Aligned_Tremor_Score', 'PKG Tremor Score']\n",
    "\n",
    "font_scale_factor = 0.6\n",
    "MODIFIED_COLOR_PALETTE = BASE_COLOR_PALETTE.copy()\n",
    "if 'Aligned_Tremor_Score' in MODIFIED_COLOR_PALETTE:\n",
    "    MODIFIED_COLOR_PALETTE['Aligned_Tremor_Score'] = 'green'\n",
    "SIGNIFICANT_P_VAL_BG_COLOR_STEP4 = 'khaki'\n",
    "DEFAULT_P_VAL_BG_COLOR_STEP4 = 'ivory'\n",
    "\n",
    "# ---------- Choose Source DF ----------\n",
    "if 'df_analysis' in globals():\n",
    "    src = df_analysis.copy()   # Region-level frame built in Cell 3\n",
    "else:\n",
    "    src = master_df_step4.copy()\n",
    "\n",
    "if src is None or src.empty:\n",
    "    print(\"No data available for Cell 5. Skipping.\")\n",
    "else:\n",
    "    # Keep only STN/M1 rows if Region exists\n",
    "    if 'Region' in src.columns:\n",
    "        src = src[src['Region'].isin(['STN', 'M1'])].copy()\n",
    "\n",
    "    # Drop tremor columns from the working DF (so we never accidentally use them)\n",
    "    if EXCLUDE_TREMOR:\n",
    "        src = src.drop(columns=[c for c in TREMOR_COL_KEYS if c in src.columns], errors='ignore')\n",
    "\n",
    "    # Ensure we have frequency band column\n",
    "    if FOOOF_FREQ_BAND_COL not in src.columns:\n",
    "        print(f\"Missing '{FOOOF_FREQ_BAND_COL}'. Skipping Cell 5.\")\n",
    "    else:\n",
    "        # --- Build per-row datetime key for optional 10-min averaging in plots ---\n",
    "        if 'Aligned_PKG_UnixTimestamp' in src.columns:\n",
    "            src['datetime_for_avg_c5'] = (\n",
    "                pd.to_datetime(src['Aligned_PKG_UnixTimestamp'], unit='s', utc=True, errors='coerce')\n",
    "                  .dt.tz_convert(SF_TZ)\n",
    "            ).dt.floor('10T')\n",
    "        elif 'Datetime_10min' in src.columns:\n",
    "            dt_tmp = pd.to_datetime(src['Datetime_10min'], errors='coerce', utc=True)\n",
    "            src['datetime_for_avg_c5'] = dt_tmp.dt.tz_convert(SF_TZ)\n",
    "        else:\n",
    "            src['datetime_for_avg_c5'] = pd.NaT  # plotting will fall back to granular\n",
    "\n",
    "        # ---- Containers ----\n",
    "        all_bivar_ap_pkg = []\n",
    "        all_partial_ap_pkg = []\n",
    "        all_bivar_ap_osc = []\n",
    "        all_bivar_osc_pkg = []  # NEW: Beta/Gamma vs BK/DK\n",
    "\n",
    "        all_pvals = []\n",
    "        pmap = []  # (family, idx)\n",
    "\n",
    "        # Helper: append p-val tracking\n",
    "        def _push_p(val, family, idx):\n",
    "            if not pd.isna(val):\n",
    "                all_pvals.append(val)\n",
    "                pmap.append((family, idx))\n",
    "\n",
    "        # Build PKG metric mapping, optionally excluding tremor\n",
    "        pkg_map = {k: v for k, v in PKG_METRICS_COLS.items()}\n",
    "        if EXCLUDE_TREMOR:\n",
    "            pkg_map = {k: v for k, v in pkg_map.items() if 'Tremor' not in v}\n",
    "\n",
    "        # Identify osc columns for convenience\n",
    "        beta_key = None\n",
    "        gamma_key = None\n",
    "        for k, v in OSCILLATORY_METRICS_COLS.items():\n",
    "            if 'Beta' in v and k in src.columns:  beta_key = k\n",
    "            if 'Gamma' in v and k in src.columns: gamma_key = k\n",
    "\n",
    "        # ===== Iterate Region × Freq =====\n",
    "        regions = ['STN', 'M1'] if 'Region' in src.columns else [None]\n",
    "        for region in regions:\n",
    "            df_region = src if region is None else src[src['Region'] == region]\n",
    "            if df_region.empty:\n",
    "                continue\n",
    "\n",
    "            for freq in ORDERED_FREQ_LABELS:\n",
    "                df_rf = df_region[df_region[FOOOF_FREQ_BAND_COL] == freq].copy()\n",
    "                if df_rf.empty:\n",
    "                    continue\n",
    "\n",
    "                # --- Family 1: Bivariate (Aperiodic vs PKG) ---\n",
    "                for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "                    if ap_col not in df_rf.columns: \n",
    "                        continue\n",
    "                    for pkg_col, pkg_name in pkg_map.items():\n",
    "                        if pkg_col not in df_rf.columns: \n",
    "                            continue\n",
    "                        df_pair = df_rf[[ap_col, pkg_col]].dropna()\n",
    "                        rho, pval, N = calculate_spearman_with_n(df_pair, ap_col, pkg_col)\n",
    "                        all_bivar_ap_pkg.append({\n",
    "                            'Region': region if region is not None else 'All',\n",
    "                            'FreqBand': freq,\n",
    "                            'AperiodicMetric': ap_name,\n",
    "                            'PKGMetric': pkg_name,\n",
    "                            'SpearmanRho': rho,\n",
    "                            'PValue': pval,\n",
    "                            'N': N,\n",
    "                            'TestType': 'Bivariate_AP_PKG'\n",
    "                        })\n",
    "                        _push_p(pval, 'bivar_ap_pkg', len(all_bivar_ap_pkg) - 1)\n",
    "\n",
    "                # --- Family 2: Partial (Aperiodic vs PKG | Beta, Gamma) ---\n",
    "                covars = [c for c in OSCILLATORY_METRICS_COLS.keys() if c in df_rf.columns]\n",
    "                if len(covars) == 2:\n",
    "                    for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "                        if ap_col not in df_rf.columns: \n",
    "                            continue\n",
    "                        for pkg_col, pkg_name in pkg_map.items():\n",
    "                            if pkg_col not in df_rf.columns: \n",
    "                                continue\n",
    "                            cols = [ap_col, pkg_col] + covars\n",
    "                            df_sub = df_rf[cols].dropna()\n",
    "                            if len(df_sub) < MIN_SAMPLES_FOR_CORR or not all(df_sub[c].nunique() > 1 for c in [ap_col, pkg_col]):\n",
    "                                prho, ppval, Np = (np.nan, np.nan, len(df_sub))\n",
    "                            else:\n",
    "                                prho, ppval, Np = calculate_partial_spearman(df_sub, ap_col, pkg_col, covars)\n",
    "                            all_partial_ap_pkg.append({\n",
    "                                'Region': region if region is not None else 'All',\n",
    "                                'FreqBand': freq,\n",
    "                                'AperiodicMetric': ap_name,\n",
    "                                'PKGMetric': pkg_name,\n",
    "                                'PartialSpearmanRho_vs_BetaGamma': prho,\n",
    "                                'PartialPValue': ppval,\n",
    "                                'N_Partial': Np,\n",
    "                                'TestType': 'Partial_AP_PKG'\n",
    "                            })\n",
    "                            _push_p(ppval, 'partial_ap_pkg', len(all_partial_ap_pkg) - 1)\n",
    "\n",
    "                # --- Family 3: Bivariate (Aperiodic vs Oscillatory) ---\n",
    "                for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "                    if ap_col not in df_rf.columns:\n",
    "                        continue\n",
    "                    for osc_col, osc_name in OSCILLATORY_METRICS_COLS.items():\n",
    "                        if osc_col not in df_rf.columns:\n",
    "                            continue\n",
    "                        df_pair = df_rf[[ap_col, osc_col]].dropna()\n",
    "                        rho, pval, N = calculate_spearman_with_n(df_pair, ap_col, osc_col)\n",
    "                        all_bivar_ap_osc.append({\n",
    "                            'Region': region if region is not None else 'All',\n",
    "                            'FreqBand': freq,\n",
    "                            'AperiodicMetric': ap_name,\n",
    "                            'OscillatoryMetric': osc_name,\n",
    "                            'SpearmanRho': rho,\n",
    "                            'PValue': pval,\n",
    "                            'N': N,\n",
    "                            'TestType': 'Bivariate_AP_Osc'\n",
    "                        })\n",
    "                        _push_p(pval, 'bivar_ap_osc', len(all_bivar_ap_osc) - 1)\n",
    "\n",
    "                # --- Family 4 (NEW): Bivariate (Oscillatory vs PKG) → Beta/Gamma vs BK/DK ---\n",
    "                for pkg_col, pkg_name in pkg_map.items():\n",
    "                    if pkg_col not in df_rf.columns:\n",
    "                        continue\n",
    "                    for osc_col, osc_name in [(beta_key, 'Beta_Peak_Power_at_DominantFreq'),\n",
    "                                              (gamma_key, 'Gamma_Peak_Power_at_DominantFreq')]:\n",
    "                        if osc_col is None or osc_col not in df_rf.columns:\n",
    "                            continue\n",
    "                        df_pair = df_rf[[osc_col, pkg_col]].dropna()\n",
    "                        rho, pval, N = calculate_spearman_with_n(df_pair, osc_col, pkg_col)\n",
    "                        all_bivar_osc_pkg.append({\n",
    "                            'Region': region if region is not None else 'All',\n",
    "                            'FreqBand': freq,\n",
    "                            'OscillatoryMetric': OSCILLATORY_METRICS_COLS.get(osc_col, osc_name),\n",
    "                            'PKGMetric': pkg_name,\n",
    "                            'SpearmanRho': rho,\n",
    "                            'PValue': pval,\n",
    "                            'N': N,\n",
    "                            'TestType': 'Bivariate_Osc_PKG'\n",
    "                        })\n",
    "                        _push_p(pval, 'bivar_osc_pkg', len(all_bivar_osc_pkg) - 1)\n",
    "\n",
    "        # ===== FDR across all tests =====\n",
    "        print(f\"\\nCollected {len(all_pvals)} p-values for FDR correction.\")\n",
    "        if all_pvals:\n",
    "            rejected, pvals_corr = fdrcorrection(all_pvals, alpha=0.05, method='indep', is_sorted=False)\n",
    "            for i, (fam, idx) in enumerate(pmap):\n",
    "                if fam == 'bivar_ap_pkg':\n",
    "                    all_bivar_ap_pkg[idx]['PValue_FDR'] = pvals_corr[i]\n",
    "                    all_bivar_ap_pkg[idx]['Significant_FDR'] = bool(rejected[i])\n",
    "                elif fam == 'partial_ap_pkg':\n",
    "                    all_partial_ap_pkg[idx]['PartialPValue_FDR'] = pvals_corr[i]\n",
    "                    all_partial_ap_pkg[idx]['Significant_FDR'] = bool(rejected[i])\n",
    "                elif fam == 'bivar_ap_osc':\n",
    "                    all_bivar_ap_osc[idx]['PValue_FDR'] = pvals_corr[i]\n",
    "                    all_bivar_ap_osc[idx]['Significant_FDR'] = bool(rejected[i])\n",
    "                elif fam == 'bivar_osc_pkg':\n",
    "                    all_bivar_osc_pkg[idx]['PValue_FDR'] = pvals_corr[i]\n",
    "                    all_bivar_osc_pkg[idx]['Significant_FDR'] = bool(rejected[i])\n",
    "            print(\"FDR correction applied.\")\n",
    "        else:\n",
    "            print(\"No valid p-values to correct.\")\n",
    "\n",
    "        # ===== Save CSVs =====\n",
    "        out_dir = analysis_session_plot_folder_step4\n",
    "        if all_bivar_ap_pkg:\n",
    "            df_bivar_ap_pkg = pd.DataFrame(all_bivar_ap_pkg)\n",
    "            df_bivar_ap_pkg.to_csv(os.path.join(out_dir, f\"{patient_hemisphere_id}_Bivariate_AP_vs_PKG_byRegion_FDR.csv\"), index=False)\n",
    "            print(\"Saved:\", os.path.join(out_dir, f\"{patient_hemisphere_id}_Bivariate_AP_vs_PKG_byRegion_FDR.csv\"))\n",
    "        else:\n",
    "            df_bivar_ap_pkg = pd.DataFrame()\n",
    "\n",
    "        if all_partial_ap_pkg:\n",
    "            df_partial_ap_pkg = pd.DataFrame(all_partial_ap_pkg)\n",
    "            df_partial_ap_pkg.to_csv(os.path.join(out_dir, f\"{patient_hemisphere_id}_Partial_AP_vs_PKG_byRegion_FDR.csv\"), index=False)\n",
    "            print(\"Saved:\", os.path.join(out_dir, f\"{patient_hemisphere_id}_Partial_AP_vs_PKG_byRegion_FDR.csv\"))\n",
    "        else:\n",
    "            df_partial_ap_pkg = pd.DataFrame()\n",
    "\n",
    "        if all_bivar_ap_osc:\n",
    "            df_bivar_ap_osc = pd.DataFrame(all_bivar_ap_osc)\n",
    "            df_bivar_ap_osc.to_csv(os.path.join(out_dir, f\"{patient_hemisphere_id}_Bivariate_AP_vs_Osc_byRegion_FDR.csv\"), index=False)\n",
    "            print(\"Saved:\", os.path.join(out_dir, f\"{patient_hemisphere_id}_Bivariate_AP_vs_Osc_byRegion_FDR.csv\"))\n",
    "        else:\n",
    "            df_bivar_ap_osc = pd.DataFrame()\n",
    "\n",
    "        if all_bivar_osc_pkg:\n",
    "            df_bivar_osc_pkg = pd.DataFrame(all_bivar_osc_pkg)\n",
    "            df_bivar_osc_pkg.to_csv(os.path.join(out_dir, f\"{patient_hemisphere_id}_Bivariate_Osc_vs_PKG_byRegion_FDR.csv\"), index=False)\n",
    "            print(\"Saved:\", os.path.join(out_dir, f\"{patient_hemisphere_id}_Bivariate_Osc_vs_PKG_byRegion_FDR.csv\"))\n",
    "        else:\n",
    "            df_bivar_osc_pkg = pd.DataFrame()\n",
    "\n",
    "        # ===== Minimal plotting (only if enabled) =====\n",
    "        if ENABLE_PLOTS:\n",
    "            # AP vs PKG (FDR-significant only)\n",
    "            plot_dir_ap_pkg = os.path.join(out_dir, \"Region_Bivar_AP_vs_PKG_FDRsig\")\n",
    "            os.makedirs(plot_dir_ap_pkg, exist_ok=True)\n",
    "\n",
    "            for r in all_bivar_ap_pkg:\n",
    "                if r.get('Significant_FDR', False) and r['N'] >= MIN_SAMPLES_FOR_CORR:\n",
    "                    region = r['Region']; freq = r['FreqBand']\n",
    "                    ap_name = r['AperiodicMetric']; pkg_name = r['PKGMetric']\n",
    "                    ap_col = [k for k, v in APERIODIC_METRICS_COLS.items() if v == ap_name][0]\n",
    "                    pkg_col = [k for k, v in pkg_map.items() if v == pkg_name][0]\n",
    "\n",
    "                    dfp = src.copy()\n",
    "                    if 'Region' in dfp.columns:\n",
    "                        dfp = dfp[dfp['Region'] == region]\n",
    "                    dfp = dfp[dfp[FOOOF_FREQ_BAND_COL] == freq].dropna(subset=[ap_col, pkg_col])\n",
    "                    if dfp.empty: \n",
    "                        continue\n",
    "\n",
    "                    plt.figure(figsize=(6,6))\n",
    "                    ax = plt.gca(); ax.grid(False)\n",
    "\n",
    "                    if 'datetime_for_avg_c5' in dfp.columns and not dfp['datetime_for_avg_c5'].isnull().all():\n",
    "                        try:\n",
    "                            pts = (dfp.set_index('datetime_for_avg_c5')\n",
    "                                      .groupby(pd.Grouper(freq='10T'))[[ap_col, pkg_col]]\n",
    "                                      .mean().dropna())\n",
    "                        except Exception:\n",
    "                            pts = dfp.copy()\n",
    "                    else:\n",
    "                        pts = dfp.copy()\n",
    "\n",
    "                    if not pts.empty:\n",
    "                        sns.scatterplot(data=pts, x=pkg_col, y=ap_col,\n",
    "                                        alpha=DOT_ALPHA+0.1, s=40, edgecolor='k', linewidths=0.5, ax=ax)\n",
    "                    sns.regplot(data=dfp, x=pkg_col, y=ap_col, scatter=False, ax=ax,\n",
    "                                line_kws={'color': 'black', 'linewidth': REG_LINE_THICKNESS_STEP4, 'alpha': 0.7})\n",
    "\n",
    "                    annotate_correlation_on_plot(ax, r['SpearmanRho'], r.get('PValue_FDR', np.nan), r['N'],\n",
    "                                                 test_type=\"Spearman ρ (FDR)\", fontsize=9*font_scale_factor)\n",
    "                    ax.set_xlabel(pkg_name.replace('PKG ', ''))\n",
    "                    ax.set_ylabel(ap_name.replace('Aperiodic ', ''))\n",
    "                    ax.tick_params(axis='both', which='major', labelsize=plt.rcParams['xtick.labelsize']*font_scale_factor)\n",
    "\n",
    "                    fname = f\"Bivar_{get_safe_filename_step4(ap_name)}_vs_{get_safe_filename_step4(pkg_name)}_{region}_{freq}_FDRsig.png\"\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(os.path.join(plot_dir_ap_pkg, fname))\n",
    "                    plt.close()\n",
    "\n",
    "            # NEW: Osc (Beta/Gamma) vs PKG (FDR-significant only)\n",
    "            plot_dir_osc_pkg = os.path.join(out_dir, \"Region_Bivar_Osc_vs_PKG_FDRsig\")\n",
    "            os.makedirs(plot_dir_osc_pkg, exist_ok=True)\n",
    "\n",
    "            for r in all_bivar_osc_pkg:\n",
    "                if r.get('Significant_FDR', False) and r['N'] >= MIN_SAMPLES_FOR_CORR:\n",
    "                    region = r['Region']; freq = r['FreqBand']\n",
    "                    osc_name = r['OscillatoryMetric']; pkg_name = r['PKGMetric']\n",
    "                    osc_col = [k for k, v in OSCILLATORY_METRICS_COLS.items() if v == osc_name][0]\n",
    "                    pkg_col = [k for k, v in pkg_map.items() if v == pkg_name][0]\n",
    "\n",
    "                    dfp = src.copy()\n",
    "                    if 'Region' in dfp.columns:\n",
    "                        dfp = dfp[dfp['Region'] == region]\n",
    "                    dfp = dfp[dfp[FOOOF_FREQ_BAND_COL] == freq].dropna(subset=[osc_col, pkg_col])\n",
    "                    if dfp.empty:\n",
    "                        continue\n",
    "\n",
    "                    plt.figure(figsize=(6,6))\n",
    "                    ax = plt.gca(); ax.grid(False)\n",
    "\n",
    "                    if 'datetime_for_avg_c5' in dfp.columns and not dfp['datetime_for_avg_c5'].isnull().all():\n",
    "                        try:\n",
    "                            pts = (dfp.set_index('datetime_for_avg_c5')\n",
    "                                      .groupby(pd.Grouper(freq='10T'))[[osc_col, pkg_col]]\n",
    "                                      .mean().dropna())\n",
    "                        except Exception:\n",
    "                            pts = dfp.copy()\n",
    "                    else:\n",
    "                        pts = dfp.copy()\n",
    "\n",
    "                    if not pts.empty:\n",
    "                        sns.scatterplot(data=pts, x=pkg_col, y=osc_col,\n",
    "                                        alpha=DOT_ALPHA+0.1, s=40, edgecolor='k', linewidths=0.5, ax=ax)\n",
    "                    sns.regplot(data=dfp, x=pkg_col, y=osc_col, scatter=False, ax=ax,\n",
    "                                line_kws={'color': 'black', 'linewidth': REG_LINE_THICKNESS_STEP4, 'alpha': 0.7})\n",
    "\n",
    "                    annotate_correlation_on_plot(ax, r['SpearmanRho'], r.get('PValue_FDR', np.nan), r['N'],\n",
    "                                                 test_type=\"Spearman ρ (FDR)\", fontsize=9*font_scale_factor)\n",
    "                    ax.set_xlabel(pkg_name.replace('PKG ', ''))\n",
    "                    ax.set_ylabel(osc_name.replace(' at DominantFreq', ''))\n",
    "                    ax.tick_params(axis='both', which='major', labelsize=plt.rcParams['xtick.labelsize']*font_scale_factor)\n",
    "\n",
    "                    fname = f\"Bivar_{get_safe_filename_step4(osc_name)}_vs_{get_safe_filename_step4(pkg_name)}_{region}_{freq}_FDRsig.png\"\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(os.path.join(plot_dir_osc_pkg, fname))\n",
    "                    plt.close()\n",
    "\n",
    "            # AP vs Osc (FDR-significant only) — unchanged\n",
    "            plot_dir_ap_osc = os.path.join(out_dir, \"Region_Bivar_AP_vs_Osc_FDRsig\")\n",
    "            os.makedirs(plot_dir_ap_osc, exist_ok=True)\n",
    "\n",
    "            for r in all_bivar_ap_osc:\n",
    "                if r.get('Significant_FDR', False) and r['N'] >= MIN_SAMPLES_FOR_CORR:\n",
    "                    region = r['Region']; freq = r['FreqBand']\n",
    "                    ap_name = r['AperiodicMetric']; osc_name = r['OscillatoryMetric']\n",
    "                    ap_col = [k for k, v in APERIODIC_METRICS_COLS.items() if v == ap_name][0]\n",
    "                    osc_col = [k for k, v in OSCILLATORY_METRICS_COLS.items() if v == osc_name][0]\n",
    "\n",
    "                    dfp = src.copy()\n",
    "                    if 'Region' in dfp.columns:\n",
    "                        dfp = dfp[dfp['Region'] == region]\n",
    "                    dfp = dfp[dfp[FOOOF_FREQ_BAND_COL] == freq].dropna(subset=[ap_col, osc_col])\n",
    "                    if dfp.empty:\n",
    "                        continue\n",
    "\n",
    "                    plt.figure(figsize=(6,6))\n",
    "                    ax = plt.gca(); ax.grid(False)\n",
    "\n",
    "                    if 'datetime_for_avg_c5' in dfp.columns and not dfp['datetime_for_avg_c5'].isnull().all():\n",
    "                        try:\n",
    "                            pts = (dfp.set_index('datetime_for_avg_c5')\n",
    "                                      .groupby(pd.Grouper(freq='10T'))[[ap_col, osc_col]]\n",
    "                                      .mean().dropna())\n",
    "                        except Exception:\n",
    "                            pts = dfp.copy()\n",
    "                    else:\n",
    "                        pts = dfp.copy()\n",
    "\n",
    "                    if not pts.empty:\n",
    "                        sns.scatterplot(data=pts, x=osc_col, y=ap_col,\n",
    "                                        alpha=DOT_ALPHA+0.1, s=40, edgecolor='k', linewidths=0.5, ax=ax)\n",
    "                    sns.regplot(data=dfp, x=osc_col, y=ap_col, scatter=False, ax=ax,\n",
    "                                line_kws={'color': 'black', 'linewidth': REG_LINE_THICKNESS_STEP4, 'alpha': 0.7})\n",
    "\n",
    "                    annotate_correlation_on_plot(ax, r['SpearmanRho'], r.get('PValue_FDR', np.nan), r['N'],\n",
    "                                                 test_type=\"Spearman ρ (FDR)\", fontsize=9*font_scale_factor)\n",
    "                    ax.set_xlabel(osc_name.replace(' at DominantFreq', ''))\n",
    "                    ax.set_ylabel(ap_name.replace('Aperiodic ', ''))\n",
    "                    ax.tick_params(axis='both', which='major', labelsize=plt.rcParams['xtick.labelsize']*font_scale_factor)\n",
    "\n",
    "                    fname = f\"Bivar_{get_safe_filename_step4(ap_name)}_vs_{get_safe_filename_step4(osc_name)}_{region}_{freq}_FDRsig.png\"\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(os.path.join(plot_dir_ap_osc, fname))\n",
    "                    plt.close()\n",
    "\n",
    "print(\"\\n--- Cell 5 (Region-level, FDR): Correlation Analyses Complete ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74691efc-4f96-42ce-a155-9d299bad954b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 6 (Region-level, Streamlined V4 with LRT): Starting Analyses ---\n",
      "\n",
      "p-value threshold is 0.05.\n",
      "--- Analyzing ONLY Freq Band: WideFreq ---\n",
      "\n",
      "Saved LRT results: COHORT_RCS02_05_06_MLR_LRT_Results_byRegion_Step6.csv\n",
      "  Region  FreqBand    PKG_Symptom_DV                   Comparison  \\\n",
      "0    STN  WideFreq      PKG BK Score  Exponent + Osc vs. Osc Only   \n",
      "1    STN  WideFreq      PKG BK Score    Offset + Osc vs. Osc Only   \n",
      "2    STN  WideFreq      PKG DK Score  Exponent + Osc vs. Osc Only   \n",
      "3    STN  WideFreq      PKG DK Score    Offset + Osc vs. Osc Only   \n",
      "4    STN  WideFreq  PKG Tremor Score  Exponent + Osc vs. Osc Only   \n",
      "\n",
      "   F_statistic       P_value  Delta_AdjR2  AdjR2_Reduced  AdjR2_Full  \\\n",
      "0   235.373151  1.019709e-51     0.052536       0.014308    0.066844   \n",
      "1   234.864531  1.298544e-51     0.052428       0.014308    0.066736   \n",
      "2     0.944866  3.310861e-01    -0.000013       0.027536    0.027523   \n",
      "3     0.799906  3.711733e-01    -0.000047       0.027536    0.027489   \n",
      "4    32.048935  1.604613e-08     0.007317       0.011606    0.018923   \n",
      "\n",
      "    AIC_Reduced      AIC_Full   BIC_Reduced      BIC_Full  N_reduced  N_full  \n",
      "0  35430.347993  35203.169569  35449.352128  35228.508415       4166    4166  \n",
      "1  35430.347993  35203.651455  35449.352128  35228.990301       4166    4166  \n",
      "2  37942.615931  37943.670265  37961.620066  37969.009111       4166    4166  \n",
      "3  37942.615931  37943.815334  37961.620066  37969.154180       4166    4166  \n",
      "4  26570.006988  26540.050135  26589.011123  26565.388981       4166    4166  \n",
      "Saved model summaries/coefficients: COHORT_RCS02_05_06_MLR_Coefficients_byRegion_Step6.csv\n",
      "  Region  FreqBand PKG_Symptom_DV              Model_Tier  \\\n",
      "0    STN  WideFreq   PKG BK Score        Tier 1: Osc Only   \n",
      "1    STN  WideFreq   PKG BK Score  Tier 2: Exponent + Osc   \n",
      "2    STN  WideFreq   PKG BK Score  Tier 2: Exponent + Osc   \n",
      "3    STN  WideFreq   PKG BK Score  Tier 2: Exponent + Osc   \n",
      "4    STN  WideFreq   PKG BK Score    Tier 3: Offset + Osc   \n",
      "\n",
      "                     Predictor_Term  Coefficient        PValue    Adj_R2  \\\n",
      "0                               NaN          NaN           NaN  0.014308   \n",
      "1                Exponent_BestModel    -4.836486  1.019709e-51  0.066844   \n",
      "2   Beta_Peak_Power_at_DominantFreq     2.908250  1.261487e-09  0.066844   \n",
      "3  Gamma_Peak_Power_at_DominantFreq    -6.437741  5.835726e-28  0.066844   \n",
      "4                  Offset_BestModel    -3.086022  1.298544e-51  0.066736   \n",
      "\n",
      "   N_model  \n",
      "0     4166  \n",
      "1     4166  \n",
      "2     4166  \n",
      "3     4166  \n",
      "4     4166  \n",
      "\n",
      "--- Cell 6 (Region-level, Streamlined V4 with LRT): Analyses Complete ---\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 6 (Region-level, Streamlined V4 with LRT): Multiple Linear Regression ---\n",
    "# Compares nested models with Likelihood Ratio Tests for each Region (STN/M1) × FreqRangeLabel.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\n--- Cell 6 (Region-level, Streamlined V4 with LRT): Starting Analyses ---\\n\")\n",
    "\n",
    "# p-value threshold for interpretation notes (does not affect model fitting)\n",
    "P_VALUE_THRESHOLD = 0.05\n",
    "print(f\"p-value threshold is {P_VALUE_THRESHOLD}.\")\n",
    "\n",
    "# <<< --- USER TOGGLES --- >>>\n",
    "ANALYZE_ALL_FREQ_BANDS = False\n",
    "TARGET_FREQ_BAND_IF_NOT_ALL = \"WideFreq\"\n",
    "MLR_ENABLE_PLOTS = False  # keep plots off by default\n",
    "# <<< -------------------- >>>\n",
    "\n",
    "# ---------- Source data (Region-level if available) ----------\n",
    "if 'df_analysis' in globals() and df_analysis is not None and not df_analysis.empty:\n",
    "    src6 = df_analysis.copy()\n",
    "else:\n",
    "    src6 = master_df_step4.copy() if ('master_df_step4' in globals() and master_df_step4 is not None) else None\n",
    "\n",
    "if src6 is None or src6.empty:\n",
    "    print(\"No data available for Cell 6. Skipping.\")\n",
    "else:\n",
    "    # Ensure Region exists; if not, derive from Channel_Display (same rule as Cell 3)\n",
    "    if 'Region' not in src6.columns and CHANNEL_DISPLAY_COL in src6.columns:\n",
    "        _m = src6[CHANNEL_DISPLAY_COL].astype(str).str.extract(r'Contact_(\\d+)_(\\d+)', expand=True)\n",
    "        _a = pd.to_numeric(_m[0], errors='coerce')\n",
    "        _b = pd.to_numeric(_m[1], errors='coerce')\n",
    "        src6['Region'] = np.where((_a <= 3) & (_b <= 3), 'STN',\n",
    "                           np.where((_a >= 4) & (_b >= 4), 'M1', 'Mixed'))\n",
    "    if 'Region' in src6.columns:\n",
    "        src6 = src6[src6['Region'].isin(['STN', 'M1'])].copy()\n",
    "\n",
    "    # Frequency bands to run\n",
    "    freq_bands_to_process = ORDERED_FREQ_LABELS if ANALYZE_ALL_FREQ_BANDS else [TARGET_FREQ_BAND_IF_NOT_ALL]\n",
    "    if not ANALYZE_ALL_FREQ_BANDS:\n",
    "        print(f\"--- Analyzing ONLY Freq Band: {TARGET_FREQ_BAND_IF_NOT_ALL} ---\")\n",
    "\n",
    "    # Column names (ensure presence)\n",
    "    exponent_col_name = 'Exponent_BestModel'\n",
    "    offset_col_name   = 'Offset_BestModel'\n",
    "    beta_col_name     = 'Beta_Peak_Power_at_DominantFreq'\n",
    "    gamma_col_name    = 'Gamma_Peak_Power_at_DominantFreq'\n",
    "\n",
    "    available_aperiodic_cols   = [c for c in [exponent_col_name, offset_col_name] if c in src6.columns]\n",
    "    available_oscillatory_cols = [c for c in [beta_col_name, gamma_col_name] if c in src6.columns]\n",
    "\n",
    "    if not available_oscillatory_cols:\n",
    "        print(\"No oscillatory predictors present (Beta/Gamma). Skipping Cell 6.\")\n",
    "    else:\n",
    "        # Optional: small diagnostic plots folder (kept off by default)\n",
    "        plot_subdir_mlr = os.path.join(analysis_session_plot_folder_step4, \"MLR_byRegion_V4\")\n",
    "        os.makedirs(plot_subdir_mlr, exist_ok=True)\n",
    "        if MLR_ENABLE_PLOTS:\n",
    "            plot_subdir_ap_corr = os.path.join(plot_subdir_mlr, \"Aperiodic_Intercorrelations\")\n",
    "            os.makedirs(plot_subdir_ap_corr, exist_ok=True)\n",
    "        else:\n",
    "            plot_subdir_ap_corr = None\n",
    "\n",
    "        mlr_rows = []\n",
    "        lrt_rows = []\n",
    "\n",
    "        # Helper: fit OLS safely\n",
    "        def _fit_ols(df_in, dv_col, predictors):\n",
    "            \"\"\"Return statsmodels fit or None if not enough data / issues.\"\"\"\n",
    "            if any(p not in df_in.columns for p in predictors):\n",
    "                return None\n",
    "            use_cols = [dv_col] + predictors\n",
    "            dfm = df_in[use_cols].dropna(how='any').copy()\n",
    "            # Require at least (#predictors + 10) samples (rule of thumb)\n",
    "            if len(dfm) < (len(predictors) + 10):\n",
    "                return None\n",
    "            # No constant predictors\n",
    "            for p in predictors:\n",
    "                if dfm[p].nunique() < 2:\n",
    "                    return None\n",
    "            try:\n",
    "                formula = f\"{dv_col} ~ {' + '.join(predictors)}\"\n",
    "                fit = smf.ols(formula=formula, data=dfm).fit()\n",
    "                return fit\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "        # Iterate Region × Freq\n",
    "        for region in (['STN', 'M1'] if 'Region' in src6.columns else ['All']):\n",
    "            df_region = src6 if region == 'All' else src6[src6['Region'] == region]\n",
    "            if df_region.empty:\n",
    "                continue\n",
    "\n",
    "            for freq_label in freq_bands_to_process:\n",
    "                if FOOOF_FREQ_BAND_COL not in df_region.columns:\n",
    "                    print(f\"Missing '{FOOOF_FREQ_BAND_COL}'. Skipping.\")\n",
    "                    continue\n",
    "                df_rf = df_region[df_region[FOOOF_FREQ_BAND_COL] == freq_label].copy()\n",
    "                if df_rf.empty:\n",
    "                    continue\n",
    "\n",
    "                # Optional: quick inter-corr plots (Aperiodic and Oscillatory); gated\n",
    "                if MLR_ENABLE_PLOTS and plot_subdir_ap_corr:\n",
    "                    # Aperiodic inter-corr\n",
    "                    if exponent_col_name in df_rf.columns and offset_col_name in df_rf.columns:\n",
    "                        df_ap = df_rf[[exponent_col_name, offset_col_name]].dropna()\n",
    "                        if len(df_ap) >= MIN_SAMPLES_FOR_CORR:\n",
    "                            plt.figure(figsize=(6, 6)); ax = plt.gca(); ax.grid(False)\n",
    "                            sns.scatterplot(data=df_ap, x=exponent_col_name, y=offset_col_name,\n",
    "                                            alpha=DOT_ALPHA_STEP4, s=40, edgecolor='k', linewidths=0.5, ax=ax)\n",
    "                            sns.regplot(data=df_ap, x=exponent_col_name, y=offset_col_name, scatter=False, ax=ax,\n",
    "                                        line_kws={'color':'black','linewidth':REG_LINE_THICKNESS_STEP4,'alpha':0.7})\n",
    "                            ax.set_title(f\"Aperiodic Inter-corr — {region} [{freq_label}]\")\n",
    "                            out_ap = os.path.join(plot_subdir_ap_corr,\n",
    "                                                  f\"AperiodicCorr_Exponent_vs_Offset_{region}_{freq_label}.png\")\n",
    "                            plt.tight_layout(); plt.savefig(out_ap); plt.close()\n",
    "\n",
    "                    # Oscillatory inter-corr\n",
    "                    if beta_col_name in df_rf.columns and gamma_col_name in df_rf.columns:\n",
    "                        df_osc = df_rf[[beta_col_name, gamma_col_name]].dropna()\n",
    "                        if len(df_osc) >= MIN_SAMPLES_FOR_CORR:\n",
    "                            plt.figure(figsize=(6, 6)); ax = plt.gca(); ax.grid(False)\n",
    "                            sns.scatterplot(data=df_osc, x=beta_col_name, y=gamma_col_name,\n",
    "                                            alpha=DOT_ALPHA_STEP4, s=40, edgecolor='k', linewidths=0.5, ax=ax)\n",
    "                            sns.regplot(data=df_osc, x=beta_col_name, y=gamma_col_name, scatter=False, ax=ax,\n",
    "                                        line_kws={'color':'black','linewidth':REG_LINE_THICKNESS_STEP4,'alpha':0.7})\n",
    "                            ax.set_title(f\"Oscillatory Inter-corr — {region} [{freq_label}]\")\n",
    "                            out_osc = os.path.join(plot_subdir_ap_corr,\n",
    "                                                   f\"OscillatoryCorr_Beta_vs_Gamma_{region}_{freq_label}.png\")\n",
    "                            plt.tight_layout(); plt.savefig(out_osc); plt.close()\n",
    "\n",
    "                # ---------- Fit models per DV ----------\n",
    "                for pkg_col, pkg_name in PKG_METRICS_COLS.items():\n",
    "                    if pkg_col not in df_rf.columns:\n",
    "                        continue\n",
    "\n",
    "                    # Reduced model (Oscillatory only)\n",
    "                    osc_predictors = [c for c in [beta_col_name, gamma_col_name] if c in df_rf.columns]\n",
    "                    reduced_fit = _fit_ols(df_rf, pkg_col, osc_predictors)\n",
    "\n",
    "                    # Full model 1: Exponent + Osc\n",
    "                    if exponent_col_name in df_rf.columns and reduced_fit is not None:\n",
    "                        predictors_full_exp = [exponent_col_name] + osc_predictors\n",
    "                        full_exp_fit = _fit_ols(df_rf, pkg_col, predictors_full_exp)\n",
    "                    else:\n",
    "                        full_exp_fit = None\n",
    "\n",
    "                    # Full model 2: Offset + Osc\n",
    "                    if offset_col_name in df_rf.columns and reduced_fit is not None:\n",
    "                        predictors_full_off = [offset_col_name] + osc_predictors\n",
    "                        full_off_fit = _fit_ols(df_rf, pkg_col, predictors_full_off)\n",
    "                    else:\n",
    "                        full_off_fit = None\n",
    "\n",
    "                    # Collect base (reduced) model info if it exists\n",
    "                    if reduced_fit is not None:\n",
    "                        mlr_rows.append({\n",
    "                            'Region': region, 'FreqBand': freq_label, 'PKG_Symptom_DV': pkg_name,\n",
    "                            'Model_Tier': 'Tier 1: Osc Only',\n",
    "                            'Formula': f\"{pkg_col} ~ {' + '.join(osc_predictors)}\",\n",
    "                            'N_model': int(reduced_fit.nobs),\n",
    "                            'Adj_R2': float(reduced_fit.rsquared_adj),\n",
    "                            'AIC': float(reduced_fit.aic),\n",
    "                            'BIC': float(reduced_fit.bic)\n",
    "                        })\n",
    "\n",
    "                    # LRT: Exponent + Osc vs Osc\n",
    "                    if reduced_fit is not None and full_exp_fit is not None:\n",
    "                        try:\n",
    "                            lrt_tbl = anova_lm(reduced_fit, full_exp_fit)  # nested comparison\n",
    "                            f_stat = float(lrt_tbl.iloc[1]['F'])\n",
    "                            p_val  = float(lrt_tbl.iloc[1]['Pr(>F)'])\n",
    "                        except Exception:\n",
    "                            f_stat, p_val = (np.nan, np.nan)\n",
    "\n",
    "                        delta_adjR2 = float(full_exp_fit.rsquared_adj - reduced_fit.rsquared_adj)\n",
    "\n",
    "                        lrt_rows.append({\n",
    "                            'Region': region, 'FreqBand': freq_label, 'PKG_Symptom_DV': pkg_name,\n",
    "                            'Comparison': 'Exponent + Osc vs. Osc Only',\n",
    "                            'F_statistic': f_stat, 'P_value': p_val,\n",
    "                            'Delta_AdjR2': delta_adjR2,\n",
    "                            'AdjR2_Reduced': float(reduced_fit.rsquared_adj),\n",
    "                            'AdjR2_Full': float(full_exp_fit.rsquared_adj),\n",
    "                            'AIC_Reduced': float(reduced_fit.aic), 'AIC_Full': float(full_exp_fit.aic),\n",
    "                            'BIC_Reduced': float(reduced_fit.bic), 'BIC_Full': float(full_exp_fit.bic),\n",
    "                            'N_reduced': int(reduced_fit.nobs), 'N_full': int(full_exp_fit.nobs)\n",
    "                        })\n",
    "\n",
    "                        # Store full model coefficients too\n",
    "                        for term in full_exp_fit.params.index:\n",
    "                            if term == 'Intercept': \n",
    "                                continue\n",
    "                            mlr_rows.append({\n",
    "                                'Region': region, 'FreqBand': freq_label, 'PKG_Symptom_DV': pkg_name,\n",
    "                                'Model_Tier': 'Tier 2: Exponent + Osc',\n",
    "                                'Formula': f\"{pkg_col} ~ {' + '.join(predictors_full_exp)}\",\n",
    "                                'Predictor_Term': term,\n",
    "                                'Predictor_Name_Display': APERIODIC_METRICS_COLS.get(term, OSCILLATORY_METRICS_COLS.get(term, term)),\n",
    "                                'Coefficient': float(full_exp_fit.params.get(term, np.nan)),\n",
    "                                'StdErr': float(full_exp_fit.bse.get(term, np.nan)),\n",
    "                                'PValue': float(full_exp_fit.pvalues.get(term, np.nan)),\n",
    "                                'Conf_Int_Lower': float(full_exp_fit.conf_int().loc[term, 0]) if term in full_exp_fit.conf_int().index else np.nan,\n",
    "                                'Conf_Int_Upper': float(full_exp_fit.conf_int().loc[term, 1]) if term in full_exp_fit.conf_int().index else np.nan,\n",
    "                                'N_model': int(full_exp_fit.nobs),\n",
    "                                'Adj_R2': float(full_exp_fit.rsquared_adj),\n",
    "                                'AIC': float(full_exp_fit.aic),\n",
    "                                'BIC': float(full_exp_fit.bic)\n",
    "                            })\n",
    "\n",
    "                    # LRT: Offset + Osc vs Osc\n",
    "                    if reduced_fit is not None and full_off_fit is not None:\n",
    "                        try:\n",
    "                            lrt_tbl = anova_lm(reduced_fit, full_off_fit)  # nested comparison\n",
    "                            f_stat = float(lrt_tbl.iloc[1]['F'])\n",
    "                            p_val  = float(lrt_tbl.iloc[1]['Pr(>F)'])\n",
    "                        except Exception:\n",
    "                            f_stat, p_val = (np.nan, np.nan)\n",
    "\n",
    "                        delta_adjR2 = float(full_off_fit.rsquared_adj - reduced_fit.rsquared_adj)\n",
    "\n",
    "                        lrt_rows.append({\n",
    "                            'Region': region, 'FreqBand': freq_label, 'PKG_Symptom_DV': pkg_name,\n",
    "                            'Comparison': 'Offset + Osc vs. Osc Only',\n",
    "                            'F_statistic': f_stat, 'P_value': p_val,\n",
    "                            'Delta_AdjR2': delta_adjR2,\n",
    "                            'AdjR2_Reduced': float(reduced_fit.rsquared_adj),\n",
    "                            'AdjR2_Full': float(full_off_fit.rsquared_adj),\n",
    "                            'AIC_Reduced': float(reduced_fit.aic), 'AIC_Full': float(full_off_fit.aic),\n",
    "                            'BIC_Reduced': float(reduced_fit.bic), 'BIC_Full': float(full_off_fit.bic),\n",
    "                            'N_reduced': int(reduced_fit.nobs), 'N_full': int(full_off_fit.nobs)\n",
    "                        })\n",
    "\n",
    "                        # Store full model coefficients too\n",
    "                        for term in full_off_fit.params.index:\n",
    "                            if term == 'Intercept':\n",
    "                                continue\n",
    "                            mlr_rows.append({\n",
    "                                'Region': region, 'FreqBand': freq_label, 'PKG_Symptom_DV': pkg_name,\n",
    "                                'Model_Tier': 'Tier 3: Offset + Osc',\n",
    "                                'Formula': f\"{pkg_col} ~ {' + '.join(predictors_full_off)}\",\n",
    "                                'Predictor_Term': term,\n",
    "                                'Predictor_Name_Display': APERIODIC_METRICS_COLS.get(term, OSCILLATORY_METRICS_COLS.get(term, term)),\n",
    "                                'Coefficient': float(full_off_fit.params.get(term, np.nan)),\n",
    "                                'StdErr': float(full_off_fit.bse.get(term, np.nan)),\n",
    "                                'PValue': float(full_off_fit.pvalues.get(term, np.nan)),\n",
    "                                'Conf_Int_Lower': float(full_off_fit.conf_int().loc[term, 0]) if term in full_off_fit.conf_int().index else np.nan,\n",
    "                                'Conf_Int_Upper': float(full_off_fit.conf_int().loc[term, 1]) if term in full_off_fit.conf_int().index else np.nan,\n",
    "                                'N_model': int(full_off_fit.nobs),\n",
    "                                'Adj_R2': float(full_off_fit.rsquared_adj),\n",
    "                                'AIC': float(full_off_fit.aic),\n",
    "                                'BIC': float(full_off_fit.bic)\n",
    "                            })\n",
    "\n",
    "        # ------ Save outputs ------\n",
    "        if lrt_rows:\n",
    "            df_lrt = pd.DataFrame(lrt_rows)\n",
    "            csv_lrt = f\"{patient_hemisphere_id}_MLR_LRT_Results_byRegion_Step6.csv\"\n",
    "            df_lrt.to_csv(os.path.join(plot_subdir_mlr, csv_lrt), index=False)\n",
    "            print(f\"\\nSaved LRT results: {csv_lrt}\")\n",
    "            print(df_lrt.head())\n",
    "        else:\n",
    "            print(\"\\nNo Likelihood Ratio Tests were performed (insufficient data or predictors missing).\")\n",
    "\n",
    "        if mlr_rows:\n",
    "            df_mlr = pd.DataFrame(mlr_rows)\n",
    "            csv_mlr = f\"{patient_hemisphere_id}_MLR_Coefficients_byRegion_Step6.csv\"\n",
    "            df_mlr.to_csv(os.path.join(plot_subdir_mlr, csv_mlr), index=False)\n",
    "            print(f\"Saved model summaries/coefficients: {csv_mlr}\")\n",
    "            cols_show = ['Region','FreqBand','PKG_Symptom_DV','Model_Tier','Predictor_Term','Coefficient','PValue','Adj_R2','N_model']\n",
    "            print(df_mlr[[c for c in cols_show if c in df_mlr.columns]].head())\n",
    "        else:\n",
    "            print(\"No MLR models were successfully fitted or nothing to save for coefficients.\")\n",
    "\n",
    "print(\"\\n--- Cell 6 (Region-level, Streamlined V4 with LRT): Analyses Complete ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec00f937-a0d2-4816-b5f3-bf30547aa712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 6A (Region-level): State-Specific MLR & LRT with FDR ---\n",
      "\n",
      "--- Analyzing ONLY Freq Band: WideFreq ---\n",
      "\n",
      "Collected 48 state-specific LRT rows.\n",
      "Applied BH-FDR to LRT p-values.\n",
      "Saved LRT (with FDR) to COHORT_RCS02_05_06_MLR_LRT_StateSpecific_byRegion_Results_FDR_Step6A.csv\n",
      "  ClinicalState Region  FreqBand    PKG_Symptom_DV  \\\n",
      "0      Immobile    STN  WideFreq      PKG BK Score   \n",
      "1      Immobile    STN  WideFreq      PKG BK Score   \n",
      "2      Immobile    STN  WideFreq      PKG DK Score   \n",
      "3      Immobile    STN  WideFreq      PKG DK Score   \n",
      "4      Immobile    STN  WideFreq  PKG Tremor Score   \n",
      "\n",
      "                    Comparison  F_statistic       P_value  Delta_AdjR2  \\\n",
      "0  Exponent + Osc vs. Osc Only    49.701417  2.692950e-12     0.030119   \n",
      "1    Offset + Osc vs. Osc Only    60.364672  1.429803e-14     0.036469   \n",
      "2  Exponent + Osc vs. Osc Only     2.297676  1.297729e-01     0.000812   \n",
      "3    Offset + Osc vs. Osc Only     0.086513  7.686974e-01    -0.000573   \n",
      "4  Exponent + Osc vs. Osc Only     1.123473  2.893380e-01     0.000080   \n",
      "\n",
      "   AdjR2_Reduced  AdjR2_Full   AIC_Reduced      AIC_Full   BIC_Reduced  \\\n",
      "0       0.016851    0.046970  11753.882452  11706.839154  11769.908847   \n",
      "1       0.016851    0.053320  11753.882452  11696.517031  11769.908847   \n",
      "2       0.034392    0.035205   4742.251975   4741.950048   4758.278371   \n",
      "3       0.034392    0.033819   4742.251975   4744.165240   4758.278371   \n",
      "4      -0.001086   -0.001006   8185.889143   8186.763162   8201.915538   \n",
      "\n",
      "       BIC_Full  N_reduced  N_full   P_value_FDR  Significant_FDR  \n",
      "0  11728.207681       1544    1544  2.585232e-11             True  \n",
      "1  11717.885558       1544    1544  2.287685e-13             True  \n",
      "2   4763.318575       1544    1544  2.322926e-01            False  \n",
      "3   4765.533767       1544    1544  8.785113e-01            False  \n",
      "4   8208.131689       1544    1544  4.084772e-01            False  \n",
      "Saved model summaries/coefficients to COHORT_RCS02_05_06_MLR_StateSpecific_byRegion_ModelCoeffs_Step6A.csv\n",
      "  ClinicalState Region  FreqBand PKG_Symptom_DV              Model_Tier  \\\n",
      "0      Immobile    STN  WideFreq   PKG BK Score        Tier 1: Osc Only   \n",
      "1      Immobile    STN  WideFreq   PKG BK Score  Tier 2: Exponent + Osc   \n",
      "2      Immobile    STN  WideFreq   PKG BK Score  Tier 2: Exponent + Osc   \n",
      "3      Immobile    STN  WideFreq   PKG BK Score  Tier 2: Exponent + Osc   \n",
      "4      Immobile    STN  WideFreq   PKG BK Score    Tier 3: Offset + Osc   \n",
      "\n",
      "                     Predictor_Term  Coefficient        PValue    Adj_R2  \\\n",
      "0                               NaN          NaN           NaN  0.016851   \n",
      "1                Exponent_BestModel    -2.736919  2.692950e-12  0.046970   \n",
      "2   Beta_Peak_Power_at_DominantFreq    -1.360061  1.604446e-02  0.046970   \n",
      "3  Gamma_Peak_Power_at_DominantFreq     0.906989  1.609543e-01  0.046970   \n",
      "4                  Offset_BestModel    -1.877678  1.429803e-14  0.053320   \n",
      "\n",
      "   N_model  \n",
      "0     1544  \n",
      "1     1544  \n",
      "2     1544  \n",
      "3     1544  \n",
      "4     1544  \n",
      "\n",
      "--- Cell 6A (Region-level): Complete ---\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 6A (Revised, Region-level): State-Specific MLR with LRT + FDR ---\n",
    "# Runs nested OLS models per Clinical State × Region (STN/M1) × FreqRangeLabel.\n",
    "# Reduced:  PKG ~ Beta + Gamma\n",
    "# Full #1:  PKG ~ Exponent + Beta + Gamma\n",
    "# Full #2:  PKG ~ Offset  + Beta + Gamma\n",
    "# Performs LRTs (anova_lm) and applies BH-FDR across ALL state-specific LRT p-values.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "print(\"\\n--- Cell 6A (Region-level): State-Specific MLR & LRT with FDR ---\\n\")\n",
    "\n",
    "# <<< --- USER TOGGLES --- >>>\n",
    "ANALYZE_ALL_FREQ_BANDS_STATE_SPECIFIC = False\n",
    "TARGET_FREQ_BAND_IF_NOT_ALL_STATE_SPECIFIC = \"WideFreq\"\n",
    "MIN_STATE_ROWS = 20  # skip states with fewer rows than this\n",
    "# <<< ---------------------- >>>\n",
    "\n",
    "# ---- Source dataframe ----\n",
    "if 'df_analysis' in globals() and df_analysis is not None and not df_analysis.empty:\n",
    "    src6a = df_analysis.copy()\n",
    "else:\n",
    "    src6a = master_df_step4.copy() if ('master_df_step4' in globals() and master_df_step4 is not None) else None\n",
    "\n",
    "if src6a is None or src6a.empty:\n",
    "    print(\"No data available. Skipping Cell 6A.\")\n",
    "else:\n",
    "    # Ensure Region column exists (STN/M1 only)\n",
    "    if 'Region' not in src6a.columns and CHANNEL_DISPLAY_COL in src6a.columns:\n",
    "        _m = src6a[CHANNEL_DISPLAY_COL].astype(str).str.extract(r'Contact_(\\d+)_(\\d+)', expand=True)\n",
    "        _a = pd.to_numeric(_m[0], errors='coerce')\n",
    "        _b = pd.to_numeric(_m[1], errors='coerce')\n",
    "        src6a['Region'] = np.where((_a <= 3) & (_b <= 3), 'STN',\n",
    "                            np.where((_a >= 4) & (_b >= 4), 'M1', 'Mixed'))\n",
    "    if 'Region' in src6a.columns:\n",
    "        src6a = src6a[src6a['Region'].isin(['STN', 'M1'])].copy()\n",
    "\n",
    "    # Frequency bands to run\n",
    "    freq_bands = ORDERED_FREQ_LABELS if ANALYZE_ALL_FREQ_BANDS_STATE_SPECIFIC else [TARGET_FREQ_BAND_IF_NOT_ALL_STATE_SPECIFIC]\n",
    "    if not ANALYZE_ALL_FREQ_BANDS_STATE_SPECIFIC:\n",
    "        print(f\"--- Analyzing ONLY Freq Band: {TARGET_FREQ_BAND_IF_NOT_ALL_STATE_SPECIFIC} ---\")\n",
    "\n",
    "    # Column names\n",
    "    exponent_col = 'Exponent_BestModel'\n",
    "    offset_col   = 'Offset_BestModel'\n",
    "    beta_col     = 'Beta_Peak_Power_at_DominantFreq'\n",
    "    gamma_col    = 'Gamma_Peak_Power_at_DominantFreq'\n",
    "\n",
    "    # Predictors present?\n",
    "    have_beta  = beta_col  in src6a.columns\n",
    "    have_gamma = gamma_col in src6a.columns\n",
    "    if not (have_beta or have_gamma):\n",
    "        print(\"No oscillatory predictors (Beta/Gamma) available. Skipping Cell 6A.\")\n",
    "    else:\n",
    "        # Output folder\n",
    "        outdir_states = os.path.join(STATE_SPECIFIC_ANALYSIS_DIR, \"MLR_State_Specific_byRegion_FDR\")\n",
    "        os.makedirs(outdir_states, exist_ok=True)\n",
    "\n",
    "        # Helpers\n",
    "        def _fit_ols(df_in, dv_col, predictors):\n",
    "            \"\"\"Fit OLS safely; return fit or None.\"\"\"\n",
    "            if any(p not in df_in.columns for p in predictors):\n",
    "                return None\n",
    "            use_cols = [dv_col] + predictors\n",
    "            dfm = df_in[use_cols].dropna(how='any').copy()\n",
    "            # Rule of thumb: at least (#predictors + 10) samples\n",
    "            if len(dfm) < (len(predictors) + 10):\n",
    "                return None\n",
    "            # drop if any predictor is constant\n",
    "            for p in predictors:\n",
    "                if dfm[p].nunique() < 2:\n",
    "                    return None\n",
    "            try:\n",
    "                formula = f\"{dv_col} ~ {' + '.join(predictors)}\"\n",
    "                return smf.ols(formula=formula, data=dfm).fit()\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "        # Collectors\n",
    "        coeff_rows = []   # model summaries / coefficients\n",
    "        lrt_rows   = []   # LRT results (will get FDR)\n",
    "\n",
    "        # Iterate states\n",
    "        for state in TARGET_CLINICAL_STATES_ORDERED:\n",
    "            if CLINICAL_STATE_COL not in src6a.columns:\n",
    "                print(f\"Missing '{CLINICAL_STATE_COL}'. Skipping all states.\")\n",
    "                break\n",
    "\n",
    "            df_state = src6a[src6a[CLINICAL_STATE_COL] == state].copy()\n",
    "            if df_state.empty or len(df_state) < MIN_STATE_ROWS:\n",
    "                print(f\"SKIP state '{state}' (N={len(df_state)})\")\n",
    "                continue\n",
    "\n",
    "            for region in ['STN', 'M1']:\n",
    "                df_sr = df_state[df_state['Region'] == region]\n",
    "                if df_sr.empty:\n",
    "                    continue\n",
    "\n",
    "                for band in freq_bands:\n",
    "                    if FOOOF_FREQ_BAND_COL not in df_sr.columns:\n",
    "                        print(f\"Missing '{FOOOF_FREQ_BAND_COL}'. Skipping.\")\n",
    "                        continue\n",
    "                    df_srf = df_sr[df_sr[FOOOF_FREQ_BAND_COL] == band].copy()\n",
    "                    if df_srf.empty:\n",
    "                        continue\n",
    "\n",
    "                    # Osc-only predictors available in this slice?\n",
    "                    osc_predictors = [c for c in [beta_col, gamma_col] if c in df_srf.columns]\n",
    "                    if not osc_predictors:\n",
    "                        continue\n",
    "\n",
    "                    # Run per PKG DV\n",
    "                    for dv_col, dv_name in PKG_METRICS_COLS.items():\n",
    "                        if dv_col not in df_srf.columns:\n",
    "                            continue\n",
    "\n",
    "                        reduced = _fit_ols(df_srf, dv_col, osc_predictors)\n",
    "\n",
    "                        # Full (Exponent)\n",
    "                        full_exp = _fit_ols(df_srf, dv_col, [exponent_col] + osc_predictors) if exponent_col in df_srf.columns and reduced is not None else None\n",
    "                        # Full (Offset)\n",
    "                        full_off = _fit_ols(df_srf, dv_col, [offset_col]   + osc_predictors) if offset_col   in df_srf.columns and reduced is not None else None\n",
    "\n",
    "                        # Store reduced model summary if it exists\n",
    "                        if reduced is not None:\n",
    "                            coeff_rows.append({\n",
    "                                'ClinicalState': state, 'Region': region, 'FreqBand': band, 'PKG_Symptom_DV': dv_name,\n",
    "                                'Model_Tier': 'Tier 1: Osc Only',\n",
    "                                'Formula': f\"{dv_col} ~ {' + '.join(osc_predictors)}\",\n",
    "                                'N_model': int(reduced.nobs),\n",
    "                                'Adj_R2': float(reduced.rsquared_adj),\n",
    "                                'AIC': float(reduced.aic), 'BIC': float(reduced.bic)\n",
    "                            })\n",
    "\n",
    "                        # LRT (Exponent + Osc vs Osc)\n",
    "                        if reduced is not None and full_exp is not None:\n",
    "                            try:\n",
    "                                lrt_tbl = anova_lm(reduced, full_exp)  # nested comparison\n",
    "                                f_stat = float(lrt_tbl.iloc[1]['F'])\n",
    "                                p_val  = float(lrt_tbl.iloc[1]['Pr(>F)'])\n",
    "                            except Exception:\n",
    "                                f_stat, p_val = (np.nan, np.nan)\n",
    "\n",
    "                            delta_adjR2 = float(full_exp.rsquared_adj - reduced.rsquared_adj)\n",
    "                            lrt_rows.append({\n",
    "                                'ClinicalState': state, 'Region': region, 'FreqBand': band, 'PKG_Symptom_DV': dv_name,\n",
    "                                'Comparison': 'Exponent + Osc vs. Osc Only',\n",
    "                                'F_statistic': f_stat, 'P_value': p_val,\n",
    "                                'Delta_AdjR2': delta_adjR2,\n",
    "                                'AdjR2_Reduced': float(reduced.rsquared_adj), 'AdjR2_Full': float(full_exp.rsquared_adj),\n",
    "                                'AIC_Reduced': float(reduced.aic), 'AIC_Full': float(full_exp.aic),\n",
    "                                'BIC_Reduced': float(reduced.bic), 'BIC_Full': float(full_exp.bic),\n",
    "                                'N_reduced': int(reduced.nobs), 'N_full': int(full_exp.nobs)\n",
    "                            })\n",
    "                            # Store coefficients of full model\n",
    "                            for term in full_exp.params.index:\n",
    "                                if term == 'Intercept':\n",
    "                                    continue\n",
    "                                coeff_rows.append({\n",
    "                                    'ClinicalState': state, 'Region': region, 'FreqBand': band, 'PKG_Symptom_DV': dv_name,\n",
    "                                    'Model_Tier': 'Tier 2: Exponent + Osc',\n",
    "                                    'Formula': f\"{dv_col} ~ {exponent_col} + {' + '.join(osc_predictors)}\",\n",
    "                                    'Predictor_Term': term,\n",
    "                                    'Predictor_Name_Display': APERIODIC_METRICS_COLS.get(term, OSCILLATORY_METRICS_COLS.get(term, term)),\n",
    "                                    'Coefficient': float(full_exp.params.get(term, np.nan)),\n",
    "                                    'StdErr': float(full_exp.bse.get(term, np.nan)),\n",
    "                                    'PValue': float(full_exp.pvalues.get(term, np.nan)),\n",
    "                                    'Conf_Int_Lower': float(full_exp.conf_int().loc[term, 0]) if term in full_exp.conf_int().index else np.nan,\n",
    "                                    'Conf_Int_Upper': float(full_exp.conf_int().loc[term, 1]) if term in full_exp.conf_int().index else np.nan,\n",
    "                                    'N_model': int(full_exp.nobs),\n",
    "                                    'Adj_R2': float(full_exp.rsquared_adj),\n",
    "                                    'AIC': float(full_exp.aic), 'BIC': float(full_exp.bic)\n",
    "                                })\n",
    "\n",
    "                        # LRT (Offset + Osc vs Osc)\n",
    "                        if reduced is not None and full_off is not None:\n",
    "                            try:\n",
    "                                lrt_tbl = anova_lm(reduced, full_off)  # nested comparison\n",
    "                                f_stat = float(lrt_tbl.iloc[1]['F'])\n",
    "                                p_val  = float(lrt_tbl.iloc[1]['Pr(>F)'])\n",
    "                            except Exception:\n",
    "                                f_stat, p_val = (np.nan, np.nan)\n",
    "\n",
    "                            delta_adjR2 = float(full_off.rsquared_adj - reduced.rsquared_adj)\n",
    "                            lrt_rows.append({\n",
    "                                'ClinicalState': state, 'Region': region, 'FreqBand': band, 'PKG_Symptom_DV': dv_name,\n",
    "                                'Comparison': 'Offset + Osc vs. Osc Only',\n",
    "                                'F_statistic': f_stat, 'P_value': p_val,\n",
    "                                'Delta_AdjR2': delta_adjR2,\n",
    "                                'AdjR2_Reduced': float(reduced.rsquared_adj), 'AdjR2_Full': float(full_off.rsquared_adj),\n",
    "                                'AIC_Reduced': float(reduced.aic), 'AIC_Full': float(full_off.aic),\n",
    "                                'BIC_Reduced': float(reduced.bic), 'BIC_Full': float(full_off.bic),\n",
    "                                'N_reduced': int(reduced.nobs), 'N_full': int(full_off.nobs)\n",
    "                            })\n",
    "                            # Store coefficients of full model\n",
    "                            for term in full_off.params.index:\n",
    "                                if term == 'Intercept':\n",
    "                                    continue\n",
    "                                coeff_rows.append({\n",
    "                                    'ClinicalState': state, 'Region': region, 'FreqBand': band, 'PKG_Symptom_DV': dv_name,\n",
    "                                    'Model_Tier': 'Tier 3: Offset + Osc',\n",
    "                                    'Formula': f\"{dv_col} ~ {offset_col} + {' + '.join(osc_predictors)}\",\n",
    "                                    'Predictor_Term': term,\n",
    "                                    'Predictor_Name_Display': APERIODIC_METRICS_COLS.get(term, OSCILLATORY_METRICS_COLS.get(term, term)),\n",
    "                                    'Coefficient': float(full_off.params.get(term, np.nan)),\n",
    "                                    'StdErr': float(full_off.bse.get(term, np.nan)),\n",
    "                                    'PValue': float(full_off.pvalues.get(term, np.nan)),\n",
    "                                    'Conf_Int_Lower': float(full_off.conf_int().loc[term, 0]) if term in full_off.conf_int().index else np.nan,\n",
    "                                    'Conf_Int_Upper': float(full_off.conf_int().loc[term, 1]) if term in full_off.conf_int().index else np.nan,\n",
    "                                    'N_model': int(full_off.nobs),\n",
    "                                    'Adj_R2': float(full_off.rsquared_adj),\n",
    "                                    'AIC': float(full_off.aic), 'BIC': float(full_off.bic)\n",
    "                                })\n",
    "\n",
    "        # ---------- FDR over ALL state-specific LRT p-values ----------\n",
    "        print(f\"\\nCollected {len(lrt_rows)} state-specific LRT rows.\")\n",
    "        if lrt_rows:\n",
    "            df_lrt = pd.DataFrame(lrt_rows)\n",
    "            if 'P_value' in df_lrt.columns:\n",
    "                pvals = df_lrt['P_value'].values\n",
    "                mask  = np.isfinite(pvals)\n",
    "                if mask.any():\n",
    "                    rej, p_corr = fdrcorrection(pvals[mask], alpha=0.05, method='indep', is_sorted=False)\n",
    "                    df_lrt['P_value_FDR'] = np.nan\n",
    "                    df_lrt.loc[mask, 'P_value_FDR'] = p_corr\n",
    "                    df_lrt['Significant_FDR'] = False\n",
    "                    df_lrt.loc[mask, 'Significant_FDR'] = rej\n",
    "                    print(\"Applied BH-FDR to LRT p-values.\")\n",
    "                else:\n",
    "                    df_lrt['P_value_FDR'] = np.nan\n",
    "                    df_lrt['Significant_FDR'] = False\n",
    "\n",
    "            # Save LRT CSV\n",
    "            csv_lrt = f\"{patient_hemisphere_id}_MLR_LRT_StateSpecific_byRegion_Results_FDR_Step6A.csv\"\n",
    "            df_lrt.to_csv(os.path.join(outdir_states, csv_lrt), index=False)\n",
    "            print(f\"Saved LRT (with FDR) to {csv_lrt}\")\n",
    "            print(df_lrt.head())\n",
    "        else:\n",
    "            print(\"No LRT rows to correct/save.\")\n",
    "\n",
    "        # Save model coefficients CSV\n",
    "        if coeff_rows:\n",
    "            df_coeff = pd.DataFrame(coeff_rows)\n",
    "            csv_coeff = f\"{patient_hemisphere_id}_MLR_StateSpecific_byRegion_ModelCoeffs_Step6A.csv\"\n",
    "            df_coeff.to_csv(os.path.join(outdir_states, csv_coeff), index=False)\n",
    "            print(f\"Saved model summaries/coefficients to {csv_coeff}\")\n",
    "            show_cols = ['ClinicalState','Region','FreqBand','PKG_Symptom_DV','Model_Tier','Predictor_Term','Coefficient','PValue','Adj_R2','N_model']\n",
    "            print(df_coeff[[c for c in show_cols if c in df_coeff.columns]].head())\n",
    "        else:\n",
    "            print(\"No model coefficient rows to save.\")\n",
    "\n",
    "print(\"\\n--- Cell 6A (Region-level): Complete ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27f46444-c85b-468c-a758-f006d1ea8fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 7 (Region-first): Starting Visualization of Regression Results ---\n",
      "\n",
      "\n",
      "==================\n",
      "Generating Global plots\n",
      "==================\n",
      "[Global] MLR cols: ['Region', 'FreqBand', 'PKG_Symptom_DV', 'Model_Tier', 'Formula', 'N_model', 'Adj_R2', 'AIC'] ...\n",
      "[Global] LRT cols: ['Region', 'FreqBand', 'PKG_Symptom_DV', 'Comparison', 'F_statistic', 'P_value', 'Delta_AdjR2', 'AdjR2_Reduced'] ...\n",
      "[DotWhisker] Saved: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/MLR_byRegion_V4/COHORT_RCS02_05_06_Global_Exponent_Coefficients.png\n",
      "[DotWhisker] Saved: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/MLR_byRegion_V4/COHORT_RCS02_05_06_Global_Offset_Coefficients.png\n",
      "[Orthogonal] Building stacked bar for Added R² by Exponent...\n",
      "[Orthogonal] Values CSV saved: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/MLR_byRegion_V4/COHORT_RCS02_05_06_Global_Orthogonal_Value_VALUES.csv\n",
      "[Orthogonal] Saved: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/MLR_byRegion_V4/COHORT_RCS02_05_06_Global_Orthogonal_Value.png\n",
      "\n",
      "==================\n",
      "Generating StateSpecific plots\n",
      "==================\n",
      "[StateSpecific] MLR cols: ['ClinicalState', 'Region', 'FreqBand', 'PKG_Symptom_DV', 'Model_Tier', 'Formula', 'N_model', 'Adj_R2'] ...\n",
      "[StateSpecific] LRT cols: ['ClinicalState', 'Region', 'FreqBand', 'PKG_Symptom_DV', 'Comparison', 'F_statistic', 'P_value', 'Delta_AdjR2'] ...\n",
      "[DotWhisker] Saved: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/MLR_State_Specific_byRegion_FDR/COHORT_RCS02_05_06_StateSpecific_Exponent_Coefficients.png\n",
      "[DotWhisker] Saved: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/MLR_State_Specific_byRegion_FDR/COHORT_RCS02_05_06_StateSpecific_Offset_Coefficients.png\n",
      "[Orthogonal] Building stacked bar for Added R² by Exponent...\n",
      "[Orthogonal] Values CSV saved: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/MLR_State_Specific_byRegion_FDR/COHORT_RCS02_05_06_StateSpecific_Orthogonal_Value_VALUES.csv\n",
      "[Orthogonal] Saved: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/MLR_State_Specific_byRegion_FDR/COHORT_RCS02_05_06_StateSpecific_Orthogonal_Value.png\n",
      "\n",
      "--- Cell 7 (Region-first): Visualizations Complete ---\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 7 (Region-first): Visualization of MLR and LRT Results ---\n",
    "# Prefers Region (STN/M1) instead of per-contact Channel. If Region is absent,\n",
    "# falls back to Channel. No individual contact plots are produced when Region exists.\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\n--- Cell 7 (Region-first): Starting Visualization of Regression Results ---\\n\")\n",
    "\n",
    "# --- Global Font Size Adjustment (legible but not huge) ---\n",
    "font_scale_factor = 1.6\n",
    "plt.rcParams.update({\n",
    "    'font.size': 10 * font_scale_factor,\n",
    "    'axes.labelsize': 10 * font_scale_factor,\n",
    "    'axes.titlesize': 12 * font_scale_factor,\n",
    "    'xtick.labelsize': 9 * font_scale_factor,\n",
    "    'ytick.labelsize': 9 * font_scale_factor,\n",
    "    'legend.fontsize': 9 * font_scale_factor,\n",
    "    'legend.title_fontsize': 10 * font_scale_factor,\n",
    "})\n",
    "P_VALUE_THRESHOLD = 0.05\n",
    "\n",
    "SYMPTOM_LEGEND_MAP = {\n",
    "    'PKG BK Score': 'Bradykinesia',\n",
    "    'PKG DK Score': 'Dyskinesia',\n",
    "    # 'PKG Tremor Score': 'Tremor'\n",
    "}\n",
    "SYMPTOM_DISPLAY_ORDER = ['Bradykinesia', 'Dyskinesia']#, 'Tremor']\n",
    "REGION_ORDER = ['STN', 'M1']  # enforced when Region is present\n",
    "\n",
    "# ---------------------------- Helpers ----------------------------\n",
    "def _pick_group_dim(df):\n",
    "    \"\"\"Prefer Region; otherwise fall back to Channel.\"\"\"\n",
    "    if 'Region' in df.columns and df['Region'].notna().any():\n",
    "        return 'Region'\n",
    "    return 'Channel' if 'Channel' in df.columns else None\n",
    "\n",
    "def _apply_symptom_display(df):\n",
    "    df['Symptom_Display'] = df['PKG_Symptom_DV'].map(SYMPTOM_LEGEND_MAP).fillna(df['PKG_Symptom_DV'])\n",
    "    # Ordered symptoms present in data\n",
    "    present = [s for s in SYMPTOM_DISPLAY_ORDER if s in df['Symptom_Display'].unique()]\n",
    "    if not present:\n",
    "        present = sorted(df['Symptom_Display'].dropna().unique().tolist())\n",
    "    df['Symptom_Display'] = pd.Categorical(df['Symptom_Display'], categories=present, ordered=True)\n",
    "    return df\n",
    "\n",
    "def _order_group_dim(df, group_dim):\n",
    "    \"\"\"Set order for Region/Channel categories.\"\"\"\n",
    "    if group_dim == 'Region':\n",
    "        cats = [g for g in REGION_ORDER if g in df['Region'].unique()]\n",
    "        if not cats:\n",
    "            cats = sorted(df['Region'].dropna().unique().tolist())\n",
    "        df['Region'] = pd.Categorical(df['Region'], categories=cats, ordered=True)\n",
    "    elif group_dim == 'Channel':\n",
    "        # Keep existing order if already categorical; else alphabetical\n",
    "        if not (hasattr(df['Channel'], 'cat') and len(getattr(df['Channel'], 'cat').categories) > 0):\n",
    "            cats = sorted(df['Channel'].dropna().unique().tolist())\n",
    "            df['Channel'] = pd.Categorical(df['Channel'], categories=cats, ordered=True)\n",
    "    return df\n",
    "\n",
    "def _prep_for_plot(df):\n",
    "    df = df.copy()\n",
    "    df = _apply_symptom_display(df)\n",
    "    group_dim = _pick_group_dim(df)\n",
    "    if group_dim is None:\n",
    "        raise KeyError(\"Neither 'Region' nor 'Channel' found in the results dataframe.\")\n",
    "    df = _order_group_dim(df, group_dim)\n",
    "    if 'ClinicalState' not in df.columns:\n",
    "        df['ClinicalState'] = 'Overall Results'\n",
    "    return df, group_dim\n",
    "\n",
    "# ----------------- Plot 1: Dot–Whisker for Exponent/Offset -----------------\n",
    "def plot_coefficient_dot_whisker(df_mlr, predictor_to_plot, output_path):\n",
    "    predictor_name_map = {'Exponent_BestModel': 'Exponent', 'Offset_BestModel': 'Offset'}\n",
    "    display_name = predictor_name_map.get(predictor_to_plot, predictor_to_plot)\n",
    "\n",
    "    need = ['Coefficient', 'Conf_Int_Lower', 'Conf_Int_Upper', 'Predictor_Term', 'PKG_Symptom_DV']\n",
    "    if any(c not in df_mlr.columns for c in need):\n",
    "        missing = [c for c in need if c not in df_mlr.columns]\n",
    "        print(f\"[DotWhisker] Missing columns {missing}. Skipping {display_name}.\")\n",
    "        return\n",
    "\n",
    "    df = df_mlr[df_mlr['Predictor_Term'] == predictor_to_plot].copy()\n",
    "    if df.empty:\n",
    "        print(f\"[DotWhisker] No rows for {display_name}.\")\n",
    "        return\n",
    "\n",
    "    df, group_dim = _prep_for_plot(df)\n",
    "    rows_before = len(df)\n",
    "    df = df.dropna(subset=[group_dim, 'Coefficient', 'Conf_Int_Lower', 'Conf_Int_Upper', 'Symptom_Display'])\n",
    "    if df.empty:\n",
    "        print(f\"[DotWhisker] No valid rows after dropna for {display_name}.\")\n",
    "        return\n",
    "    if rows_before != len(df):\n",
    "        print(f\"[DotWhisker] Dropped {rows_before - len(df)} rows with missing values.\")\n",
    "\n",
    "    states = list(pd.unique(df['ClinicalState']))\n",
    "    groups = list(df[group_dim].cat.categories)\n",
    "    symptoms = list(df['Symptom_Display'].cat.categories)\n",
    "    colors = dict(zip(symptoms, sns.color_palette('bright', len(symptoms))))\n",
    "\n",
    "    fig, axes = plt.subplots(len(states), 1, figsize=(14, 6 + 3*len(states)), sharex=True, squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, state in enumerate(states):\n",
    "        ax = axes[i]\n",
    "        ax.set_title(state, pad=14)\n",
    "        sub = df[df['ClinicalState'] == state].copy()\n",
    "\n",
    "        x_idx = np.arange(len(groups))\n",
    "        dodge = 0.5\n",
    "        pos = np.linspace(-dodge/2, dodge/2, len(symptoms))\n",
    "\n",
    "        for s_idx, sym in enumerate(symptoms):\n",
    "            dd = sub[sub['Symptom_Display'] == sym]\n",
    "            if dd.empty:\n",
    "                continue\n",
    "            # Align x positions by category code of group_dim\n",
    "            x = dd[group_dim].cat.codes.values + pos[s_idx]\n",
    "            y = dd['Coefficient'].values\n",
    "            lo = (dd['Coefficient'] - dd['Conf_Int_Lower']).values\n",
    "            hi = (dd['Conf_Int_Upper'] - dd['Coefficient']).values\n",
    "\n",
    "            ax.errorbar(x=x, y=y, yerr=[lo, hi],\n",
    "                        fmt='o', color=colors[sym], capsize=6, markersize=8, linestyle='none',\n",
    "                        label=sym if i == 0 else None)\n",
    "\n",
    "        ax.axhline(0, ls='--', color='black', lw=1.6, zorder=0)\n",
    "        ax.set_xticks(np.arange(len(groups)))\n",
    "        ax.set_xticklabels(groups, rotation=0)\n",
    "        ax.set_ylabel(\"Coefficient (95% CI)\")\n",
    "        ax.grid(axis='y', linestyle=':', alpha=0.6)\n",
    "\n",
    "    # Legend only once\n",
    "    if symptoms:\n",
    "        handles = [plt.Line2D([0], [0], marker='o', linestyle='None', markersize=8, color=colors[s]) for s in symptoms]\n",
    "        fig.legend(handles, symptoms, title=\"Symptom\", bbox_to_anchor=(1.02, 0.92), loc='upper left')\n",
    "\n",
    "    xlbl = \"Region\" if group_dim == 'Region' else \"Channel\"\n",
    "    fig.supxlabel(xlbl)\n",
    "    fig.suptitle(f\"{display_name} Coefficients vs PKG\", y=1.02)\n",
    "    plt.tight_layout(rect=[0, 0, 0.88, 0.98])\n",
    "    plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"[DotWhisker] Saved: {output_path}\")\n",
    "\n",
    "# ------------- Plot 2: Orthogonal Value (Added R² by Exponent) -------------\n",
    "def plot_orthogonal_value_stacked_bar(df_mlr, df_lrt, output_path):\n",
    "    print(\"[Orthogonal] Building stacked bar for Added R² by Exponent...\")\n",
    "\n",
    "    # Normalize key text columns\n",
    "    def _norm(df):\n",
    "        df = df.copy()\n",
    "        for c in ['ClinicalState', 'Channel', 'Region', 'PKG_Symptom_DV', 'Model_Tier', 'Comparison']:\n",
    "            if c in df.columns:\n",
    "                df[c] = (df[c].astype('string')\n",
    "                                .str.normalize('NFKC')\n",
    "                                .str.strip()\n",
    "                                .str.replace(r'\\s+', ' ', regex=True))\n",
    "        # unify model tier labels\n",
    "\n",
    "                # unify model tier labels to match your CSV\n",
    "        if 'Model_Tier' in df.columns:\n",
    "            df['Model_Tier'] = df['Model_Tier'].replace({\n",
    "                'Tier1: Oscillatory Only': 'Tier 1: Osc Only',\n",
    "                'Tier 1: Oscillatory Only': 'Tier 1: Osc Only',\n",
    "                'Oscillatory Only': 'Tier 1: Osc Only',\n",
    "                'Osc Only': 'Tier 1: Osc Only',\n",
    "                'Tier 1: Osc Only': 'Tier 1: Osc Only',\n",
    "\n",
    "                'Tier 2: Exponent + Oscillatory': 'Tier 2: Exponent + Osc',\n",
    "                'Exponent + Osc': 'Tier 2: Exponent + Osc',\n",
    "                'Tier 2: Exponent + Osc': 'Tier 2: Exponent + Osc',\n",
    "\n",
    "                'Tier 3: Offset + Oscillatory': 'Tier 3: Offset + Osc',\n",
    "                'Offset + Osc': 'Tier 3: Offset + Osc',\n",
    "                'Tier 3: Offset + Osc': 'Tier 3: Offset + Osc',\n",
    "            })\n",
    "        return df\n",
    "    def _find_adj_r2(df):\n",
    "        for k in ['Adj_R2', 'R_squared_adj_model', 'R_squared_adj', 'AdjR2', 'R2_adj']:\n",
    "            if k in df.columns: return k\n",
    "        return None\n",
    "\n",
    "    df_mlr = _norm(df_mlr)\n",
    "    df_lrt = _norm(df_lrt)\n",
    "\n",
    "    # prefer Region grouping\n",
    "    group_dim = _pick_group_dim(df_mlr)\n",
    "    if group_dim is None:\n",
    "        print(\"[Orthogonal] No Region/Channel column in MLR results; aborting.\")\n",
    "        return\n",
    "\n",
    "    # symptom names\n",
    "    df_mlr = _apply_symptom_display(df_mlr)\n",
    "    df_mlr = _order_group_dim(df_mlr, group_dim)\n",
    "    if 'ClinicalState' not in df_mlr.columns: df_mlr['ClinicalState'] = 'Overall Results'\n",
    "    if 'ClinicalState' not in df_lrt.columns: df_lrt['ClinicalState'] = 'Overall Results'\n",
    "\n",
    "    r2col = _find_adj_r2(df_mlr)\n",
    "    if r2col is None:\n",
    "        print(f\"[Orthogonal] No adjusted R² col found in MLR results. Columns: {list(df_mlr.columns)}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    key = ['ClinicalState', group_dim, 'PKG_Symptom_DV']\n",
    "    reduced = (df_mlr[df_mlr['Model_Tier'] == 'Tier 1: Osc Only']\n",
    "               .drop_duplicates(subset=key)[key + [r2col]]\n",
    "               .rename(columns={r2col: 'R2_Reduced'}))\n",
    "\n",
    "    full_exp = (df_mlr[df_mlr['Model_Tier'] == 'Tier 2: Exponent + Osc']\n",
    "                .drop_duplicates(subset=key)[key + [r2col]]\n",
    "                .rename(columns={r2col: 'R2_Full'}))\n",
    "\n",
    "    if reduced.empty or full_exp.empty:\n",
    "        print(\"[Orthogonal] Reduced or full model rows missing.\")\n",
    "        return\n",
    "\n",
    "    df_r2 = pd.merge(reduced, full_exp, on=key, how='inner')\n",
    "    if df_r2.empty:\n",
    "        print(\"[Orthogonal] No overlap between reduced and full rows.\")\n",
    "        return\n",
    "\n",
    "    df_r2['R2_Added_by_Exponent'] = (df_r2['R2_Full'] - df_r2['R2_Reduced']).clip(lower=0)\n",
    "    df_r2['Symptom_Display'] = df_r2['PKG_Symptom_DV'].map(SYMPTOM_LEGEND_MAP).fillna(df_r2['PKG_Symptom_DV'])\n",
    "\n",
    "    # pick p-value column from LRT (Exponent + Osc vs Osc Only)\n",
    "    if 'Comparison' in df_lrt.columns:\n",
    "        mask = df_lrt['Comparison'].str.lower().str.contains('exponent') & df_lrt['Comparison'].str.contains('osc', case=False)\n",
    "        df_lrt_exp = df_lrt[mask].copy()\n",
    "    else:\n",
    "        df_lrt_exp = df_lrt.copy()\n",
    "\n",
    "    pcol = None\n",
    "    for c in ['P_value_FDR', 'P_value', 'pval', 'p_adj', 'P_FDR']:\n",
    "        if c in df_lrt_exp.columns:\n",
    "            pcol = c; break\n",
    "\n",
    "    lrt_key = ['ClinicalState', group_dim, 'PKG_Symptom_DV']\n",
    "    if pcol and not df_lrt_exp.empty:\n",
    "        df_lrt_small = df_lrt_exp[lrt_key + [pcol]].rename(columns={pcol: 'P_value_any'})\n",
    "        df_plot = pd.merge(df_r2, df_lrt_small, on=lrt_key, how='left')\n",
    "        df_plot['is_significant'] = df_plot['P_value_any'] < P_VALUE_THRESHOLD\n",
    "    else:\n",
    "        df_plot = df_r2.copy()\n",
    "        df_plot['is_significant'] = False\n",
    "\n",
    "    # categories\n",
    "    df_plot = _order_group_dim(df_plot, group_dim)\n",
    "    df_plot = _apply_symptom_display(df_plot)\n",
    "\n",
    "    # coercions\n",
    "    for c in ['R2_Full', 'R2_Reduced', 'R2_Added_by_Exponent']:\n",
    "        df_plot[c] = pd.to_numeric(df_plot[c], errors='coerce')\n",
    "    df_plot = df_plot.dropna(subset=[group_dim, 'Symptom_Display', 'R2_Full', 'R2_Reduced'])\n",
    "    if df_plot.empty:\n",
    "        print(\"[Orthogonal] Nothing to plot after cleaning.\")\n",
    "        return\n",
    "\n",
    "    # facet per clinical state\n",
    "    states = list(pd.unique(df_plot['ClinicalState']))\n",
    "    groups = list(df_plot[group_dim].cat.categories)\n",
    "    symptoms = list(pd.Categorical(df_plot['Symptom_Display']).categories)\n",
    "\n",
    "    g = sns.FacetGrid(df_plot, col='ClinicalState', col_wrap=2, height=6.2, aspect=1.6, sharey=True)\n",
    "    custom_palette = {\n",
    "    'Bradykinesia': '#b0b0b0',   # light grey\n",
    "    'Dyskinesia':  '#707070',    # dark grey\n",
    "    # 'Tremor': '#404040'         # optional\n",
    "    }\n",
    "    # base bars: reduced\n",
    "    g.map_dataframe(\n",
    "        sns.barplot, x=group_dim, y='R2_Reduced', hue='Symptom_Display',\n",
    "        palette=custom_palette, dodge=0.8, errorbar=None, alpha=0.55, zorder=1,\n",
    "        order=groups, hue_order=symptoms\n",
    "    )\n",
    "\n",
    "    # add colored hatched cap = Added R² by exponent\n",
    "    palette = sns.color_palette('viridis', len(symptoms))\n",
    "    for ax, state_name in zip(g.axes.flat, g.col_names):\n",
    "        sub = df_plot[df_plot['ClinicalState'] == state_name]\n",
    "        # compose in the same hue/channel order as seaborn created bars\n",
    "        added, total, sigs = [], [], []\n",
    "        for grp in groups:\n",
    "            for sym in symptoms:\n",
    "                row = sub[(sub[group_dim] == grp) & (sub['Symptom_Display'] == sym)]\n",
    "                if not row.empty:\n",
    "                    added.append(float(row['R2_Added_by_Exponent'].iloc[0]))\n",
    "                    total.append(float(row['R2_Full'].iloc[0]))\n",
    "                    sigs.append(bool(row['is_significant'].iloc[0]))\n",
    "                else:\n",
    "                    added.append(0.0); total.append(0.0); sigs.append(False)\n",
    "\n",
    "        patches = [p for p in ax.patches]  # one per base bar\n",
    "        for idx, p in enumerate(patches):\n",
    "            if idx >= len(added): break\n",
    "            h_add = added[idx]\n",
    "            if h_add > 0:\n",
    "                sym_idx = idx % len(symptoms)\n",
    "                ax.bar(\n",
    "                    p.get_x() + p.get_width()/2, h_add, width=p.get_width(),\n",
    "                    bottom=p.get_height(), align='center',\n",
    "                    color=palette[sym_idx], hatch='///', linewidth=0, zorder=2\n",
    "                )\n",
    "        # mark significance at total height\n",
    "        for idx, p in enumerate(patches):\n",
    "            if idx >= len(sigs): break\n",
    "            if sigs[idx]:\n",
    "                ax.text(p.get_x() + p.get_width()/2, total[idx] + 0.01, '*',\n",
    "                        ha='center', va='bottom', fontsize=14 * font_scale_factor)\n",
    "\n",
    "        ax.set_xticklabels(groups, rotation=0)\n",
    "        ax.set_ylabel(\"Adjusted R-squared\")\n",
    "        ax.grid(axis='y', linestyle=':', alpha=0.6)\n",
    "\n",
    "    # legends\n",
    "    g.add_legend(title=\"Symptom Score\")\n",
    "    pattern_legend = [Patch(facecolor='lightgray', alpha=0.55, label='Reduced (Osc-only)'),\n",
    "                      Patch(facecolor='white', edgecolor='black', hatch='///', label='Added by Exponent')]\n",
    "    g.fig.legend(handles=pattern_legend,\n",
    "                 labels=[h.get_label() for h in pattern_legend],\n",
    "                 loc='upper left', bbox_to_anchor=(0.88, 0.92))\n",
    "\n",
    "    g.set_titles(\"{col_name}\", pad=14)\n",
    "    g.fig.suptitle(\"Orthogonal Value of Exponent (Added R²)\", y=1.02)\n",
    "    g.fig.tight_layout(rect=[0, 0, 0.96, 0.98])\n",
    "\n",
    "    # Also dump a CSV of exactly what was plotted (handy to audit)\n",
    "    try:\n",
    "        out_csv = os.path.splitext(output_path)[0] + \"_VALUES.csv\"\n",
    "        dump_cols = ['ClinicalState', group_dim, 'Symptom_Display', 'R2_Reduced', 'R2_Full', 'R2_Added_by_Exponent']\n",
    "        if 'P_value_any' in df_plot.columns: dump_cols.append('P_value_any')\n",
    "        if 'is_significant' in df_plot.columns: dump_cols.append('is_significant')\n",
    "        df_plot.sort_values(['ClinicalState', group_dim, 'Symptom_Display']).to_csv(out_csv, index=False)\n",
    "        print(f\"[Orthogonal] Values CSV saved: {out_csv}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Orthogonal] Could not write values CSV: {e}\")\n",
    "\n",
    "    plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"[Orthogonal] Saved: {output_path}\")\n",
    "\n",
    "# ---------------------------- Runner ----------------------------\n",
    "def run_visualizations(analysis_type, results_dir, mlr_filename, lrt_filename, output_dir):\n",
    "    print(f\"\\n{'='*18}\\nGenerating {analysis_type} plots\\n{'='*18}\")\n",
    "    mlr_path = os.path.join(results_dir, mlr_filename)\n",
    "    lrt_path = os.path.join(results_dir, lrt_filename)\n",
    "\n",
    "    try:\n",
    "        df_mlr = pd.read_csv(mlr_path)\n",
    "        df_lrt = pd.read_csv(lrt_path)\n",
    "\n",
    "        # 'PKG Tremor Score': 'Tremor',\n",
    "        if EXCLUDE_TREMOR:\n",
    "            if 'PKG_Symptom_DV' in df_mlr.columns:\n",
    "                df_mlr = df_mlr[~df_mlr['PKG_Symptom_DV'].isin(TREMOR_LABELS)]\n",
    "            if 'PKG_Symptom_DV' in df_lrt.columns:\n",
    "                df_lrt = df_lrt[~df_lrt['PKG_Symptom_DV'].isin(TREMOR_LABELS)]\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"SKIP {analysis_type}: Missing file: {e.filename}\")\n",
    "        return\n",
    "\n",
    "    # Quick sanity\n",
    "    print(f\"[{analysis_type}] MLR cols: {list(df_mlr.columns)[:8]} ...\")\n",
    "    print(f\"[{analysis_type}] LRT cols: {list(df_lrt.columns)[:8]} ...\")\n",
    "\n",
    "    # Dot–whisker for Exponent / Offset (only if present)\n",
    "    if 'Predictor_Term' in df_mlr.columns and 'Coefficient' in df_mlr.columns:\n",
    "        exp_out = os.path.join(output_dir, f\"{patient_hemisphere_id}_{analysis_type}_Exponent_Coefficients.png\")\n",
    "        off_out = os.path.join(output_dir, f\"{patient_hemisphere_id}_{analysis_type}_Offset_Coefficients.png\")\n",
    "        plot_coefficient_dot_whisker(df_mlr, 'Exponent_BestModel', exp_out)\n",
    "        plot_coefficient_dot_whisker(df_mlr, 'Offset_BestModel',   off_out)\n",
    "    else:\n",
    "        print(f\"[{analysis_type}] No coefficient rows found; skipping dot–whisker plots.\")\n",
    "\n",
    "    # Orthogonal Added R² plot (Exponent)\n",
    "    ortho_out = os.path.join(output_dir, f\"{patient_hemisphere_id}_{analysis_type}_Orthogonal_Value.png\")\n",
    "    plot_orthogonal_value_stacked_bar(df_mlr, df_lrt, ortho_out)\n",
    "\n",
    "# ---------------------------- Main --------------------------------\n",
    "if __name__ == \"__main__\" and 'patient_hemisphere_id' in locals():\n",
    "    # --- Global (Cell 6) results ---\n",
    "    global_dir = os.path.join(analysis_session_plot_folder_step4, \"MLR_byRegion_V4\")\n",
    "    global_mlr_file = f\"{patient_hemisphere_id}_MLR_Coefficients_byRegion_Step6.csv\"\n",
    "    global_lrt_file = f\"{patient_hemisphere_id}_MLR_LRT_Results_byRegion_Step6.csv\"\n",
    "    os.makedirs(global_dir, exist_ok=True)\n",
    "    run_visualizations(\"Global\", global_dir, global_mlr_file, global_lrt_file, global_dir)\n",
    "\n",
    "\n",
    "    # --- State-specific (Cell 6A) results ---\n",
    "    # Prefer by-Region 6A outputs if you used the region-level 6A I provided.\n",
    "    state_dir_candidates = [\n",
    "        os.path.join(STATE_SPECIFIC_ANALYSIS_DIR, \"MLR_State_Specific_byRegion_FDR\"),     # region-level 6A (recommended)\n",
    "        os.path.join(STATE_SPECIFIC_ANALYSIS_DIR, \"MultipleLinearRegression_State_Specific_FDR\")  # fallback if you ran the older 6A\n",
    "    ]\n",
    "    for state_dir in state_dir_candidates:\n",
    "        if os.path.isdir(state_dir):\n",
    "            # Region-level file names (first), else older ones\n",
    "            mlr_files = [\n",
    "                f\"{patient_hemisphere_id}_MLR_StateSpecific_byRegion_ModelCoeffs_Step6A.csv\",\n",
    "                f\"{patient_hemisphere_id}_MLR_StateSpecific_Results_Step6A.csv\"\n",
    "            ]\n",
    "            lrt_files = [\n",
    "                f\"{patient_hemisphere_id}_MLR_LRT_StateSpecific_byRegion_Results_FDR_Step6A.csv\",\n",
    "                f\"{patient_hemisphere_id}_MLR_LRT_StateSpecific_Results_FDR_Step6A.csv\"\n",
    "            ]\n",
    "            mlr_found = next((f for f in mlr_files if os.path.exists(os.path.join(state_dir, f))), None)\n",
    "            lrt_found = next((f for f in lrt_files if os.path.exists(os.path.join(state_dir, f))), None)\n",
    "            if mlr_found and lrt_found:\n",
    "                run_visualizations(\"StateSpecific\", state_dir, mlr_found, lrt_found, state_dir)\n",
    "                break\n",
    "    else:\n",
    "        print(\"SKIP StateSpecific: No state-specific results directory with expected files was found.\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping plot generation because __main__ guard did not pass or key variables are missing.\")\n",
    "\n",
    "print(\"\\n--- Cell 7 (Region-first): Visualizations Complete ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47f5ed7c-6393-4f0b-aa74-8ba60845f8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 8 (Region-first): Starting Curated Visualization (STN vs M1) ---\n",
      "\n",
      "Region column found — generating STN vs M1 plots (no contact selection).\n",
      "\n",
      "Generating Curated Dot-and-Whisker: 'Exponent' (Region)…\n",
      "Saved plot to: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/MLR_byRegion_V4/Curated_Result_Plots/COHORT_RCS02_05_06_Curated_Exponent_Coefficients_REGION.png\n",
      "\n",
      "Generating Curated Dot-and-Whisker: 'Offset' (Region)…\n",
      "Saved plot to: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/MLR_byRegion_V4/Curated_Result_Plots/COHORT_RCS02_05_06_Curated_Offset_Coefficients_REGION.png\n",
      "Generating Curated Stacked Bar (Added R² by Exponent)…\n",
      "Saved plot to: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/MLR_byRegion_V4/Curated_Result_Plots/COHORT_RCS02_05_06_Curated_Orthogonal_Value_REGION.png\n",
      "\n",
      "--- Cell 8 (Region-first): Complete. 'user_selections' saved. ---\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 8 (Region-first & Safe Fallback): Curated Visualization (STN vs M1 only) ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\n--- Cell 8 (Region-first): Starting Curated Visualization (STN vs M1) ---\\n\")\n",
    "\n",
    "# --- Global Font / Style ---\n",
    "font_scale_factor = 3\n",
    "plt.rcParams.update({\n",
    "    'font.size': 10 * font_scale_factor, 'axes.labelsize': 10 * font_scale_factor,\n",
    "    'axes.titlesize': 12 * font_scale_factor, 'xtick.labelsize': 10 * font_scale_factor,\n",
    "    'ytick.labelsize': 8 * font_scale_factor, 'legend.fontsize': 9 * font_scale_factor,\n",
    "    'legend.title_fontsize': 10 * font_scale_factor,\n",
    "})\n",
    "P_VALUE_THRESHOLD = 0.05\n",
    "\n",
    "REGION_ORDER = ['STN', 'M1']\n",
    "CHANNEL_GROUP_MAP = {\n",
    "    'STN': ['Contact_2_0', 'Contact_3_0', 'Contact_3_1'],\n",
    "    'M1':  ['Contact_10_8', 'Contact_11_9']\n",
    "}\n",
    "\n",
    "SYMPTOM_ORDER = ['PKG BK Score', 'PKG DK Score', 'PKG Tremor Score']\n",
    "SYMPTOM_LEGEND_MAP = {\n",
    "    'PKG BK Score': 'Bradykinesia',\n",
    "    'PKG DK Score': 'Dyskinesia',\n",
    "    # 'PKG Tremor Score': 'Tremor'\n",
    "}\n",
    "SYMPTOM_DISPLAY_ORDER = ['Bradykinesia', 'Dyskinesia']#, 'Tremor']\n",
    "\n",
    "def _pick_p_col(df, prefer_fdr=True):\n",
    "    candidates_fdr = ['P_value_FDR', 'P_FDR', 'p_adj', 'p_fdr']\n",
    "    candidates_raw = ['P_value', 'p_value', 'pval', 'P']\n",
    "    if prefer_fdr:\n",
    "        for c in candidates_fdr:\n",
    "            if c in df.columns: return c\n",
    "    for c in candidates_raw:\n",
    "        if c in df.columns: return c\n",
    "    return None\n",
    "\n",
    "# ---------- Plotters ----------\n",
    "def plot_curated_coefficients(df_plot, predictor_to_plot, output_path):\n",
    "    predictor_name_map = {'Exponent_BestModel': 'Exponent', 'Offset_BestModel': 'Offset'}\n",
    "    predictor_display_name = predictor_name_map.get(predictor_to_plot, predictor_to_plot)\n",
    "    print(f\"\\nGenerating Curated Dot-and-Whisker: '{predictor_display_name}' (Region)…\")\n",
    "\n",
    "    req = {'Coefficient','Conf_Int_Lower','Conf_Int_Upper','Predictor_Term','Symptom_Display','Region'}\n",
    "    if not req.issubset(df_plot.columns):\n",
    "        print(f\"Missing columns for coefficient plot: {sorted(list(req - set(df_plot.columns)))}\")\n",
    "        return\n",
    "\n",
    "    df_plot = df_plot[df_plot['Predictor_Term'] == predictor_to_plot].copy()\n",
    "    if df_plot.empty:\n",
    "        print(\"No data to plot. Skipping.\")\n",
    "        return\n",
    "\n",
    "    df_plot['Symptom_Display'] = pd.Categorical(df_plot['Symptom_Display'],\n",
    "                                                categories=SYMPTOM_DISPLAY_ORDER, ordered=True)\n",
    "    cats = [r for r in REGION_ORDER if r in df_plot['Region'].unique()]\n",
    "    if not cats: cats = sorted(df_plot['Region'].dropna().unique().tolist())\n",
    "    df_plot['Region'] = pd.Categorical(df_plot['Region'], categories=cats, ordered=True)\n",
    "    df_plot = df_plot.sort_values(['Region','Symptom_Display'])\n",
    "\n",
    "    regions = list(df_plot['Region'].cat.categories)\n",
    "    symptoms = list(df_plot['Symptom_Display'].cat.categories)\n",
    "    symptom_colors = dict(zip(symptoms, sns.color_palette('bright', len(symptoms))))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    idx = np.arange(len(regions))\n",
    "    dodge = 0.4\n",
    "    pos = np.linspace(-dodge/2, dodge/2, len(symptoms))\n",
    "\n",
    "    for s_i, sym in enumerate(symptoms):\n",
    "        sub = df_plot[df_plot['Symptom_Display']==sym]\n",
    "        if sub.empty: continue\n",
    "        x = sub['Region'].cat.codes.values + pos[s_i]\n",
    "        y = sub['Coefficient'].values\n",
    "        lo = (sub['Coefficient'] - sub['Conf_Int_Lower']).values\n",
    "        hi = (sub['Conf_Int_Upper'] - sub['Coefficient']).values\n",
    "        ax.errorbar(x=x, y=y, yerr=[lo, hi], fmt='o',\n",
    "                    color=symptom_colors[sym], label=sym,\n",
    "                    capsize=8, markersize=14, linestyle='none',\n",
    "                    linewidth=2.5, markeredgewidth=2.5)\n",
    "\n",
    "    ax.axhline(0, ls='--', color='black', lw=2, zorder=0)\n",
    "    ax.set_xticks(idx); ax.set_xticklabels(regions)\n",
    "    ax.set_ylabel(\"Regression Coefficient (95% CI)\")\n",
    "    ax.grid(axis='y', linestyle=':', alpha=0.7)\n",
    "    fig.legend(title=\"Symptom Score\", bbox_to_anchor=(1.02, 0.9), loc='upper left')\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "    plt.savefig(output_path, bbox_inches='tight'); plt.close()\n",
    "    print(f\"Saved plot to: {output_path}\")\n",
    "\n",
    "def plot_curated_orthogonal_value(df_plot, output_path):\n",
    "    \"\"\"\n",
    "    Curated stacked bar: base = R2_Reduced, hatched cap = R2_Added_by_Exponent,\n",
    "    significance star at total height (R2_Full) if LRT p < alpha.\n",
    "    \"\"\"\n",
    "    print(\"Generating Curated Stacked Bar (Added R² by Exponent)…\")\n",
    "\n",
    "    if df_plot is None or df_plot.empty:\n",
    "        print(\"No data to plot. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Expect columns\n",
    "    need = {'Region','Symptom_Display','R2_Reduced','R2_Full','R2_Added_by_Exponent','is_significant'}\n",
    "    missing = sorted(list(need - set(df_plot.columns)))\n",
    "    if missing:\n",
    "        print(f\"Missing columns for orthogonal plot: {missing}\")\n",
    "        return\n",
    "\n",
    "    df_plot = df_plot.copy()\n",
    "\n",
    "    # ---- Coerce numeric (in case they came in as strings) ----\n",
    "    for c in ['R2_Reduced','R2_Full','R2_Added_by_Exponent']:\n",
    "        df_plot[c] = pd.to_numeric(df_plot[c], errors='coerce')\n",
    "    df_plot = df_plot.dropna(subset=['Region','Symptom_Display','R2_Reduced','R2_Full'])\n",
    "    if df_plot.empty:\n",
    "        print(\"Nothing to plot after cleaning.\")\n",
    "        return\n",
    "\n",
    "    # ---- Ensure categorical dtypes & ordering BEFORE plotting ----\n",
    "    # Symptom order\n",
    "    present_sym = [s for s in SYMPTOM_DISPLAY_ORDER if s in df_plot['Symptom_Display'].unique()]\n",
    "    if not present_sym:  # fallback to alphabetical if none match expected order\n",
    "        present_sym = sorted(df_plot['Symptom_Display'].dropna().unique().tolist())\n",
    "    df_plot['Symptom_Display'] = pd.Categorical(df_plot['Symptom_Display'],\n",
    "                                                categories=present_sym, ordered=True)\n",
    "\n",
    "    # Region order\n",
    "    present_reg = [r for r in REGION_ORDER if r in df_plot['Region'].unique()]\n",
    "    if not present_reg:\n",
    "        present_reg = sorted(df_plot['Region'].dropna().unique().tolist())\n",
    "    df_plot['Region'] = pd.Categorical(df_plot['Region'],\n",
    "                                       categories=present_reg, ordered=True)\n",
    "\n",
    "    # Sort for tidy seaborn drawing\n",
    "    df_plot = df_plot.sort_values(['Region','Symptom_Display'])\n",
    "\n",
    "    # ---- Plot ----\n",
    "    # bright = sns.color_palette('bright', 3)\n",
    "    # symptom_colors = {'Bradykinesia': bright[0], 'Dyskinesia': bright[1], 'Tremor': bright[2]}\n",
    "    # Clearer greys for stacked bars\n",
    "    symptom_colors = {\n",
    "        'Bradykinesia': '#b0b0b0',  # light grey\n",
    "        'Dyskinesia':  '#707070',   # darker grey\n",
    "        # 'Tremor': '#404040'        # (keep only if tremor is reintroduced)\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "    custom_palette = {\n",
    "    'Bradykinesia': '#b0b0b0',   # light grey\n",
    "    'Dyskinesia':  '#707070',    # dark grey\n",
    "    # 'Tremor': '#404040'         # optional\n",
    "    }\n",
    "    # Base (reduced): grayscale bars\n",
    "    sns.barplot(\n",
    "        data=df_plot, x='Region', y='R2_Reduced', hue='Symptom_Display',\n",
    "        palette=custom_palette, dodge=0.8, errorbar=None, ax=ax, alpha=0.55, legend=False,\n",
    "        order=list(df_plot['Region'].cat.categories),\n",
    "        hue_order=list(df_plot['Symptom_Display'].cat.categories)\n",
    "    )\n",
    "\n",
    "    regions = list(df_plot['Region'].cat.categories)\n",
    "    symptoms = list(df_plot['Symptom_Display'].cat.categories)\n",
    "\n",
    "    # Build arrays aligned to seaborn's (region major, symptom minor)\n",
    "    added_heights, totals, sigs = [], [], []\n",
    "    for reg in regions:\n",
    "        for sym in symptoms:\n",
    "            row = df_plot[(df_plot['Region']==reg) & (df_plot['Symptom_Display']==sym)]\n",
    "            if not row.empty:\n",
    "                added_heights.append(float(row['R2_Added_by_Exponent'].iloc[0]))\n",
    "                totals.append(float(row['R2_Full'].iloc[0]))\n",
    "                sigs.append(bool(row['is_significant'].iloc[0]))\n",
    "            else:\n",
    "                added_heights.append(0.0); totals.append(0.0); sigs.append(False)\n",
    "\n",
    "    # Hatch caps on top of base bars\n",
    "    patches = [p for p in ax.patches]  # one per base bar\n",
    "    for idx, p in enumerate(patches):\n",
    "        if idx >= len(added_heights): break\n",
    "        h_add = added_heights[idx]\n",
    "        if h_add > 0:\n",
    "            sym_idx = idx % len(symptoms)\n",
    "            ax.bar(\n",
    "                p.get_x() + p.get_width()/2, h_add, width=p.get_width(),\n",
    "                bottom=p.get_height(), align='center',\n",
    "                color=symptom_colors.get(symptoms[sym_idx], 'C0'),\n",
    "                hatch='///', linewidth=0, zorder=2\n",
    "            )\n",
    "\n",
    "    # Significance stars at total height (R2_Full)\n",
    "    for idx, p in enumerate(patches):\n",
    "        if idx >= len(sigs): break\n",
    "        if sigs[idx]:\n",
    "            ax.text(\n",
    "                p.get_x() + p.get_width()/2, totals[idx] + 0.005, '*',\n",
    "                ha='center', va='bottom', color='red',\n",
    "                fontsize=18 * font_scale_factor, zorder=3\n",
    "            )\n",
    "\n",
    "    ax.set_ylabel(\"Adjusted R-squared\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.grid(axis='y', linestyle=':', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved plot to: {output_path}\")\n",
    "\n",
    "\n",
    "# ---------- Main ----------\n",
    "def run_curated_visualizations(results_dir, mlr_filename, lrt_filename, output_dir):\n",
    "    try:\n",
    "        df_mlr = pd.read_csv(os.path.join(results_dir, mlr_filename))\n",
    "        df_lrt = pd.read_csv(os.path.join(results_dir, lrt_filename))\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"SKIPPING: Missing file: {e.filename}. Run Cell 6/6A first.\")\n",
    "        return None\n",
    "    if EXCLUDE_TREMOR:\n",
    "        for _df in (df_mlr, df_lrt):\n",
    "            if 'PKG_Symptom_DV' in _df.columns:\n",
    "                _df.drop(_df[_df['PKG_Symptom_DV'].isin(TREMOR_LABELS)].index, inplace=True)\n",
    "\n",
    "    # REGION BRANCH\n",
    "    if 'Region' in df_mlr.columns and df_mlr['Region'].notna().any():\n",
    "        print(\"Region column found — generating STN vs M1 plots (no contact selection).\")\n",
    "        df_coeff = df_mlr.copy()\n",
    "        df_coeff['Symptom_Display'] = df_coeff['PKG_Symptom_DV'].map(SYMPTOM_LEGEND_MAP)\n",
    "\n",
    "        r2_col = None\n",
    "        for c in ['R_squared_adj_model','R_squared_adj','Adj_R2','R2_adj','AdjR2']:\n",
    "            if c in df_mlr.columns: r2_col = c; break\n",
    "        if r2_col is None:\n",
    "            print(\"No adjusted R² col; skipping orthogonal plot.\")\n",
    "            return None\n",
    "\n",
    "        key = ['Region','PKG_Symptom_DV']\n",
    "        reduced = (df_mlr[df_mlr.get('Model_Tier','')=='Tier 1: Osc Only']\n",
    "                   .drop_duplicates(subset=key)[key+[r2_col]].rename(columns={r2_col:'R2_Reduced'}))\n",
    "        full = (df_mlr[df_mlr.get('Model_Tier','')=='Tier 2: Exponent + Osc']\n",
    "                .drop_duplicates(subset=key)[key+[r2_col]].rename(columns={r2_col:'R2_Full'}))\n",
    "        df_r2 = pd.merge(reduced, full, on=key, how='inner')\n",
    "        df_r2['Symptom_Display'] = df_r2['PKG_Symptom_DV'].map(SYMPTOM_LEGEND_MAP)\n",
    "        df_r2['R2_Added_by_Exponent'] = (df_r2['R2_Full'] - df_r2['R2_Reduced']).clip(lower=0)\n",
    "\n",
    "        pcol = _pick_p_col(df_lrt, prefer_fdr=True)\n",
    "        if pcol and 'Comparison' in df_lrt.columns:\n",
    "            mask = df_lrt['Comparison'].astype(str).str.lower().str.contains('exponent') & \\\n",
    "                   df_lrt['Comparison'].astype(str).str.lower().str.contains('osc')\n",
    "            lrt_small = df_lrt.loc[mask, ['Region','PKG_Symptom_DV', pcol]].rename(columns={pcol:'P_any'})\n",
    "            df_ortho = pd.merge(df_r2, lrt_small, on=['Region','PKG_Symptom_DV'], how='left')\n",
    "        else:\n",
    "            df_ortho = df_r2.copy(); df_ortho['P_any'] = np.nan\n",
    "        df_ortho['is_significant'] = df_ortho['P_any'] < P_VALUE_THRESHOLD\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        plot_curated_coefficients(df_coeff, 'Exponent_BestModel',\n",
    "                                  os.path.join(output_dir, f\"{patient_hemisphere_id}_Curated_Exponent_Coefficients_REGION.png\"))\n",
    "        plot_curated_coefficients(df_coeff, 'Offset_BestModel',\n",
    "                                  os.path.join(output_dir, f\"{patient_hemisphere_id}_Curated_Offset_Coefficients_REGION.png\"))\n",
    "        plot_curated_orthogonal_value(df_ortho,\n",
    "                                  os.path.join(output_dir, f\"{patient_hemisphere_id}_Curated_Orthogonal_Value_REGION.png\"))\n",
    "        return {'mode': 'region', 'selections': None}\n",
    "\n",
    "    # CONTACT FALLBACK\n",
    "    print(\"Region not found — falling back to contact-level selection (plots still STN vs M1).\")\n",
    "    return None\n",
    "\n",
    "# ---------- Execute ----------\n",
    "if __name__ == \"__main__\" and 'patient_hemisphere_id' in locals():\n",
    "    global_results_dir = os.path.join(analysis_session_plot_folder_step4, \"MLR_byRegion_V4\")\n",
    "    global_mlr_file = f\"{patient_hemisphere_id}_MLR_Coefficients_byRegion_Step6.csv\"\n",
    "    global_lrt_file = f\"{patient_hemisphere_id}_MLR_LRT_Results_byRegion_Step6.csv\"\n",
    "    curated_output_dir = os.path.join(global_results_dir, \"Curated_Result_Plots\")\n",
    "    os.makedirs(curated_output_dir, exist_ok=True)\n",
    "\n",
    "    user_selections = run_curated_visualizations(global_results_dir, global_mlr_file, global_lrt_file, curated_output_dir)\n",
    "\n",
    "    if user_selections is not None:\n",
    "        print(\"\\n--- Cell 8 (Region-first): Complete. 'user_selections' saved. ---\")\n",
    "    else:\n",
    "        print(\"\\n--- Cell 8 (Region-first): Finished with no selections saved. ---\")\n",
    "else:\n",
    "    print(\"Skipping plot generation as script is not being run directly or key variables are missing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba0003ad-f6f8-493b-9fdd-918ee43a7665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 9 (Revised V3, Region-first): Generating Exponent Box Plots with Median CIs ---\n",
      "  Plots will be saved to: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/Exponent_BoxPlots_with_MedianCI_REGION\n",
      "  Grouping by: Region\n",
      "  LowFreq: removed 554 outliers (5.5%) via IQR per (Region×State).\n",
      "  MidFreq: removed 73 outliers (0.7%) via IQR per (Region×State).\n",
      "  WideFreq: removed 209 outliers (2.1%) via IQR per (Region×State).\n",
      "  Saved medians/CI table to: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/Exponent_BoxPlots_with_MedianCI_REGION/COHORT_RCS02_05_06_Cell9_Medians_CI_by_Region.csv\n",
      "  Saved Kruskal–Wallis summary to: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044/Exponent_BoxPlots_with_MedianCI_REGION/COHORT_RCS02_05_06_Cell9_Kruskal_by_Region.csv\n",
      "\n",
      "--- Cell 9 (Revised V3, Region-first): Completed. ---\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 9 (Revised V3, Region-first): Individual Box Plots with Bootstrapped Median CIs ---\n",
    "# Improvements:\n",
    "# • Region-first (STN vs M1); falls back to per-contact if Region cannot be derived\n",
    "# • IQR outlier filtering per (Group × State)\n",
    "# • Bootstrapped 95% CI for the median overlaid on each box\n",
    "# • Optional Kruskal–Wallis across states (per group) + CSV exports\n",
    "\n",
    "print(\"\\n--- Cell 9 (Revised V3, Region-first): Generating Exponent Box Plots with Median CIs ---\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "from scipy.stats import kruskal\n",
    "import scikit_posthocs as sp\n",
    "import warnings\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in scalar divide\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Confidence interval might not be reliable for bootstrap samples with fewer than 50 elements.\")\n",
    "\n",
    "P_VALUE_THRESHOLD = 0.05\n",
    "MIN_SAMPLES_FOR_GROUP_COMPARISON = 5\n",
    "\n",
    "# Columns / labels from earlier cells\n",
    "CLINICAL_STATE_COL   = 'Clinical_State_2min_Window'\n",
    "CHANNEL_DISPLAY_COL  = 'Channel_Display'\n",
    "FOOOF_FREQ_BAND_COL  = 'FreqRangeLabel'\n",
    "AP_COL               = 'Exponent_BestModel'   # aperiodic exponent column\n",
    "AP_LABEL             = 'Aperiodic Exponent'\n",
    "\n",
    "ORDERED_FREQ_LABELS = [\"LowFreq\", \"MidFreq\", \"WideFreq\"]\n",
    "CELL9_TARGET_STATES_ORDERED = [\"Sleep\", \"Immobile\", \"Non-Dyskinetic Mobile\", \"Transitional Mobile\", \"Dyskinetic Mobile\"]\n",
    "CELL9_STATE_COLORS = {\n",
    "    'Sleep': '#4169E1', 'Immobile': '#40E0D0', 'Non-Dyskinetic Mobile': '#32CD32',\n",
    "    'Transitional Mobile': '#FFD700', 'Dyskinetic Mobile': '#FF6347'\n",
    "}\n",
    "\n",
    "# Region mapping (contact -> region)\n",
    "CONTACT_TO_REGION = {\n",
    "    'Contact_2_0': 'STN', 'Contact_3_0': 'STN', 'Contact_3_1': 'STN',\n",
    "    'STN_DBS_2-0': 'STN', 'STN_DBS_3-1': 'STN',\n",
    "    'Contact_10_8': 'M1', 'Contact_11_9': 'M1',\n",
    "    'Cortical_ECoG_10-8': 'M1', 'Cortical_ECoG_11-9': 'M1',\n",
    "}\n",
    "REGION_ORDER = ['STN', 'M1']\n",
    "\n",
    "# Short tick labels for states\n",
    "STATE_TICK_SHORT = {\n",
    "    \"Sleep\": \"Sleep\", \"Immobile\": \"Imm\", \"Non-Dyskinetic Mobile\": \"NDM\",\n",
    "    \"Transitional Mobile\": \"TM\", \"Dyskinetic Mobile\": \"DM\"\n",
    "}\n",
    "\n",
    "# --- Plot style (bigger but readable) ---\n",
    "plt.rcParams.update({\n",
    "    'font.size': 18, 'axes.labelsize': 20, 'axes.titlesize': 22,\n",
    "    'xtick.labelsize': 16, 'ytick.labelsize': 16, 'legend.fontsize': 16,\n",
    "    'legend.title_fontsize': 16,\n",
    "})\n",
    "BOX_FILL_ALPHA = 0.7\n",
    "BOXPLOT_LINE_THICKNESS = 2.0\n",
    "DOT_ALPHA = 0.5\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def bootstrap_median_ci(data, n_boot=2000, ci=0.95, random_state=None):\n",
    "    \"\"\"Bootstrap CI for the median. Returns (median, ci_low, ci_high).\"\"\"\n",
    "    x = np.asarray(data, dtype=float)\n",
    "    x = x[~np.isnan(x)]\n",
    "    if x.size < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    boot = np.median(rng.choice(x, size=(n_boot, x.size), replace=True), axis=1)\n",
    "    lo = np.percentile(boot, (1-ci)/2 * 100.0)\n",
    "    hi = np.percentile(boot, (1+ci)/2 * 100.0)\n",
    "    return float(np.median(x)), float(lo), float(hi)\n",
    "\n",
    "def filter_outliers_iqr_per_group(df, group_cols, value_col, factor=1.5):\n",
    "    \"\"\"\n",
    "    IQR outlier filtering applied per unique combination in group_cols.\n",
    "    Returns filtered df and number of removed points.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    removed = 0\n",
    "    def _clip_group(g):\n",
    "        nonlocal removed\n",
    "        v = g[value_col]\n",
    "        q1, q3 = v.quantile(0.25), v.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lo, hi = q1 - factor*iqr, q3 + factor*iqr\n",
    "        mask = (v < lo) | (v > hi)\n",
    "        removed += int(mask.sum())\n",
    "        g.loc[mask, value_col] = np.nan\n",
    "        return g\n",
    "\n",
    "    df = df.groupby(group_cols, dropna=False, as_index=False, group_keys=False).apply(_clip_group)\n",
    "    # drop after marking\n",
    "    df = df.dropna(subset=[value_col])\n",
    "    return df, removed\n",
    "\n",
    "def ensure_categorical(df, col, order=None):\n",
    "    df = df.copy()\n",
    "    if order:\n",
    "        present = [c for c in order if c in df[col].dropna().unique()]\n",
    "        if not present:\n",
    "            present = sorted(df[col].dropna().unique().tolist())\n",
    "        df[col] = pd.Categorical(df[col], categories=present, ordered=True)\n",
    "    else:\n",
    "        if not pd.api.types.is_categorical_dtype(df[col]):\n",
    "            df[col] = pd.Categorical(df[col])\n",
    "    return df\n",
    "\n",
    "# ---------------- Data prep ----------------\n",
    "if 'master_df_step4' not in locals() or master_df_step4 is None or master_df_step4.empty:\n",
    "    print(\"ERROR: master_df_step4 is not available. Please run previous cells.\")\n",
    "else:\n",
    "    df0 = master_df_step4.copy()\n",
    "\n",
    "    # Restrict to target states (keep order)\n",
    "    df0 = df0[df0[CLINICAL_STATE_COL].isin(CELL9_TARGET_STATES_ORDERED)].copy()\n",
    "\n",
    "    # Derive Region (if not already present)\n",
    "    if 'Region' not in df0.columns:\n",
    "        # Start from Channel_Display when possible\n",
    "        if CHANNEL_DISPLAY_COL in df0.columns:\n",
    "            df0['Region'] = df0[CHANNEL_DISPLAY_COL].map(CONTACT_TO_REGION)\n",
    "        else:\n",
    "            df0['Region'] = np.nan\n",
    "\n",
    "    # If Region is still missing for some rows, try 'Contact' column if you have it\n",
    "    if df0['Region'].isna().any() and 'Contact' in df0.columns:\n",
    "        df0.loc[df0['Region'].isna(), 'Region'] = df0.loc[df0['Region'].isna(), 'Contact'].map(CONTACT_TO_REGION)\n",
    "\n",
    "    # Build output folder\n",
    "    plot_dir = os.path.join(analysis_session_plot_folder_step4, \"Exponent_BoxPlots_with_MedianCI_REGION\")\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    print(f\"  Plots will be saved to: {plot_dir}\")\n",
    "\n",
    "    # 10-min timestamp for optional point overlay\n",
    "    if 'datetime_for_avg' not in df0.columns and 'Aligned_PKG_UnixTimestamp' in df0.columns:\n",
    "        df0['datetime_for_avg'] = pd.to_datetime(df0['Aligned_PKG_UnixTimestamp'], unit='s', utc=True, errors='coerce')\n",
    "\n",
    "    # Collect stats for CSVs\n",
    "    summary_rows = []\n",
    "    kw_rows = []\n",
    "\n",
    "    # ---------------- Main loop (Region-first; falls back to Channel if Region is all NaN) ---------------\n",
    "    group_dim = 'Region' if ('Region' in df0.columns and df0['Region'].notna().any()) else CHANNEL_DISPLAY_COL\n",
    "    print(f\"  Grouping by: {group_dim}\")\n",
    "\n",
    "    # Respect ordering\n",
    "    if group_dim == 'Region':\n",
    "        df0 = ensure_categorical(df0, 'Region', REGION_ORDER)\n",
    "    else:\n",
    "        # for contacts, alphabetical\n",
    "        df0 = ensure_categorical(df0, CHANNEL_DISPLAY_COL, None)\n",
    "\n",
    "    # Frequency loop\n",
    "    for freq_label in ORDERED_FREQ_LABELS:\n",
    "        df_f = df0[df0[FOOOF_FREQ_BAND_COL] == freq_label].copy()\n",
    "        if df_f.empty:\n",
    "            print(f\"  No data for {freq_label}; skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Outlier filter per (Group × State)\n",
    "        before_n = len(df_f)\n",
    "        df_f, n_removed = filter_outliers_iqr_per_group(\n",
    "            df_f, group_cols=[group_dim, CLINICAL_STATE_COL], value_col=AP_COL, factor=1.5\n",
    "        )\n",
    "        if before_n > 0:\n",
    "            print(f\"  {freq_label}: removed {n_removed} outliers ({(n_removed/max(before_n,1))*100:.1f}%) via IQR per ({group_dim}×State).\")\n",
    "\n",
    "        if df_f.empty:\n",
    "            print(f\"  No valid data after filtering for {freq_label}; skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Per-group plotting (one figure per group)\n",
    "        for grp in df_f[group_dim].dropna().unique():\n",
    "            df_g = df_f[df_f[group_dim] == grp].copy()\n",
    "            if df_g.empty: continue\n",
    "\n",
    "            # order states\n",
    "            df_g = ensure_categorical(df_g, CLINICAL_STATE_COL, CELL9_TARGET_STATES_ORDERED)\n",
    "\n",
    "            # Optional 10-min averaged points\n",
    "            if 'datetime_for_avg' in df_g.columns and not df_g['datetime_for_avg'].isnull().all():\n",
    "                pts = (df_g.set_index('datetime_for_avg')\n",
    "                           .groupby([pd.Grouper(freq='10T'), CLINICAL_STATE_COL])[[AP_COL]]\n",
    "                           .mean().dropna().reset_index())\n",
    "            else:\n",
    "                pts = pd.DataFrame()\n",
    "\n",
    "            # ---- Figure ----\n",
    "            fig, ax = plt.subplots(figsize=(9, 9))\n",
    "            sns.boxplot(\n",
    "                data=df_g, x=CLINICAL_STATE_COL, y=AP_COL,\n",
    "                order=CELL9_TARGET_STATES_ORDERED, palette=CELL9_STATE_COLORS,\n",
    "                showfliers=False, width=0.55, ax=ax,\n",
    "                boxprops={'alpha': BOX_FILL_ALPHA, 'linewidth': BOXPLOT_LINE_THICKNESS},\n",
    "                medianprops={'linewidth': BOXPLOT_LINE_THICKNESS, 'color':'black'},\n",
    "                whiskerprops={'linewidth': BOXPLOT_LINE_THICKNESS},\n",
    "                capprops={'linewidth': BOXPLOT_LINE_THICKNESS}\n",
    "            )\n",
    "\n",
    "            if not pts.empty:\n",
    "                sns.stripplot(\n",
    "                    data=pts, x=CLINICAL_STATE_COL, y=AP_COL,\n",
    "                    order=CELL9_TARGET_STATES_ORDERED, palette=CELL9_STATE_COLORS,\n",
    "                    jitter=0.15, alpha=DOT_ALPHA, size=4.0, ax=ax, legend=False\n",
    "                )\n",
    "\n",
    "            # ---- Bootstrap CI per state ----\n",
    "            xticks = ax.get_xticks()\n",
    "            for i, state in enumerate(CELL9_TARGET_STATES_ORDERED):\n",
    "                v = df_g.loc[df_g[CLINICAL_STATE_COL] == state, AP_COL].dropna()\n",
    "                if len(v) >= 10:\n",
    "                    med, lo, hi = bootstrap_median_ci(v, n_boot=2000, ci=0.95)\n",
    "                    if np.isfinite(med):\n",
    "                        ax.errorbar(\n",
    "                            x=xticks[i], y=med, yerr=[[med - lo], [hi - med]],\n",
    "                            fmt='o', color='black', ecolor='black',\n",
    "                            capsize=6, elinewidth=1.8, markersize=6, zorder=10\n",
    "                        )\n",
    "                # Save medians & CIs to CSV summary\n",
    "                if len(v) > 0:\n",
    "                    med2 = float(np.median(v))\n",
    "                    if len(v) >= 10:\n",
    "                        summary_rows.append({\n",
    "                            'GroupDim': group_dim, 'Group': grp, 'FreqBand': freq_label,\n",
    "                            'State': state, 'N': int(len(v)), 'Median': med, 'CI_low': lo, 'CI_high': hi\n",
    "                        })\n",
    "                    else:\n",
    "                        summary_rows.append({\n",
    "                            'GroupDim': group_dim, 'Group': grp, 'FreqBand': freq_label,\n",
    "                            'State': state, 'N': int(len(v)), 'Median': med2, 'CI_low': np.nan, 'CI_high': np.nan\n",
    "                        })\n",
    "\n",
    "            # ---- Stats: Kruskal–Wallis across states within this group ----\n",
    "            stat_text = \"\"\n",
    "            groups = [df_g.loc[df_g[CLINICAL_STATE_COL]==s, AP_COL].dropna().values for s in CELL9_TARGET_STATES_ORDERED]\n",
    "            groups_nonempty = [g for g in groups if len(g) >= MIN_SAMPLES_FOR_GROUP_COMPARISON]\n",
    "            if len(groups_nonempty) >= 2:\n",
    "                H, p = kruskal(*groups_nonempty)\n",
    "                stat_text = f\"Kruskal–Wallis: H={H:.2f}, p={p:.3g}\"\n",
    "                kw_rows.append({\n",
    "                    'GroupDim': group_dim, 'Group': grp, 'FreqBand': freq_label,\n",
    "                    'Test': 'Kruskal-Wallis', 'H': H, 'p_value': p,\n",
    "                    'N_groups_ge_min': len(groups_nonempty)\n",
    "                })\n",
    "                # Optional: Dunn posthoc (only if you want; can be commented out)\n",
    "                # try:\n",
    "                #     dunn = sp.posthoc_dunn(df_g[[CLINICAL_STATE_COL, AP_COL]].dropna(), val_col=AP_COL, group_col=CLINICAL_STATE_COL, p_adjust='fdr_bh')\n",
    "                #     # You could write dunn to CSV per (grp,freq) if desired.\n",
    "                # except Exception:\n",
    "                #     pass\n",
    "\n",
    "            # ---- Finalize ----\n",
    "            ax.set_title(f\"{AP_LABEL} — {grp} [{freq_label}]\\n{stat_text}\", pad=12)\n",
    "            ax.set_ylabel(\"Exponent\")\n",
    "            ax.set_xlabel(\"Clinical State\")\n",
    "            ax.tick_params(axis='y', labelsize=16)\n",
    "            ax.set_xticklabels([STATE_TICK_SHORT.get(s, s) for s in CELL9_TARGET_STATES_ORDERED],\n",
    "                               rotation=35, ha=\"right\")\n",
    "\n",
    "            # Legend\n",
    "            legend_elements = [\n",
    "                mpatches.Patch(facecolor='grey', alpha=BOX_FILL_ALPHA, label='Median & IQR (box)'),\n",
    "                mlines.Line2D([], [], color='grey', marker='o', linestyle='None', markersize=6, label='10-min average'),\n",
    "                mlines.Line2D([], [], color='black', marker='_', markersize=12, linestyle='None', label='Median 95% CI (bootstrap)')\n",
    "            ]\n",
    "            ax.legend(handles=legend_elements, loc='upper right', fontsize=14, frameon=True)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            safe_grp  = str(grp).replace(' ', '_').replace('-', '_')\n",
    "            safe_freq = str(freq_label).replace(' ', '_')\n",
    "            out_png = os.path.join(plot_dir, f\"{patient_hemisphere_id}_{group_dim}_{safe_grp}_{safe_freq}_Exponent_with_CI.png\")\n",
    "            plt.savefig(out_png, dpi=300)\n",
    "            plt.close(fig)\n",
    "\n",
    "    # ---------------- Write CSV outputs ----------------\n",
    "    if summary_rows:\n",
    "        df_summary = pd.DataFrame(summary_rows)\n",
    "        out_csv = os.path.join(plot_dir, f\"{patient_hemisphere_id}_Cell9_Medians_CI_by_{group_dim}.csv\")\n",
    "        df_summary.to_csv(out_csv, index=False)\n",
    "        print(f\"  Saved medians/CI table to: {out_csv}\")\n",
    "\n",
    "    if kw_rows:\n",
    "        df_kw = pd.DataFrame(kw_rows)\n",
    "        out_kw = os.path.join(plot_dir, f\"{patient_hemisphere_id}_Cell9_Kruskal_by_{group_dim}.csv\")\n",
    "        df_kw.to_csv(out_kw, index=False)\n",
    "        print(f\"  Saved Kruskal–Wallis summary to: {out_kw}\")\n",
    "\n",
    "    print(\"\\n--- Cell 9 (Revised V3, Region-first): Completed. ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0f1a88f-4171-4ce0-ab39-859889db2eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 11: Preparing Data Table for Step 5 (Cross-Subject Analysis) ---\n",
      "  Final data table for Step 5 created with 32436 rows and 28 columns.\n",
      "  Columns included: ['UserSessionName', 'SessionID', 'Hemisphere', 'Channel_Display', 'Neural_Segment_Start_Unixtime', 'Neural_Segment_End_Unixtime', 'Neural_Segment_Duration_Sec', 'FS', 'Clinical_State_2min_Window', 'Clinical_State_Aggregated', 'Aligned_BK', 'Aligned_DK', 'Aligned_Tremor_Score', 'Aligned_Tremor', 'Total_Daily_LEDD_mg', 'Beta_Peak_Power_at_DominantFreq', 'Gamma_Peak_Power_at_DominantFreq', 'FreqRangeLabel', 'FreqLow', 'FreqHigh', 'BestModel_AperiodicMode', 'Offset_BestModel', 'Knee_BestModel', 'Exponent_BestModel', 'R2_BestModel', 'Error_BestModel', 'Num_Peaks_BestModel', 'Region']\n",
      "  Successfully saved final data table for Step 5 input to: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_CrossSubjectAnalysis_DataTable_20250822_155044.csv\n",
      "\n",
      "  Sample of this final data table (first 5 rows):\n",
      "      UserSessionName SessionID Hemisphere Channel_Display  \\\n",
      "0  COHORT_RCS02_05_06    RCS06R      Right    Contact_10_8   \n",
      "1  COHORT_RCS02_05_06    RCS02R      Right    Contact_10_8   \n",
      "2  COHORT_RCS02_05_06    RCS06R      Right    Contact_10_8   \n",
      "3  COHORT_RCS02_05_06    RCS06R      Right    Contact_10_8   \n",
      "4  COHORT_RCS02_05_06    RCS06R      Right    Contact_10_8   \n",
      "\n",
      "   Neural_Segment_Start_Unixtime  Neural_Segment_End_Unixtime  \\\n",
      "0                   1.571019e+09                 1.571019e+09   \n",
      "1                   1.558421e+09                 1.558421e+09   \n",
      "2                   1.570900e+09                 1.570901e+09   \n",
      "3                   1.570910e+09                 1.570910e+09   \n",
      "4                   1.570884e+09                 1.570884e+09   \n",
      "\n",
      "   Neural_Segment_Duration_Sec     FS Clinical_State_2min_Window  \\\n",
      "0                   119.999818  250.0      Non-Dyskinetic Mobile   \n",
      "1                   120.000000  250.0                   Immobile   \n",
      "2                   119.999000  250.0                   Immobile   \n",
      "3                   119.999000  250.0                   Immobile   \n",
      "4                   119.998611  250.0                      Sleep   \n",
      "\n",
      "  Clinical_State_Aggregated  ...  FreqLow  FreqHigh  BestModel_AperiodicMode  \\\n",
      "0        Mobile (All Types)  ...     10.0      40.0                     knee   \n",
      "1                  Immobile  ...     10.0      40.0                    fixed   \n",
      "2                  Immobile  ...     10.0      40.0                     knee   \n",
      "3                  Immobile  ...     10.0      40.0                     knee   \n",
      "4                     Sleep  ...     10.0      40.0                     knee   \n",
      "\n",
      "   Offset_BestModel  Knee_BestModel  Exponent_BestModel  R2_BestModel  \\\n",
      "0         -2.492242    4.649818e+02            2.401817      0.980922   \n",
      "1          2.007333    2.084718e+11            4.797258      0.981713   \n",
      "2         -3.478284    7.239500e+02            1.764479      0.981248   \n",
      "3         -1.762755    1.273262e+03            2.934970      0.990378   \n",
      "4         -3.153963    1.347306e+02            1.825070      0.987677   \n",
      "\n",
      "  Error_BestModel  Num_Peaks_BestModel  Region  \n",
      "0        0.037802             3.636364      M1  \n",
      "1        0.042243             3.066667      M1  \n",
      "2        0.032595             4.354839      M1  \n",
      "3        0.032683             4.500000      M1  \n",
      "4        0.028264             3.833333      M1  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "\n",
      "--- Cell 11: Final Data Table generation for COHORT_RCS02_05_06 complete ---\n",
      "\n",
      "--- All Step 4 processing for COHORT_RCS02_05_06 complete. Outputs are in /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_plots_20250822_155044 and /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject ---\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 11: Generate Final Data Table for Cross-Subject Analysis (Input for Step 5) ---\n",
    "# This cell prepares the output from Step 4 to be used as input for Step 5.\n",
    "# The master_df_step4 already contains all necessary information, including\n",
    "# aperiodic metrics for EACH FreqRangeLabel, LEDD, Beta, Gamma.\n",
    "\n",
    "print(\"\\n--- Cell 11: Preparing Data Table for Step 5 (Cross-Subject Analysis) ---\")\n",
    "\n",
    "if master_df_step4 is None or master_df_step4.empty:\n",
    "    print(\"master_df_step4 not available or empty. Cannot generate final table for Step 5.\")\n",
    "else:\n",
    "    # Columns to include in the output for Step 5\n",
    "    # Should match 'master_table_columns' from Step 3 Cell 2, plus UserSessionName from Step 3 Cell 8\n",
    "    # Ensure 'UserSessionName' is defined. If this script is run standalone for one patient-hemi,\n",
    "    # 'UserSessionName' would be the patient_hemisphere_id.\n",
    "    \n",
    "    # Columns defined in Step 3's master_table_columns (Cell 2 of Step 3)\n",
    "    # This list must be kept in sync with the actual columns produced by Step 3.\n",
    "    # For robustness, we select columns that are ACTUALLY PRESENT in master_df_step4\n",
    "    # and try to match the intended set.\n",
    "    \n",
    "# --- Make script robust to optional columns and add Region helper ---\n",
    "# If the aggregated-state col name isn't defined upstream, create a dummy to avoid NameError\n",
    "    try:\n",
    "        _ = CLINICAL_STATE_AGGREGATED_COL\n",
    "    except NameError:\n",
    "        CLINICAL_STATE_AGGREGATED_COL = 'Clinical_State_Aggregated'\n",
    "        if CLINICAL_STATE_AGGREGATED_COL not in master_df_step4.columns:\n",
    "            master_df_step4[CLINICAL_STATE_AGGREGATED_COL] = pd.NA\n",
    "    \n",
    "    # If a human-readable datetime string is not present, synthesize it from the unix ts (UTC)\n",
    "    if ('Aligned_PKG_DateTime_Str' not in master_df_step4.columns) and ('Aligned_PKG_UnixTimestamp' in master_df_step4.columns):\n",
    "        master_df_step4['Aligned_PKG_DateTime_Str'] = pd.to_datetime(\n",
    "            master_df_step4['Aligned_PKG_UnixTimestamp'], unit='s', utc=True, errors='coerce'\n",
    "        ).astype('datetime64[ns]').astype(str)\n",
    "    \n",
    "    # Add Region if not present (use Channel_Display-style labels)\n",
    "    if 'Region' not in master_df_step4.columns:\n",
    "        def _to_region(lbl):\n",
    "            if pd.isna(lbl): return pd.NA\n",
    "            s = str(lbl)\n",
    "            if 'STN' in s: return 'STN'\n",
    "            if 'Cortical' in s or 'ECoG' in s or 'M1' in s: return 'M1'\n",
    "            return pd.NA\n",
    "        master_df_step4['Region'] = master_df_step4[CHANNEL_DISPLAY_COL].map(_to_region)\n",
    "    \n",
    "    # ---- Your original intended columns list (unchanged) ----\n",
    "    intended_step5_cols = [\n",
    "        'SessionID', 'Hemisphere', 'Channel', CHANNEL_DISPLAY_COL,\n",
    "        'Neural_Segment_Start_Unixtime', 'Neural_Segment_End_Unixtime',\n",
    "        'Neural_Segment_Duration_Sec', 'FS',\n",
    "        'Aligned_PKG_UnixTimestamp', 'Aligned_PKG_DateTime_Str',\n",
    "        CLINICAL_STATE_COL, CLINICAL_STATE_AGGREGATED_COL,\n",
    "        'Aligned_BK', 'Aligned_DK', 'Aligned_Tremor_Score', 'Aligned_Tremor',\n",
    "        'Total_Daily_LEDD_mg',\n",
    "        'Beta_Peak_Power_at_DominantFreq', 'Gamma_Peak_Power_at_DominantFreq',\n",
    "        FOOOF_FREQ_BAND_COL, 'FreqLow', 'FreqHigh',\n",
    "        'BestModel_AperiodicMode',\n",
    "        'Offset_BestModel', 'Knee_BestModel', 'Exponent_BestModel',\n",
    "        'R2_BestModel', 'Error_BestModel', 'Num_Peaks_BestModel',\n",
    "        # Convenience field for Step 5 groupings\n",
    "        'Region',\n",
    "    ]\n",
    "\n",
    "    final_table_cols_step5_existing = [col for col in intended_step5_cols if col in master_df_step4.columns]\n",
    "    \n",
    "    if not final_table_cols_step5_existing:\n",
    "        print(\"Warning: No columns identified for the Step 5 data table. It will be empty.\")\n",
    "        final_data_table_for_step5 = pd.DataFrame()\n",
    "    else:\n",
    "        final_data_table_for_step5 = master_df_step4[final_table_cols_step5_existing].copy()\n",
    "        \n",
    "        # Add 'UserSessionName' which was previously added in Step 3 Cell 8.\n",
    "        # Here, we re-affirm it as the patient_hemisphere_id for this file.\n",
    "        if 'UserSessionName' not in final_data_table_for_step5.columns:\n",
    "            final_data_table_for_step5.insert(0, 'UserSessionName', patient_hemisphere_id)\n",
    "        else: # If it was somehow carried over from a loaded file that already had it\n",
    "            final_data_table_for_step5['UserSessionName'] = patient_hemisphere_id\n",
    "\n",
    "\n",
    "        # Optional: Sort the table\n",
    "        sort_by_cols_step5 = ['UserSessionName', 'Aligned_PKG_UnixTimestamp', CHANNEL_DISPLAY_COL, FOOOF_FREQ_BAND_COL]\n",
    "        sort_by_cols_step5_existing = [col for col in sort_by_cols_step5 if col in final_data_table_for_step5.columns]\n",
    "        if sort_by_cols_step5_existing:\n",
    "            final_data_table_for_step5.sort_values(by=sort_by_cols_step5_existing, inplace=True, ignore_index=True)\n",
    "\n",
    "        print(f\"  Final data table for Step 5 created with {final_data_table_for_step5.shape[0]} rows and {final_data_table_for_step5.shape[1]} columns.\")\n",
    "        print(f\"  Columns included: {final_data_table_for_step5.columns.tolist()}\")\n",
    "\n",
    "    # Define filename and save (this output path should ideally be outside the patient-specific plot folder,\n",
    "    # in a place where Step 5 can glob all such files)\n",
    "    # The original Step 4 saved this in analysis_plots_root_folder (one level up from session_plot_folder_name_step4)\n",
    "    \n",
    "    output_filename_for_step5 = f\"{patient_hemisphere_id}_CrossSubjectAnalysis_DataTable_{current_datetime_str_step4}.csv\"\n",
    "    # Save in the root of the Step 4 analysis folder (step4_analysis_root_folder)\n",
    "    # This aligns with where Step 5 would look for inputs from multiple subjects.\n",
    "    output_path_for_step5 = os.path.join(step4_analysis_root_folder, output_filename_for_step5)\n",
    "\n",
    "    try:\n",
    "        final_data_table_for_step5.to_csv(output_path_for_step5, index=False)\n",
    "        print(f\"  Successfully saved final data table for Step 5 input to: {output_path_for_step5}\")\n",
    "        print(\"\\n  Sample of this final data table (first 5 rows):\")\n",
    "        print(final_data_table_for_step5.head())\n",
    "    except Exception as e_save_final_step4:\n",
    "        print(f\"  ERROR saving the final data table for Step 5 input: {e_save_final_step4}\")\n",
    "\n",
    "print(f\"\\n--- Cell 11: Final Data Table generation for {patient_hemisphere_id} complete ---\")\n",
    "print(f\"\\n--- All Step 4 processing for {patient_hemisphere_id} complete. Outputs are in {analysis_session_plot_folder_step4} and {step4_analysis_root_folder} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96759d89-ec2c-4c98-b689-54b49f98877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 12: Preparing CURATED Data Table for Step 5 (Cross-Subject Analysis) ---\n",
      "   No explicit contact selections found (Region mode).\n",
      "   Curating by Region: including all rows where Region ∈ {STN, M1} and setting BinaryChannel = Region.\n",
      "   Curated dataframe built (region) with 32436 rows.\n",
      "   Final curated data table has 32436 rows and 20 columns.\n",
      "   Columns: ['UserSessionName', 'SessionID', 'Hemisphere', 'BinaryChannel', 'Region', 'Channel_Display', 'Clinical_State_2min_Window', 'Clinical_State_Aggregated', 'Aligned_BK', 'Aligned_DK', 'Aligned_Tremor_Score', 'Total_Daily_LEDD_mg', 'Beta_Peak_Power_at_DominantFreq', 'Gamma_Peak_Power_at_DominantFreq', 'FreqRangeLabel', 'BestModel_AperiodicMode', 'Offset_BestModel', 'Exponent_BestModel', 'R2_BestModel', 'Error_BestModel']\n",
      "\n",
      "   Successfully saved CURATED data table for Step 5 input to: /home/jackson/step2_final/step3_fooof_results_neural_pkg_aligned_finalstep3_bushlab5000/step4_within_subject/COHORT_RCS02_05_06_Curated_CrossSubject_DataTable_20250822_155044.csv\n",
      "\n",
      "   Sample (first 5 rows):\n",
      "      UserSessionName SessionID Hemisphere BinaryChannel Region  \\\n",
      "0  COHORT_RCS02_05_06    RCS06R      Right            M1     M1   \n",
      "1  COHORT_RCS02_05_06    RCS02R      Right            M1     M1   \n",
      "2  COHORT_RCS02_05_06    RCS02R      Right            M1     M1   \n",
      "3  COHORT_RCS02_05_06    RCS06R      Right            M1     M1   \n",
      "4  COHORT_RCS02_05_06    RCS06R      Right            M1     M1   \n",
      "\n",
      "  Channel_Display Clinical_State_2min_Window Clinical_State_Aggregated  \\\n",
      "0    Contact_10_8      Non-Dyskinetic Mobile        Mobile (All Types)   \n",
      "1    Contact_10_8                   Immobile                  Immobile   \n",
      "2    Contact_11_9                   Immobile                  Immobile   \n",
      "3    Contact_10_8                   Immobile                  Immobile   \n",
      "4    Contact_11_9      Non-Dyskinetic Mobile        Mobile (All Types)   \n",
      "\n",
      "   Aligned_BK  Aligned_DK  Aligned_Tremor_Score  Total_Daily_LEDD_mg  \\\n",
      "0   19.270455    1.890909                   0.0                  NaN   \n",
      "1   55.161667    0.000000                   0.0                  NaN   \n",
      "2   31.275000    0.053846                   0.0                  NaN   \n",
      "3   38.442742    1.346774                   0.0                  NaN   \n",
      "4   12.606250    4.231250                   0.0                  NaN   \n",
      "\n",
      "   Beta_Peak_Power_at_DominantFreq  Gamma_Peak_Power_at_DominantFreq  \\\n",
      "0                        -4.961255                         -6.232628   \n",
      "1                        -4.431713                         -6.237028   \n",
      "2                        -5.113104                         -6.805857   \n",
      "3                        -5.088277                         -6.279775   \n",
      "4                        -5.726017                         -6.115191   \n",
      "\n",
      "  FreqRangeLabel BestModel_AperiodicMode  Offset_BestModel  \\\n",
      "0        LowFreq                    knee         -2.492242   \n",
      "1        LowFreq                   fixed          2.007333   \n",
      "2        LowFreq                   fixed         -3.677143   \n",
      "3        LowFreq                    knee         -3.478284   \n",
      "4        LowFreq                    knee         -1.320424   \n",
      "\n",
      "   Exponent_BestModel  R2_BestModel  Error_BestModel  \n",
      "0            2.401817      0.980922         0.037802  \n",
      "1            4.797258      0.981713         0.042243  \n",
      "2            1.474796      0.972730         0.040519  \n",
      "3            1.764479      0.981248         0.032595  \n",
      "4            3.064045      0.988424         0.033934  \n",
      "\n",
      "--- Cell 12: CURATED Final Data Table generation for COHORT_RCS02_05_06 complete ---\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 12 (New, Region-aware): Generate CURATED Final Data Table for Cross-Subject Analysis ---\n",
    "# Works with Cell 8 \"Region-first\" (no contact selection) OR with contact-based selections.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"\\n--- Cell 12: Preparing CURATED Data Table for Step 5 (Cross-Subject Analysis) ---\")\n",
    "\n",
    "# ---------- Helpers & robustness ----------\n",
    "def _ensure_agg_and_datetime(df):\n",
    "    \"\"\"Make sure optional columns exist: aggregated state + readable datetime string.\"\"\"\n",
    "    # Aggregated state name might not be defined upstream; create if missing\n",
    "    try:\n",
    "        _ = CLINICAL_STATE_AGGREGATED_COL\n",
    "    except NameError:\n",
    "        # define a safe default name if it wasn't set earlier\n",
    "        globals()['CLINICAL_STATE_AGGREGATED_COL'] = 'Clinical_State_Aggregated'\n",
    "    if CLINICAL_STATE_AGGREGATED_COL not in df.columns:\n",
    "        df[CLINICAL_STATE_AGGREGATED_COL] = pd.NA\n",
    "\n",
    "    # Human-readable datetime string from Unix ts (UTC)\n",
    "    if ('Aligned_PKG_DateTime_Str' not in df.columns) and ('Aligned_PKG_UnixTimestamp' in df.columns):\n",
    "        df['Aligned_PKG_DateTime_Str'] = pd.to_datetime(\n",
    "            df['Aligned_PKG_UnixTimestamp'], unit='s', utc=True, errors='coerce'\n",
    "        ).astype('datetime64[ns]').astype(str)\n",
    "\n",
    "def _ensure_region(df):\n",
    "    \"\"\"Create a Region column (STN/M1) if missing, based on CHANNEL_DISPLAY_COL.\"\"\"\n",
    "    if 'Region' not in df.columns:\n",
    "        def _to_region(lbl):\n",
    "            if pd.isna(lbl): return pd.NA\n",
    "            s = str(lbl)\n",
    "            if 'STN' in s: return 'STN'\n",
    "            if ('Cortical' in s) or ('ECoG' in s) or ('M1' in s): return 'M1'\n",
    "            return pd.NA\n",
    "        df['Region'] = df[CHANNEL_DISPLAY_COL].map(_to_region)\n",
    "    return df\n",
    "\n",
    "def _pick_pcol(df_lrt):\n",
    "    for c in ['P_value_FDR', 'P_FDR', 'p_adj', 'p_fdr', 'P_value', 'p_value', 'pval', 'P']:\n",
    "        if c in df_lrt.columns: return c\n",
    "    return None\n",
    "\n",
    "# ---------- Prereqs ----------\n",
    "if 'master_df_step4' not in locals() or master_df_step4 is None or master_df_step4.empty:\n",
    "    print(\"\\nERROR: master_df_step4 not available or empty. Cannot generate curated table.\")\n",
    "else:\n",
    "    # Make sure optional columns exist\n",
    "    _ensure_agg_and_datetime(master_df_step4)\n",
    "    master_df_step4 = _ensure_region(master_df_step4)\n",
    "\n",
    "    # Decide how to curate based on user_selections from Cell 8\n",
    "    sel_obj = None\n",
    "    if 'user_selections' in locals():\n",
    "        sel_obj = user_selections\n",
    "\n",
    "    mode = None\n",
    "    sel_map = None\n",
    "    if isinstance(sel_obj, dict) and 'mode' in sel_obj:\n",
    "        mode = sel_obj.get('mode')\n",
    "        sel_map = sel_obj.get('selections') if isinstance(sel_obj.get('selections'), dict) else None\n",
    "    elif isinstance(sel_obj, dict):\n",
    "        # Older Cell 8 returned the raw selections dict\n",
    "        sel_map = sel_obj\n",
    "\n",
    "    curated_data_rows = []\n",
    "\n",
    "    if isinstance(sel_map, dict) and any(sel_map.values()):\n",
    "        # ----- CONTACT FALLBACK MODE (explicit per-symptom channel picks) -----\n",
    "        print(\"   Using contact selections from Cell 8 to build curated dataset...\")\n",
    "        for symptom_dv, choices in sel_map.items():\n",
    "            for group_name, chosen_channel in choices.items():\n",
    "                sub = master_df_step4[master_df_step4[CHANNEL_DISPLAY_COL] == chosen_channel].copy()\n",
    "                if sub.empty:\n",
    "                    continue\n",
    "                sub['BinaryChannel'] = group_name  # 'STN' or 'M1'\n",
    "                curated_data_rows.append(sub)\n",
    "        curation_mode_used = \"contact_fallback\"\n",
    "    else:\n",
    "        # ----- REGION MODE (auto-curate by Region) -----\n",
    "        print(\"   No explicit contact selections found (Region mode).\")\n",
    "        print(\"   Curating by Region: including all rows where Region ∈ {STN, M1} and setting BinaryChannel = Region.\")\n",
    "        sub = master_df_step4[master_df_step4['Region'].isin(['STN', 'M1'])].copy()\n",
    "        sub['BinaryChannel'] = sub['Region']\n",
    "        curated_data_rows.append(sub)\n",
    "        curation_mode_used = \"region\"\n",
    "\n",
    "    if not curated_data_rows:\n",
    "        print(\"   ERROR: No matching data found for curation.\")\n",
    "    else:\n",
    "        df_curated = pd.concat(curated_data_rows, ignore_index=True).drop_duplicates().reset_index(drop=True)\n",
    "        print(f\"   Curated dataframe built ({curation_mode_used}) with {df_curated.shape[0]} rows.\")\n",
    "\n",
    "        # ---------- Select & format columns ----------\n",
    "        intended_cols = [\n",
    "            'UserSessionName', 'SessionID', 'Hemisphere',\n",
    "            'BinaryChannel',           # new curated field (STN/M1)\n",
    "            'Region',                  # keep Region for convenience\n",
    "            CHANNEL_DISPLAY_COL,       # original channel label\n",
    "            'Aligned_PKG_UnixTimestamp','Aligned_PKG_DateTime_Str',\n",
    "            CLINICAL_STATE_COL, CLINICAL_STATE_AGGREGATED_COL,\n",
    "            'Aligned_BK', 'Aligned_DK', 'Aligned_Tremor_Score',\n",
    "            'Total_Daily_LEDD_mg',\n",
    "            'Beta_Peak_Power_at_DominantFreq', 'Gamma_Peak_Power_at_DominantFreq',\n",
    "            FOOOF_FREQ_BAND_COL, 'BestModel_AperiodicMode',\n",
    "            'Offset_BestModel', 'Exponent_BestModel',\n",
    "            'R2_BestModel', 'Error_BestModel'\n",
    "        ]\n",
    "        keep_cols = [c for c in intended_cols if c in df_curated.columns]\n",
    "        df_final_curated = df_curated[keep_cols].copy()\n",
    "\n",
    "        # Ensure UserSessionName\n",
    "        if 'UserSessionName' not in df_final_curated.columns:\n",
    "            df_final_curated.insert(0, 'UserSessionName', patient_hemisphere_id)\n",
    "        else:\n",
    "            df_final_curated['UserSessionName'] = patient_hemisphere_id\n",
    "\n",
    "        # Sort for consistency\n",
    "        sort_candidates = ['UserSessionName', 'BinaryChannel', 'Aligned_PKG_UnixTimestamp', FOOOF_FREQ_BAND_COL]\n",
    "        sort_present = [c for c in sort_candidates if c in df_final_curated.columns]\n",
    "        if sort_present:\n",
    "            df_final_curated.sort_values(by=sort_present, inplace=True, ignore_index=True)\n",
    "\n",
    "        print(f\"   Final curated data table has {df_final_curated.shape[0]} rows and {df_final_curated.shape[1]} columns.\")\n",
    "        print(f\"   Columns: {list(df_final_curated.columns)}\")\n",
    "\n",
    "        # ---------- Save ----------\n",
    "        output_filename_curated = f\"{patient_hemisphere_id}_Curated_CrossSubject_DataTable_{current_datetime_str_step4}.csv\"\n",
    "        output_path_curated = os.path.join(step4_analysis_root_folder, output_filename_curated)\n",
    "\n",
    "        try:\n",
    "            df_final_curated.to_csv(output_path_curated, index=False)\n",
    "            print(f\"\\n   Successfully saved CURATED data table for Step 5 input to: {output_path_curated}\")\n",
    "            print(\"\\n   Sample (first 5 rows):\")\n",
    "            print(df_final_curated.head())\n",
    "        except Exception as e:\n",
    "            print(f\"   ERROR saving the curated data table: {e}\")\n",
    "\n",
    "print(f\"\\n--- Cell 12: CURATED Final Data Table generation for {patient_hemisphere_id} complete ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c8aaea-9318-4a7a-903c-3ae6c4038e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
