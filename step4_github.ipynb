{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f43b35-ba44-4cb5-b9e1-a8afc93dd13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Step 4: Within-Subject Analysis (Revised) ---\n",
    "# --- Cell 1: Imports and Global Styling Setup ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re # For natural sorting and safe filenames\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, spearmanr, mannwhitneyu # For bivariate correlations\n",
    "import pingouin as pg # For partial correlations\n",
    "import statsmodels.formula.api as smf # For multiple linear regression\n",
    "from statsmodels.graphics.regressionplots import plot_partregress_grid # For partial regression plots\n",
    "\n",
    "# --- Suppress Warnings ---\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Degrees of freedom <= 0 for slice\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"p-value may not be accurate for N > 5000\")\n",
    "\n",
    "# --- Plotting Style and Global Parameters ---\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']\n",
    "plt.rcParams['axes.titlesize'] = 14     # Titles for individual subplots\n",
    "plt.rcParams['axes.labelsize'] = 12     # X/Y axis labels\n",
    "plt.rcParams['xtick.labelsize'] = 10    # X-axis tick labels\n",
    "plt.rcParams['ytick.labelsize'] = 10    # Y-axis tick labels\n",
    "plt.rcParams['legend.fontsize'] = 10    # Legend font size\n",
    "plt.rcParams['figure.titlesize'] = 18   # For suptitle on overview (figure-level) plots\n",
    "plt.rcParams['figure.dpi'] = 100        # For inline viewing\n",
    "plt.rcParams['savefig.dpi'] = 600       # For saving figures\n",
    "\n",
    "print(\"Cell 1: Imports and global styling setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c2fa4-d63e-4b52-bf13-195f0aaf1f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 2: User Input, File Paths, and Analysis Parameter Definitions ---\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re # For safe filenames\n",
    "\n",
    "# --- User Input ---\n",
    "# For development, hardcode; replace with input() in practice if needed for batch processing setup\n",
    "# This script processes ONE patient-hemisphere at a time.\n",
    "# The patient_hemisphere_id should match the identifier in the MASTER_FOOOF_PKG_results file name.\n",
    "# Example: \"RCS20R\" if your file is MASTER_FOOOF_PKG_results_RCS20R_... .csv\n",
    "patient_hemisphere_id = \"RCS02L\" # <<< USER: SET THIS FOR THE CURRENT PATIENT-HEMISPHERE\n",
    "print(f\"Processing data for Patient-Hemisphere ID: {patient_hemisphere_id}\")\n",
    "\n",
    "if not patient_hemisphere_id:\n",
    "    raise ValueError(\"Patient-Hemisphere ID cannot be empty.\")\n",
    "\n",
    "# --- Path Configuration ---\n",
    "user_home = os.path.expanduser(\"~\")\n",
    "project_base_path = \"..\"\n",
    "\n",
    "# Path to the output folder from Step 3 (where MASTER_FOOOF_PKG_results... files are)\n",
    "step3_output_version_tag = \"neural_pkg_aligned\" # <<< USER: Ensure this matches Step 3's tag\n",
    "step3_master_csv_base_folder = os.path.join(project_base_path, 'Working', f'step3_fooof_results_{step3_output_version_tag}')\n",
    "\n",
    "master_csv_filename = f\"MASTER_FOOOF_PKG_results_{patient_hemisphere_id}_{step3_output_version_tag}.csv\"\n",
    "master_csv_path_to_load = os.path.join(step3_master_csv_base_folder, master_csv_filename)\n",
    "print(f\"Attempting to load master data from: {master_csv_path_to_load}\")\n",
    "\n",
    "# Output folder for Step 4 results and plots\n",
    "step4_analysis_root_folder = os.path.join(step3_master_csv_base_folder, \"step4_within_subject_analysis\")\n",
    "os.makedirs(step4_analysis_root_folder, exist_ok=True)\n",
    "\n",
    "current_datetime_str_step4 = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "session_plot_folder_name_step4 = f\"{patient_hemisphere_id}_plots_{current_datetime_str_step4}\"\n",
    "analysis_session_plot_folder_step4 = os.path.join(step4_analysis_root_folder, session_plot_folder_name_step4)\n",
    "os.makedirs(analysis_session_plot_folder_step4, exist_ok=True)\n",
    "print(f\"Step 4 plots will be saved in: {analysis_session_plot_folder_step4}\")\n",
    "\n",
    "# --- Analysis Parameters ---\n",
    "# These should align with what's available in your master CSV from Step 3\n",
    "APERIODIC_METRICS_COLS = {\n",
    "    'Exponent_BestModel': 'Aperiodic Exponent',\n",
    "    'Offset_BestModel': 'Aperiodic Offset',\n",
    "}\n",
    "PKG_METRICS_COLS = {\n",
    "    'Aligned_BK': 'PKG BK Score',\n",
    "    'Aligned_DK': 'PKG DK Score',\n",
    "    'Aligned_Tremor_Score': 'PKG Tremor Score'\n",
    "}\n",
    "OSCILLATORY_METRICS_COLS = {\n",
    "    'Beta_Peak_Power_at_DominantFreq': 'Beta Peak Power',\n",
    "    'Gamma_Peak_Power_at_DominantFreq': 'Gamma Peak Power'\n",
    "}\n",
    "\n",
    "CHANNEL_COL = 'Channel' # Raw channel key like 'TD_key0'\n",
    "CHANNEL_DISPLAY_COL = 'Channel_Display' # User-friendly labels like 'STN_DBS_2-0'\n",
    "FOOOF_FREQ_BAND_COL = 'FreqRangeLabel'\n",
    "CLINICAL_STATE_COL = 'Clinical_State_2min_Window'\n",
    "CLINICAL_STATE_AGGREGATED_COL = 'Clinical_State_Aggregated' # From Step 3\n",
    "\n",
    "# Desired order for iterations and plotting\n",
    "# ORDERED_CHANNEL_LABELS will be derived from data in Cell 3, or can be hardcoded here if preferred:\n",
    "# e.g., ORDERED_CHANNEL_LABELS = ['STN_DBS_2-0', 'STN_DBS_3-1', 'Cortical_ECoG_10-8', 'Cortical_ECoG_11-9']\n",
    "ORDERED_FREQ_LABELS = [\"LowFreq\", \"MidFreq\", \"WideFreq\"] # From Step 3 FOOOF bands\n",
    "\n",
    "# --- Statistical Thresholds ---\n",
    "MIN_SAMPLES_FOR_CORR = 5       # Minimum data points for a correlation to be considered reliable\n",
    "P_VALUE_THRESHOLD = 0.05\n",
    "\n",
    "# --- Styling Parameters (can be expanded) ---\n",
    "COLOR_PALETTE_STEP4 = {\n",
    "    'Exponent_BestModel': 'darkslateblue',\n",
    "    'Offset_BestModel': 'mediumseagreen',\n",
    "    'Beta_Peak_Power_at_DominantFreq': 'goldenrod',\n",
    "    'Gamma_Peak_Power_at_DominantFreq': 'firebrick',\n",
    "    'Aligned_BK': 'steelblue',\n",
    "    'Aligned_DK': 'orangered',\n",
    "    'Aligned_Tremor_Score': 'mediumpurple'\n",
    "}\n",
    "DOT_ALPHA_STEP4 = 0.5\n",
    "REG_CI_ALPHA_STEP4 = 0.15\n",
    "BOX_FILL_ALPHA_STEP4 = 0.6\n",
    "REG_LINE_THICKNESS_STEP4 = 2.0\n",
    "\n",
    "# For heatmaps\n",
    "SIGNIFICANT_P_VAL_BG_COLOR_STEP4 = 'khaki' # Not directly used for heatmap cell color, but for annotations\n",
    "DEFAULT_P_VAL_BG_COLOR_STEP4 = 'ivory'\n",
    "\n",
    "print(f\"\\nStep 4 analysis parameters and paths configured for {patient_hemisphere_id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c32f9f-b3f7-41c9-991b-ad61c00369f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 3: Data Loading and Initial Preprocessing ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re # For natural sort key\n",
    "\n",
    "def load_and_preprocess_step4_data(file_path, patient_hemisphere_id_val):\n",
    "    \"\"\"Loads and preprocesses the master CSV file from Step 3 for Step 4 analyses.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"ERROR: Master CSV file from Step 3 not found at {file_path}\")\n",
    "        return None, []\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded {file_path}. Initial shape: {df.shape}\")\n",
    "\n",
    "        # --- Verify Patient ID consistency (optional but good check) ---\n",
    "        if 'SessionID' in df.columns and df['SessionID'].nunique() == 1:\n",
    "            csv_session_id = df['SessionID'].unique()[0]\n",
    "            if csv_session_id != patient_hemisphere_id_val:\n",
    "                print(f\"Warning: SessionID in CSV ({csv_session_id}) differs from expected ({patient_hemisphere_id_val}). Proceeding with CSV data.\")\n",
    "        elif 'SessionID' not in df.columns:\n",
    "             print(f\"Warning: 'SessionID' column not found. Adding it based on patient_hemisphere_id_val: {patient_hemisphere_id_val}\")\n",
    "             df['SessionID'] = patient_hemisphere_id_val\n",
    "\n",
    "\n",
    "        # --- Data Type Conversions & Cleaning ---\n",
    "        cols_to_numeric = (\n",
    "            list(APERIODIC_METRICS_COLS.keys()) +\n",
    "            list(PKG_METRICS_COLS.keys()) +\n",
    "            list(OSCILLATORY_METRICS_COLS.keys()) +\n",
    "            ['Total_Daily_LEDD_mg', 'R2_BestModel', 'Error_BestModel', 'Num_Peaks_BestModel']\n",
    "        )\n",
    "        for col in cols_to_numeric:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            else:\n",
    "                print(f\"Warning: Expected numeric column '{col}' not found in master_df.\")\n",
    "        \n",
    "        # Ensure key categorical columns are strings\n",
    "        for col in [CHANNEL_COL, CHANNEL_DISPLAY_COL, FOOOF_FREQ_BAND_COL, CLINICAL_STATE_COL, CLINICAL_STATE_AGGREGATED_COL, 'Hemisphere', 'BestModel_AperiodicMode']:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(str)\n",
    "            else:\n",
    "                print(f\"Warning: Expected categorical column '{col}' not found.\")\n",
    "\n",
    "\n",
    "        # --- Filtering based on FOOOF fit quality (optional, as done in original Step 4) ---\n",
    "        initial_rows = len(df)\n",
    "        if 'R2_BestModel' in df.columns:\n",
    "            r2_threshold_step4 = 0.5 # Example threshold\n",
    "            df = df[df['R2_BestModel'] >= r2_threshold_step4].copy()\n",
    "            print(f\"Filtered by R2_BestModel >= {r2_threshold_step4}. Rows changed from {initial_rows} to {len(df)}.\")\n",
    "        else:\n",
    "            print(\"Warning: 'R2_BestModel' column not found. Cannot filter by FOOOF fit quality.\")\n",
    "\n",
    "        # --- Create Channel_Display if not present (mapping from Step 3 should have done this) ---\n",
    "        # This is a fallback\n",
    "        if CHANNEL_DISPLAY_COL not in df.columns and CHANNEL_COL in df.columns:\n",
    "            print(f\"'{CHANNEL_DISPLAY_COL}' not found. Creating from '{CHANNEL_COL}'. Hardcoded map will be used if available.\")\n",
    "            # Hardcoded map (ensure this is consistent with Step 3 and your data)\n",
    "            channel_mapping_step4 = {\n",
    "                'TD_key0': 'STN_DBS_2-0', 'TD_key1': 'STN_DBS_3-1',\n",
    "                'TD_key2': 'Cortical_ECoG_10-8', 'TD_key3': 'Cortical_ECoG_11-9'\n",
    "            }\n",
    "            df[CHANNEL_DISPLAY_COL] = df[CHANNEL_COL].map(channel_mapping_step4).fillna(df[CHANNEL_COL])\n",
    "\n",
    "\n",
    "        # Determine ordered channel labels from the data if not hardcoded in Cell 2\n",
    "        if CHANNEL_DISPLAY_COL in df.columns:\n",
    "            def natural_sort_key_step4(s):\n",
    "                return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', str(s))]\n",
    "            \n",
    "            # Use pre-defined channel mapping for ordering if available\n",
    "            defined_channel_map_order = {\n",
    "                'STN_DBS_2-0': 0, 'STN_DBS_3-1': 1, \n",
    "                'Cortical_ECoG_10-8': 2, 'Cortical_ECoG_11-9': 3\n",
    "            }\n",
    "            unique_ch_labels_data = df[CHANNEL_DISPLAY_COL].unique()\n",
    "            # Filter and sort based on the defined order\n",
    "            ordered_ch_labels_from_data = sorted(\n",
    "                [ch for ch in unique_ch_labels_data if ch in defined_channel_map_order],\n",
    "                key=lambda x: defined_channel_map_order[x]\n",
    "            )\n",
    "            # Add any channels from data not in defined_channel_map_order, sorted naturally\n",
    "            ordered_ch_labels_from_data.extend(\n",
    "                sorted([ch for ch in unique_ch_labels_data if ch not in defined_channel_map_order], \n",
    "                       key=natural_sort_key_step4)\n",
    "            )\n",
    "            print(f\"Derived ORDERED_CHANNEL_LABELS for plots: {ordered_ch_labels_from_data}\")\n",
    "        else:\n",
    "            print(f\"ERROR: '{CHANNEL_DISPLAY_COL}' not found. Cannot determine channel order.\")\n",
    "            ordered_ch_labels_from_data = []\n",
    "            \n",
    "        # Drop rows where essential metrics for correlation/regression are NaN\n",
    "        # This step is crucial as analysis loops will iterate through these.\n",
    "        key_metrics_for_analysis = (\n",
    "            list(APERIODIC_METRICS_COLS.keys()) +\n",
    "            list(PKG_METRICS_COLS.keys()) +\n",
    "            list(OSCILLATORY_METRICS_COLS.keys())\n",
    "        )\n",
    "        key_metrics_present = [col for col in key_metrics_for_analysis if col in df.columns]\n",
    "        \n",
    "        rows_before_na_essential_drop = len(df)\n",
    "        if key_metrics_present:\n",
    "            df.dropna(subset=key_metrics_present, how='any', inplace=True) # Drop if ANY of these are NaN for a row\n",
    "            print(f\"Dropped rows with NaNs in any of {key_metrics_present}. Rows changed from {rows_before_na_essential_drop} to {len(df)}.\")\n",
    "        else:\n",
    "            print(\"Warning: No key metrics found to check for NaNs. Data might be incomplete.\")\n",
    "\n",
    "\n",
    "        print(f\"Final master_df for Step 4 shape: {df.shape}\")\n",
    "        if df.empty:\n",
    "            print(\"Warning: DataFrame is empty after preprocessing. Subsequent analyses might fail.\")\n",
    "        \n",
    "        return df, ordered_ch_labels_from_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing the CSV file '{file_path}' for Step 4: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "        return None, []\n",
    "\n",
    "# --- Load and Preprocess Data ---\n",
    "master_df_step4, ORDERED_CHANNEL_LABELS = load_and_preprocess_step4_data(master_csv_path_to_load, patient_hemisphere_id)\n",
    "\n",
    "# --- START OF NEW CODE BLOCK for Redefining Clinical States ---\n",
    "if master_df_step4 is not None and not master_df_step4.empty and \\\n",
    "   'Aligned_BK' in master_df_step4.columns and 'Aligned_DK' in master_df_step4.columns:\n",
    "\n",
    "    print(\"\\\\n--- Redefining Clinical States Point-by-Point ---\")\n",
    "\n",
    "    # Ensure Aligned_BK and Aligned_DK are numeric (should be done by load_and_preprocess_step4_data already)\n",
    "    master_df_step4['Aligned_BK'] = pd.to_numeric(master_df_step4['Aligned_BK'], errors='coerce')\n",
    "    master_df_step4['Aligned_DK'] = pd.to_numeric(master_df_step4['Aligned_DK'], errors='coerce')\n",
    "\n",
    "    # 1. Define criteria for \"general mobile candidate\"\n",
    "    # These are based on the original Step 3 Cell 3a logic before windowing\n",
    "    is_general_mobile_candidate_series = (\n",
    "        (master_df_step4['Aligned_BK'] <= 26) | (master_df_step4['Aligned_DK'] >= 7)\n",
    "    )\n",
    "    \n",
    "    # 2. Isolate \"Mobile Candidate\" Data for Percentile Calculation\n",
    "    df_mobile_for_percentiles = master_df_step4[is_general_mobile_candidate_series & \\\n",
    "                                                master_df_step4['Aligned_DK'].notna()].copy()\n",
    "\n",
    "    p30_dk_mobile_only = np.nan\n",
    "    p70_dk_mobile_only = np.nan\n",
    "\n",
    "    if not df_mobile_for_percentiles.empty and len(df_mobile_for_percentiles['Aligned_DK'].dropna()) > 1: # Need at least 2 points for percentile\n",
    "        p30_dk_mobile_only = np.percentile(df_mobile_for_percentiles['Aligned_DK'].dropna(), 30)\n",
    "        p70_dk_mobile_only = np.percentile(df_mobile_for_percentiles['Aligned_DK'].dropna(), 70)\n",
    "        print(f\"  Calculated new mobile-only DK percentiles: p30={p30_dk_mobile_only:.2f}, p70={p70_dk_mobile_only:.2f}\")\n",
    "    else:\n",
    "        print(\"  Warning: Not enough 'mobile candidate' data with valid DK scores to calculate new percentiles. States might not be redefined accurately.\")\n",
    "\n",
    "    # 3. Define a function for point-by-point state assignment\n",
    "    def redefine_clinical_state_pointwise(row, p30_mobile, p70_mobile):\n",
    "        bk = row['Aligned_BK']\n",
    "        dk = row['Aligned_DK']\n",
    "\n",
    "        if pd.isna(bk) or pd.isna(dk):\n",
    "            return \"Other\" # Or some other placeholder for missing PKG data\n",
    "\n",
    "        # Original criteria from Step 3 Cell 3a\n",
    "        is_sleep = (bk >= 80)\n",
    "        is_immobile = (bk > 26) & (bk < 80) & (dk < 7)\n",
    "        is_general_mobile = (bk <= 26) | (dk >= 7)\n",
    "\n",
    "        if is_sleep:\n",
    "            return \"Sleep\"\n",
    "        elif is_immobile:\n",
    "            return \"Immobile\"\n",
    "        elif is_general_mobile:\n",
    "            if pd.notna(p30_mobile) and pd.notna(p70_mobile): # Only assign refined if percentiles are valid\n",
    "                if dk <= p30_mobile:\n",
    "                    return \"Non-Dyskinetic Mobile\"\n",
    "                elif dk > p70_mobile:\n",
    "                    return \"Dyskinetic Mobile\"\n",
    "                else: # dk is > p30_mobile and <= p70_mobile\n",
    "                    return \"Transitional Mobile\"\n",
    "            else: # Fallback if percentiles could not be calculated\n",
    "                return \"Mobile (Generic)\" # Fallback for mobile if percentiles are NaN\n",
    "        else:\n",
    "            return \"Other\"\n",
    "\n",
    "    # 4. Apply the function to Re-calculate Clinical_State_2min_Window\n",
    "    # CLINICAL_STATE_COL is 'Clinical_State_2min_Window' as defined in Cell 2\n",
    "    master_df_step4[CLINICAL_STATE_COL] = master_df_step4.apply(\n",
    "        lambda row: redefine_clinical_state_pointwise(row, p30_dk_mobile_only, p70_dk_mobile_only), axis=1\n",
    "    )\n",
    "    print(f\"  '{CLINICAL_STATE_COL}' column has been redefined point-by-point.\")\n",
    "\n",
    "    # 5. Update Clinical_State_Aggregated\n",
    "    # CLINICAL_STATE_AGGREGATED_COL is 'Clinical_State_Aggregated'\n",
    "    # REFINED_MOBILE_STATES were Sleep, Immobile, Dyskinetic Mobile, Non-Dyskinetic Mobile, Transitional Mobile, Other\n",
    "    # We need a list of the new mobile states for aggregation\n",
    "    new_refined_mobile_states = [\"Non-Dyskinetic Mobile\", \"Transitional Mobile\", \"Dyskinetic Mobile\"]\n",
    "    \n",
    "    def aggregate_new_mobile_states(state_redefined):\n",
    "        if state_redefined in new_refined_mobile_states:\n",
    "            return \"Mobile (All Types)\" # This name is from previous logic, can be adjusted\n",
    "        return state_redefined\n",
    "\n",
    "    master_df_step4[CLINICAL_STATE_AGGREGATED_COL] = master_df_step4[CLINICAL_STATE_COL].apply(aggregate_new_mobile_states)\n",
    "    print(f\"  '{CLINICAL_STATE_AGGREGATED_COL}' column has been updated based on new states.\")\n",
    "\n",
    "    # 6. Print value counts of the new distribution\n",
    "    print(\"\\\\n  New distribution of 'Clinical_State_2min_Window':\")\n",
    "    print(master_df_step4[CLINICAL_STATE_COL].value_counts(dropna=False))\n",
    "    print(\"\\\\n  New distribution of 'Clinical_State_Aggregated':\")\n",
    "    print(master_df_step4[CLINICAL_STATE_AGGREGATED_COL].value_counts(dropna=False))\n",
    "\n",
    "else:\n",
    "    if master_df_step4 is None or master_df_step4.empty:\n",
    "        print(\"\\\\nSkipping clinical state redefinition because master_df_step4 is not loaded or is empty.\")\n",
    "    else:\n",
    "        print(\"\\\\nSkipping clinical state redefinition because 'Aligned_BK' or 'Aligned_DK' columns are missing.\")\n",
    "\n",
    "# --- END OF NEW CODE BLOCK ---\n",
    "\n",
    "if master_df_step4 is not None and not master_df_step4.empty:\n",
    "    print(\"\\nFirst 5 rows of the processed master DataFrame for Step 4 (showing key cols):\")\n",
    "    cols_to_show_step4 = [CHANNEL_DISPLAY_COL, FOOOF_FREQ_BAND_COL] + \\\n",
    "                         list(APERIODIC_METRICS_COLS.keys()) + \\\n",
    "                         list(PKG_METRICS_COLS.keys()) + \\\n",
    "                         list(OSCILLATORY_METRICS_COLS.keys()) + \\\n",
    "                         ['Total_Daily_LEDD_mg']\n",
    "    cols_to_show_step4_present = [col for col in cols_to_show_step4 if col in master_df_step4.columns]\n",
    "    print(master_df_step4[cols_to_show_step4_present].head())\n",
    "else:\n",
    "    print(\"Halting Step 4 script as master data could not be loaded or is empty after preprocessing.\")\n",
    "    # sys.exit() # Uncomment to halt execution if master_df_step4 is not loaded\n",
    "\n",
    "print(\"\\nCell 3: Data loading and preprocessing complete for Step 4.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b8a5c-369e-4ab0-a96e-5b893b88dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 4: Helper Functions for Step 4 ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches # For legend patches if needed\n",
    "from scipy.stats import spearmanr\n",
    "import pingouin as pg # For partial correlation\n",
    "\n",
    "def calculate_spearman_with_n(data_df, col1, col2, min_samples=MIN_SAMPLES_FOR_CORR):\n",
    "    \"\"\"Calculates Spearman correlation if N >= min_samples.\"\"\"\n",
    "    pair_data = data_df[[col1, col2]].dropna()\n",
    "    n_points = len(pair_data)\n",
    "\n",
    "    if n_points < min_samples:\n",
    "        return np.nan, np.nan, n_points # rho, p-value, N\n",
    "    try:\n",
    "        rho, p_value = spearmanr(pair_data[col1], pair_data[col2])\n",
    "        if np.isnan(rho): # Handle cases where spearmanr might return NaN (e.g., no variance)\n",
    "            return np.nan, np.nan, n_points\n",
    "        return rho, p_value, n_points\n",
    "    except ValueError: # Handle other potential errors like constant input\n",
    "        return np.nan, np.nan, n_points\n",
    "\n",
    "def calculate_partial_spearman(data_df, x_col, y_col, covar_cols, min_samples=MIN_SAMPLES_FOR_CORR):\n",
    "    \"\"\"Calculates partial Spearman correlation if N >= min_samples.\"\"\"\n",
    "    all_cols_for_partial = [x_col, y_col] + covar_cols\n",
    "    partial_data = data_df[all_cols_for_partial].dropna()\n",
    "    n_points = len(partial_data)\n",
    "\n",
    "    if n_points < min_samples:\n",
    "        return np.nan, np.nan, n_points # partial_rho, p-value, N\n",
    "    try:\n",
    "        # Ensure all columns for partial corr are numeric and not constant after dropna\n",
    "        if not all(partial_data[col].nunique() > 1 for col in all_cols_for_partial if col in partial_data):\n",
    "            # print(f\"Warning: Constant column found in data for partial corr {x_col} vs {y_col}. N={n_points}\")\n",
    "            return np.nan, np.nan, n_points\n",
    "            \n",
    "        pcorr_result = pg.partial_corr(data=partial_data, x=x_col, y=y_col, covar=covar_cols, method='spearman')\n",
    "        rho = pcorr_result['r'].iloc[0]\n",
    "        p_value = pcorr_result['p-val'].iloc[0]\n",
    "        return rho, p_value, n_points\n",
    "    except Exception as e: # Catch any error during partial correlation\n",
    "        # print(f\"Error in partial correlation for {x_col} vs {y_col} (N={n_points}): {e}\")\n",
    "        return np.nan, np.nan, n_points\n",
    "\n",
    "\n",
    "def annotate_correlation_on_plot(ax, rho, p_value, N_val, test_type=\"Spearman œÅ\", \n",
    "                                 x_pos=0.97, y_pos=0.97, fontsize=9,\n",
    "                                 sig_threshold=P_VALUE_THRESHOLD):\n",
    "    \"\"\"Annotates correlation statistics on a plot axis.\"\"\"\n",
    "    if pd.isna(rho) or pd.isna(p_value):\n",
    "        stat_text = f\"{test_type}: N/A (N={N_val})\"\n",
    "        bg_color = DEFAULT_P_VAL_BG_COLOR_STEP4 # from Cell 2\n",
    "    else:\n",
    "        stars = \"\"\n",
    "        if p_value < 0.001: stars = \"***\"\n",
    "        elif p_value < 0.01: stars = \"**\"\n",
    "        elif p_value < sig_threshold: stars = \"*\"\n",
    "        stat_text = f\"{test_type}={rho:.2f}{stars}\\np={p_value:.3g}\\n(N={N_val})\"\n",
    "        bg_color = SIGNIFICANT_P_VAL_BG_COLOR_STEP4 if p_value < sig_threshold else DEFAULT_P_VAL_BG_COLOR_STEP4\n",
    "    \n",
    "    ax.text(x_pos, y_pos, stat_text, transform=ax.transAxes, fontsize=fontsize,\n",
    "            verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', fc=bg_color, alpha=0.85, edgecolor='darkgrey'))\n",
    "\n",
    "def get_safe_filename_step4(base_name):\n",
    "    \"\"\"Creates a filesystem-safe filename.\"\"\"\n",
    "    return re.sub(r'[^\\w\\s-]', '', str(base_name)).strip().replace(' ', '_').replace('-', '_')\n",
    "\n",
    "def trim_data_for_boxplot_visualization(df_group, value_col):\n",
    "    \"\"\"Trims outliers based on IQR for cleaner boxplot visualization (doesn't affect stats).\"\"\"\n",
    "    if df_group.empty or df_group[value_col].isnull().all() or len(df_group) < 2:\n",
    "        return df_group\n",
    "    Q1 = df_group[value_col].quantile(0.25)\n",
    "    Q3 = df_group[value_col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    if IQR == 0: # Avoid issues if all data points are the same\n",
    "        return df_group\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df_group[(df_group[value_col] >= lower_bound) & (df_group[value_col] <= upper_bound)]\n",
    "\n",
    "\n",
    "print(\"Cell 4: Helper functions for Step 4 defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e498b-0341-4a81-bd36-f40089d1efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 5_PREAMBLE: Definitions for State-Specific Analyses (Revised Order: No Sleep, 4 Separate Mobile/Immobile States) ---\n",
    "# This cell should be run after Cell 4 (Helper Functions) and before the new state-specific analysis cells.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import re\n",
    "\n",
    "# --- Define NEW Target Clinical States and their Order (4 States, No Sleep, New Order) ---\n",
    "TARGET_CLINICAL_STATES_ORDERED = [\n",
    "    \"Immobile\",\n",
    "    \"Non-Dyskinetic Mobile\", # Moved up\n",
    "    \"Transitional Mobile\",   # Moved down\n",
    "    \"Dyskinetic Mobile\"\n",
    "]\n",
    "\n",
    "# This list is now the same as TARGET_CLINICAL_STATES_ORDERED as no combining is done here.\n",
    "# It's used to initially filter master_df_step4.\n",
    "ORIGINAL_STATES_FOR_ANALYSIS = TARGET_CLINICAL_STATES_ORDERED[:] # Create a copy\n",
    "\n",
    "# No combining needed for this setup\n",
    "STATES_TO_COMBINE_MAPPING = {}\n",
    "NEW_COMBINED_STATE_NAME = None\n",
    "\n",
    "\n",
    "# --- Define Clinical State Colors (using original distinct colors, excluding Sleep) ---\n",
    "# The color definitions themselves don't change, but their application order will follow TARGET_CLINICAL_STATES_ORDERED\n",
    "NEW_CLINICAL_STATE_COLORS_FOR_PLOTTING = {\n",
    "    'Immobile': '#40E0D0',              # Turquoise\n",
    "    'Transitional Mobile': '#FFD700',   # Gold\n",
    "    'Non-Dyskinetic Mobile': '#32CD32', # LimeGreen\n",
    "    'Dyskinetic Mobile': '#FF6347',     # Tomato\n",
    "    # Fallbacks or other states if they were to appear unexpectedly\n",
    "    'Sleep': '#4169E1',                 # RoyalBlue (original, but excluded from TARGET_CLINICAL_STATES_ORDERED)\n",
    "    'Other': '#C0C0C0',                 # Silver\n",
    "    'Mobile (All Types)': 'darkgreen'   # For aggregated view if ever used\n",
    "}\n",
    "\n",
    "\n",
    "# --- Define PKG Symptom Colors (remains the same) ---\n",
    "PKG_SYMPTOM_COLORS = {\n",
    "    'Aligned_BK': COLOR_PALETTE_STEP4.get('Aligned_BK', 'steelblue'),\n",
    "    'Aligned_DK': COLOR_PALETTE_STEP4.get('Aligned_DK', 'orangered'),\n",
    "    'Aligned_Tremor_Score': COLOR_PALETTE_STEP4.get('Aligned_Tremor_Score', 'mediumpurple')\n",
    "}\n",
    "\n",
    "# Base output directory name remains based on the content (4 states, no sleep)\n",
    "STATE_SPECIFIC_ANALYSIS_DIR = os.path.join(analysis_session_plot_folder_step4, \"State_Specific_Analyses\")\n",
    "os.makedirs(STATE_SPECIFIC_ANALYSIS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Cell 5_PREAMBLE: Definitions for state-specific analyses (4 States - No Sleep, Separate Mobile, New Order) are set.\")\n",
    "print(f\"Target clinical states for analysis (NEW ORDER): {TARGET_CLINICAL_STATES_ORDERED}\")\n",
    "print(f\"Colors for clinical states: {NEW_CLINICAL_STATE_COLORS_FOR_PLOTTING}\") # This dict remains the same, order of use changes\n",
    "print(f\"State-specific outputs will be saved in subdirectories of: {STATE_SPECIFIC_ANALYSIS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df28e92-33a3-4a24-9544-6334616c6e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 5A (New): State-Specific Correlation Calculations (Revised: No Sleep, 4 Separate Mobile/Immobile States) ---\n",
    "# Calculates Bivariate and Partial correlations for each of the TARGET_CLINICAL_STATES_ORDERED.\n",
    "\n",
    "print(\"\\\\n--- Cell 5A (New): Starting State-Specific Correlation Calculations (4 States - No Sleep, Separate Mobile) ---\")\n",
    "\n",
    "if 'master_df_step4' not in locals() or master_df_step4.empty:\n",
    "    print(\"master_df_step4 not available or empty. Skipping Cell 5A.\")\n",
    "else:\n",
    "    # 1. Filter master_df_step4 directly for the new TARGET_CLINICAL_STATES_ORDERED\n",
    "    # TARGET_CLINICAL_STATES_ORDERED is now [\"Immobile\", \"Transitional Mobile\", \"Non-Dyskinetic Mobile\", \"Dyskinetic Mobile\"]\n",
    "    master_df_step4_filtered_states = master_df_step4[master_df_step4[CLINICAL_STATE_COL].isin(TARGET_CLINICAL_STATES_ORDERED)].copy()\n",
    "\n",
    "    if not master_df_step4_filtered_states.empty:\n",
    "        # Ensure the column is categorical with the specified order for consistent processing\n",
    "        master_df_step4_filtered_states[CLINICAL_STATE_COL] = pd.Categorical(\n",
    "            master_df_step4_filtered_states[CLINICAL_STATE_COL],\n",
    "            categories=TARGET_CLINICAL_STATES_ORDERED,\n",
    "            ordered=True\n",
    "        )\n",
    "        # Drop any rows that might not have matched (e.g., if a state name had a typo or was not in the original data)\n",
    "        master_df_step4_filtered_states.dropna(subset=[CLINICAL_STATE_COL], inplace=True)\n",
    "        \n",
    "        # Add datetime_for_avg if not present (needed for Cell 5B)\n",
    "        if 'datetime_for_avg' not in master_df_step4_filtered_states.columns:\n",
    "            if 'Aligned_PKG_UnixTimestamp' in master_df_step4_filtered_states.columns:\n",
    "                master_df_step4_filtered_states['datetime_for_avg'] = pd.to_datetime(\n",
    "                    master_df_step4_filtered_states['Aligned_PKG_UnixTimestamp'], unit='s', utc=True, errors='coerce'\n",
    "                )\n",
    "            else:\n",
    "                print(\"Warning in Cell 5A: 'Aligned_PKG_UnixTimestamp' missing, 'datetime_for_avg' cannot be created. Cell 5B averaging might fail.\")\n",
    "                master_df_step4_filtered_states['datetime_for_avg'] = pd.NaT\n",
    "\n",
    "\n",
    "    if 'master_df_step4_filtered_states' not in locals() or master_df_step4_filtered_states.empty:\n",
    "        print(f\"No data found after filtering for target clinical states: {TARGET_CLINICAL_STATES_ORDERED}. Skipping Cell 5A.\")\n",
    "    else:\n",
    "        print(f\"Filtered data for target clinical states. Shape: {master_df_step4_filtered_states.shape}. Unique states: {master_df_step4_filtered_states[CLINICAL_STATE_COL].unique()}\")\n",
    "\n",
    "        # UPDATED folder name\n",
    "        state_corr_csv_dir = os.path.join(STATE_SPECIFIC_ANALYSIS_DIR, \"Correlation_CSVs_by_State\")\n",
    "        os.makedirs(state_corr_csv_dir, exist_ok=True)\n",
    "\n",
    "        all_bivariate_ap_pkg_by_state_results = []\n",
    "        all_partial_ap_pkg_by_state_results = []\n",
    "        all_bivariate_ap_osc_by_state_results = []\n",
    "\n",
    "        if CHANNEL_DISPLAY_COL not in master_df_step4_filtered_states.columns:\n",
    "            if CHANNEL_COL in master_df_step4_filtered_states.columns and 'electrode_labels' in locals():\n",
    "                 master_df_step4_filtered_states[CHANNEL_DISPLAY_COL] = master_df_step4_filtered_states[CHANNEL_COL].map(electrode_labels).fillna(master_df_step4_filtered_states[CHANNEL_COL])\n",
    "                 print(f\"'{CHANNEL_DISPLAY_COL}' created from '{CHANNEL_COL}' using electrode_labels map for state-specific analysis.\")\n",
    "\n",
    "        for state_current in TARGET_CLINICAL_STATES_ORDERED: # Loop over the 4 new state categories\n",
    "            df_state = master_df_step4_filtered_states[master_df_step4_filtered_states[CLINICAL_STATE_COL] == state_current]\n",
    "            if df_state.empty:\n",
    "                print(f\"  No data for Clinical State: {state_current}. Skipping correlations for this state.\")\n",
    "                continue\n",
    "            print(f\"\\\\nProcessing Clinical State: {state_current} (N={len(df_state)})\")\n",
    "\n",
    "            for channel_label in ORDERED_CHANNEL_LABELS:\n",
    "                df_channel_state = df_state[df_state[CHANNEL_DISPLAY_COL] == channel_label]\n",
    "                if df_channel_state.empty:\n",
    "                    continue\n",
    "\n",
    "                for freq_label in ORDERED_FREQ_LABELS:\n",
    "                    df_channel_freq_state = df_channel_state[df_channel_state[FOOOF_FREQ_BAND_COL] == freq_label].copy()\n",
    "                    if df_channel_freq_state.empty:\n",
    "                        continue\n",
    "\n",
    "                    # Part 1: Bivariate Aperiodic vs. PKG\n",
    "                    for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "                        for pkg_col, pkg_name in PKG_METRICS_COLS.items():\n",
    "                            if ap_col in df_channel_freq_state.columns and pkg_col in df_channel_freq_state.columns:\n",
    "                                rho, p_val, N = calculate_spearman_with_n(df_channel_freq_state, ap_col, pkg_col)\n",
    "                                all_bivariate_ap_pkg_by_state_results.append({\n",
    "                                    'ClinicalState': state_current, 'Channel': channel_label, 'FreqBand': freq_label,\n",
    "                                    'AperiodicMetric': ap_name, 'PKGMetric': pkg_name,\n",
    "                                    'SpearmanRho': rho, 'PValue': p_val, 'N': N\n",
    "                                })\n",
    "\n",
    "                    # Part 2: Partial Aperiodic vs. PKG (controlling for Beta, Gamma)\n",
    "                    covariates_partial_corr_state = [col for col in OSCILLATORY_METRICS_COLS.keys() if col in df_channel_freq_state.columns]\n",
    "                    if len(covariates_partial_corr_state) == 2:\n",
    "                        for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "                            for pkg_col, pkg_name in PKG_METRICS_COLS.items():\n",
    "                                if ap_col in df_channel_freq_state.columns and pkg_col in df_channel_freq_state.columns:\n",
    "                                    data_for_partial_state = df_channel_freq_state[[ap_col, pkg_col] + covariates_partial_corr_state].dropna()\n",
    "                                    if len(data_for_partial_state) < MIN_SAMPLES_FOR_CORR:\n",
    "                                        partial_rho, partial_p_val, N_partial = np.nan, np.nan, len(data_for_partial_state)\n",
    "                                    else:\n",
    "                                        partial_rho, partial_p_val, N_partial = calculate_partial_spearman(\n",
    "                                            data_for_partial_state, ap_col, pkg_col, covariates_partial_corr_state\n",
    "                                        )\n",
    "                                    all_partial_ap_pkg_by_state_results.append({\n",
    "                                        'ClinicalState': state_current, 'Channel': channel_label, 'FreqBand': freq_label,\n",
    "                                        'AperiodicMetric': ap_name, 'PKGMetric': pkg_name,\n",
    "                                        'PartialSpearmanRho_vs_BetaGamma': partial_rho, 'PartialPValue': partial_p_val, 'N_Partial': N_partial\n",
    "                                    })\n",
    "\n",
    "                    # Part 3: Bivariate Aperiodic vs. Oscillatory\n",
    "                    for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "                        for osc_col, osc_name in OSCILLATORY_METRICS_COLS.items():\n",
    "                            if ap_col in df_channel_freq_state.columns and osc_col in df_channel_freq_state.columns:\n",
    "                                rho_ap_osc, p_val_ap_osc, N_ap_osc = calculate_spearman_with_n(df_channel_freq_state, ap_col, osc_col)\n",
    "                                all_bivariate_ap_osc_by_state_results.append({\n",
    "                                    'ClinicalState': state_current, 'Channel': channel_label, 'FreqBand': freq_label,\n",
    "                                    'AperiodicMetric': ap_name, 'OscillatoryMetric': osc_name,\n",
    "                                    'SpearmanRho': rho_ap_osc, 'PValue': p_val_ap_osc, 'N': N_ap_osc\n",
    "                                })\n",
    "        # UPDATED filenames\n",
    "        if all_bivariate_ap_pkg_by_state_results:\n",
    "            df_bivar_ap_pkg_state = pd.DataFrame(all_bivariate_ap_pkg_by_state_results)\n",
    "            df_bivar_ap_pkg_state.to_csv(os.path.join(state_corr_csv_dir, f\"{patient_hemisphere_id}_Bivariate_AP_vs_PKG_ByState.csv\"), index=False)\n",
    "            print(f\"\\\\nSaved Bivariate AP vs PKG by State (4 States - No Sleep) results for {patient_hemisphere_id}.\")\n",
    "\n",
    "        if all_partial_ap_pkg_by_state_results:\n",
    "            df_partial_ap_pkg_state = pd.DataFrame(all_partial_ap_pkg_by_state_results)\n",
    "            df_partial_ap_pkg_state.to_csv(os.path.join(state_corr_csv_dir, f\"{patient_hemisphere_id}_Partial_AP_vs_PKG_ByState.csv\"), index=False)\n",
    "            print(f\"Saved Partial AP vs PKG (controlling Beta, Gamma) by State (4 States - No Sleep) results for {patient_hemisphere_id}.\")\n",
    "\n",
    "        if all_bivariate_ap_osc_by_state_results:\n",
    "            df_bivar_ap_osc_state = pd.DataFrame(all_bivariate_ap_osc_by_state_results)\n",
    "            df_bivar_ap_osc_state.to_csv(os.path.join(state_corr_csv_dir, f\"{patient_hemisphere_id}_Bivariate_AP_vs_Oscillatory_ByState.csv\"), index=False)\n",
    "            print(f\"Saved Bivariate AP vs Oscillatory by State (4 States - No Sleep) results for {patient_hemisphere_id}.\")\n",
    "\n",
    "print(\"\\\\n--- Cell 5A (New): State-Specific Correlation Calculations (4 States - No Sleep, Separate Mobile) Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4c3778-f82a-46f0-a3f5-8bb2c959bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 5B (New): State-Specific Overview Scatter Plots (Aperiodic vs. PKG) (Revised: No Sleep, 4 Separate Mobile/Immobile States) ---\n",
    "# Generates overview scatter plots: one figure per (PKG_Symptom, Aperiodic_Metric, Channel, FreqBand),\n",
    "# with subplots for each clinical state (now 4 states). Y-axes are standardized within each figure.\n",
    "# Scatter plot points are 10-minute averages. Regression line uses all granular data.\n",
    "\n",
    "print(\"\\\\n--- Cell 5B (New): Starting State-Specific Overview Scatter Plot Generation (4 States - No Sleep, 10-min avg pts) ---\")\n",
    "\n",
    "# Ensure master_df_step4_filtered_states has the correct 4 states from the updated Cell 5A\n",
    "if 'master_df_step4_filtered_states' not in locals() or master_df_step4_filtered_states.empty:\n",
    "    print(\"master_df_step4_filtered_states (with 4 states - No Sleep) not available or empty. Skipping Cell 5B.\")\n",
    "elif 'df_bivar_ap_pkg_state' not in locals() or ('df_bivar_ap_pkg_state' in locals() and df_bivar_ap_pkg_state.empty):\n",
    "    print(\"Bivariate AP vs PKG by State correlation results (df_bivar_ap_pkg_state) not found. Skipping Cell 5B plot annotations.\")\n",
    "    df_bivar_ap_pkg_state = pd.DataFrame(columns=['ClinicalState', 'Channel', 'FreqBand', 'AperiodicMetric', 'PKGMetric', 'SpearmanRho', 'PValue', 'N'])\n",
    "else:\n",
    "    # UPDATED FOLDER NAME\n",
    "    plot_subdir_overview_scatter_state = os.path.join(STATE_SPECIFIC_ANALYSIS_DIR, \"Overview_Scatter_AP_vs_PKG_by_State\")\n",
    "    os.makedirs(plot_subdir_overview_scatter_state, exist_ok=True)\n",
    "\n",
    "    # Ensure 'datetime_for_avg' exists from Cell 5A modifications\n",
    "    if 'datetime_for_avg' not in master_df_step4_filtered_states.columns:\n",
    "        print(\"ERROR in Cell 5B: 'datetime_for_avg' column missing from master_df_step4_filtered_states. Averaging will fail.\")\n",
    "        # Fallback or exit\n",
    "    else:\n",
    "        for pkg_col_overview, pkg_name_overview in PKG_METRICS_COLS.items():\n",
    "            # ... (rest of the loops for ap_metric, channel, freq_band are the same as the last version of 5B) ...\n",
    "            # Key is that TARGET_CLINICAL_STATES_ORDERED (now 4 states) and \n",
    "            # NEW_CLINICAL_STATE_COLORS_FOR_PLOTTING (with original mobile colors) are used.\n",
    "            # The number of subplots will be len(TARGET_CLINICAL_STATES_ORDERED) -> 4.\n",
    "\n",
    "            if pkg_col_overview not in master_df_step4_filtered_states.columns:\n",
    "                print(f\"PKG Metric {pkg_name_overview} ({pkg_col_overview}) not found in data. Skipping its overview plots.\")\n",
    "                continue\n",
    "\n",
    "            for ap_metric_overview_col, ap_metric_overview_name in APERIODIC_METRICS_COLS.items():\n",
    "                if ap_metric_overview_col not in master_df_step4_filtered_states.columns:\n",
    "                    print(f\"Aperiodic Metric {ap_metric_overview_name} ({ap_metric_overview_col}) not found. Skipping its overview plots.\")\n",
    "                    continue\n",
    "                \n",
    "                print(f\"\\\\nGenerating overview plots for: {ap_metric_overview_name} vs. {pkg_name_overview}\")\n",
    "\n",
    "                for channel_label_overview in ORDERED_CHANNEL_LABELS:\n",
    "                    for freq_label_overview in ORDERED_FREQ_LABELS:\n",
    "                        \n",
    "                        fig_width = max(15, 4 * len(TARGET_CLINICAL_STATES_ORDERED)) # Now 4 states\n",
    "                        fig, axes = plt.subplots(1, len(TARGET_CLINICAL_STATES_ORDERED), \n",
    "                                                 figsize=(fig_width, 5.5), sharey=False)\n",
    "                        if len(TARGET_CLINICAL_STATES_ORDERED) == 1: # Should not happen with 4 states, but good practice\n",
    "                            axes = [axes]\n",
    "                        \n",
    "                        fig.suptitle(f\"{ap_metric_overview_name} vs. {pkg_name_overview}\\\\nChannel: {channel_label_overview} - Freq: {freq_label_overview} - Patient: {patient_hemisphere_id}\\\\n(Scatter points are 10-min averages; Regression on all raw data)\",\n",
    "                                     fontsize=plt.rcParams['figure.titlesize'] * 0.85, y=1.05)\n",
    "\n",
    "                        all_ap_values_for_ylim = []\n",
    "                        valid_plot_exists_for_figure = False \n",
    "\n",
    "                        for i, state_overview_ylim in enumerate(TARGET_CLINICAL_STATES_ORDERED): # Iterates 4 states\n",
    "                            df_current_combo_ylim_pass = master_df_step4_filtered_states[\n",
    "                                (master_df_step4_filtered_states[CLINICAL_STATE_COL] == state_overview_ylim) &\n",
    "                                (master_df_step4_filtered_states[CHANNEL_DISPLAY_COL] == channel_label_overview) &\n",
    "                                (master_df_step4_filtered_states[FOOOF_FREQ_BAND_COL] == freq_label_overview)\n",
    "                            ]\n",
    "                            cols_to_drop_na_for_ylim_pass = [ap_metric_overview_col, pkg_col_overview, 'datetime_for_avg']\n",
    "                            \n",
    "                            df_plot_data_ylim_pass = df_current_combo_ylim_pass.dropna(subset=cols_to_drop_na_for_ylim_pass)\n",
    "                            \n",
    "                            if not df_plot_data_ylim_pass.empty and len(df_plot_data_ylim_pass) >= MIN_SAMPLES_FOR_CORR:\n",
    "                                all_ap_values_for_ylim.extend(df_plot_data_ylim_pass[ap_metric_overview_col].tolist())\n",
    "                        \n",
    "                        min_y, max_y = (np.nan, np.nan)\n",
    "                        if all_ap_values_for_ylim: \n",
    "                            min_y_val_calc = np.nanmin(all_ap_values_for_ylim)\n",
    "                            max_y_val_calc = np.nanmax(all_ap_values_for_ylim)\n",
    "                            if not (np.isnan(min_y_val_calc) or np.isnan(max_y_val_calc)):\n",
    "                                 padding = (max_y_val_calc - min_y_val_calc) * 0.1 if (max_y_val_calc - min_y_val_calc) > 0 else 0.1\n",
    "                                 min_y = min_y_val_calc - padding\n",
    "                                 max_y = max_y_val_calc + padding\n",
    "                                 \n",
    "                        for i, state_overview in enumerate(TARGET_CLINICAL_STATES_ORDERED): # Iterates 4 states\n",
    "                            ax = axes[i]\n",
    "                            df_current_combo_plot = master_df_step4_filtered_states[\n",
    "                                (master_df_step4_filtered_states[CLINICAL_STATE_COL] == state_overview) &\n",
    "                                (master_df_step4_filtered_states[CHANNEL_DISPLAY_COL] == channel_label_overview) &\n",
    "                                (master_df_step4_filtered_states[FOOOF_FREQ_BAND_COL] == freq_label_overview)\n",
    "                            ]\n",
    "                            \n",
    "                            cols_to_drop_na_plot = [ap_metric_overview_col, pkg_col_overview, 'datetime_for_avg']\n",
    "                            df_plot_data_granular_plot = df_current_combo_plot.dropna(subset=cols_to_drop_na_plot)\n",
    "\n",
    "                            if not df_plot_data_granular_plot.empty and len(df_plot_data_granular_plot) >= MIN_SAMPLES_FOR_CORR :\n",
    "                                valid_plot_exists_for_figure = True \n",
    "\n",
    "                                corr_stats_row = df_bivar_ap_pkg_state[\n",
    "                                    (df_bivar_ap_pkg_state['ClinicalState'] == state_overview) &\n",
    "                                    (df_bivar_ap_pkg_state['Channel'] == channel_label_overview) &\n",
    "                                    (df_bivar_ap_pkg_state['FreqBand'] == freq_label_overview) &\n",
    "                                    (df_bivar_ap_pkg_state['AperiodicMetric'] == ap_metric_overview_name) &\n",
    "                                    (df_bivar_ap_pkg_state['PKGMetric'] == pkg_name_overview)\n",
    "                                ]\n",
    "                                rho = corr_stats_row['SpearmanRho'].iloc[0] if not corr_stats_row.empty else np.nan\n",
    "                                p_val = corr_stats_row['PValue'].iloc[0] if not corr_stats_row.empty else np.nan\n",
    "                                N_val = corr_stats_row['N'].iloc[0] if not corr_stats_row.empty else len(df_plot_data_granular_plot)\n",
    "\n",
    "                                df_averaged_points_plot = pd.DataFrame()\n",
    "                                if 'datetime_for_avg' in df_plot_data_granular_plot.columns and \\\n",
    "                                   not df_plot_data_granular_plot['datetime_for_avg'].isnull().all():\n",
    "                                    try:\n",
    "                                        df_averaged_points_plot = df_plot_data_granular_plot.set_index('datetime_for_avg')\\\n",
    "                                            .groupby(pd.Grouper(freq='10T'))[[ap_metric_overview_col, pkg_col_overview]]\\\n",
    "                                            .mean().dropna()\n",
    "                                    except Exception as e_avg: \n",
    "                                        print(f\"Warning: 10-min averaging failed for {channel_label_overview}, {freq_label_overview}, {state_overview}. Plotting granular points. Error: {e_avg}\")\n",
    "                                        df_averaged_points_plot = df_plot_data_granular_plot \n",
    "                                else: \n",
    "                                    df_averaged_points_plot = df_plot_data_granular_plot\n",
    "\n",
    "                                if not df_averaged_points_plot.empty:\n",
    "                                    sns.scatterplot(data=df_averaged_points_plot, x=pkg_col_overview, y=ap_metric_overview_col,\n",
    "                                                    color=NEW_CLINICAL_STATE_COLORS_FOR_PLOTTING.get(state_overview, 'grey'),\n",
    "                                                    alpha=DOT_ALPHA_STEP4 + 0.2, s=40, edgecolor='black', linewidths=0.5, ax=ax, legend=False)\n",
    "\n",
    "                                sns.regplot(data=df_plot_data_granular_plot, x=pkg_col_overview, y=ap_metric_overview_col, scatter=False, ax=ax,\n",
    "                                            line_kws={'color': 'black', 'linewidth': 1.5, 'alpha': 0.6})\n",
    "                                \n",
    "                                annotate_correlation_on_plot(ax, rho, p_val, N_val, fontsize=8)\n",
    "                                ax.set_title(state_overview, fontsize=plt.rcParams['axes.titlesize']*0.8)\n",
    "                                ax.set_xlabel(pkg_name_overview if i == len(TARGET_CLINICAL_STATES_ORDERED) // 2 else \"\", fontsize=plt.rcParams['axes.labelsize']*0.9)\n",
    "                                \n",
    "                                if not pd.isna(min_y) and not pd.isna(max_y):\n",
    "                                    ax.set_ylim(min_y, max_y)\n",
    "                            else:\n",
    "                                ax.text(0.5, 0.5, \"N < min_samples\" if len(df_plot_data_granular_plot) < MIN_SAMPLES_FOR_CORR else \"No Data\", \n",
    "                                        horizontalalignment='center', verticalalignment='center', transform=ax.transAxes, fontsize=9)\n",
    "                                ax.set_title(state_overview, fontsize=plt.rcParams['axes.titlesize']*0.8)\n",
    "                                if not pd.isna(min_y) and not pd.isna(max_y): \n",
    "                                    ax.set_ylim(min_y, max_y)\n",
    "\n",
    "                            if i == 0:\n",
    "                                ax.set_ylabel(ap_metric_overview_name, fontsize=plt.rcParams['axes.labelsize'])\n",
    "                            else:\n",
    "                                ax.set_ylabel(\"\")\n",
    "                                ax.set_yticklabels([])\n",
    "                            \n",
    "                            ax.tick_params(axis='x', labelsize=plt.rcParams['xtick.labelsize']*0.9)\n",
    "                            ax.tick_params(axis='y', labelsize=plt.rcParams['ytick.labelsize']*0.9)\n",
    "\n",
    "                        if valid_plot_exists_for_figure: \n",
    "                            plt.tight_layout(rect=[0, 0.03, 1, 0.93]) \n",
    "                            safe_ap_name = get_safe_filename_step4(ap_metric_overview_name)\n",
    "                            safe_pkg_name = get_safe_filename_step4(pkg_name_overview)\n",
    "                            safe_ch_name = get_safe_filename_step4(channel_label_overview)\n",
    "                            safe_freq_name = get_safe_filename_step4(freq_label_overview)\n",
    "                            # UPDATED FILENAME\n",
    "                            plot_filename = f\"Overview_{safe_ap_name}_vs_{safe_pkg_name}_{safe_ch_name}_{safe_freq_name}.png\" \n",
    "                            plt.savefig(os.path.join(plot_subdir_overview_scatter_state, plot_filename))\n",
    "                        plt.close(fig)\n",
    "\n",
    "print(\"\\\\n--- Cell 5B (New): State-Specific Overview Scatter Plot Generation (4 States - No Sleep, 10-min avg pts) Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14e58fe-c0da-4663-8c61-7012ebb94026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 5C (Revised Logic v3): State-Specific Heatmaps for Exponent/Offset vs. PKG ---\n",
    "# Generates heatmaps of Partial Spearman correlations (Aperiodic vs. PKG, controlling for Beta/Gamma).\n",
    "# Separate plots for Exponent and Offset. Columns are PKG metrics (BK, DK, Tremor).\n",
    "# Significance stars are bold. Annotations show rho and stars only.\n",
    "\n",
    "print(\"\\\\n--- Cell 5C (Revised Logic v3): Starting State-Specific Heatmap Generation for Aperiodic vs. PKG ---\")\n",
    "\n",
    "if 'df_partial_ap_pkg_state' not in locals() or df_partial_ap_pkg_state.empty:\n",
    "    print(\"State-specific partial correlation data (df_partial_ap_pkg_state) not available or empty. Skipping Cell 5C.\")\n",
    "else:\n",
    "    plot_subdir_heatmaps_state = os.path.join(STATE_SPECIFIC_ANALYSIS_DIR, \"Heatmaps_PartialCorrelations_by_State_Revised\")\n",
    "    os.makedirs(plot_subdir_heatmaps_state, exist_ok=True)\n",
    "\n",
    "    # Define short PKG names for heatmap columns and their desired order\n",
    "    PKG_DISPLAY_NAME_MAP = {\n",
    "        'PKG BK Score': 'BK',\n",
    "        'PKG DK Score': 'DK',\n",
    "        'PKG Tremor Score': 'Tremor' \n",
    "    }\n",
    "    ORDERED_PKG_METRIC_ORIGINAL_NAMES = [\n",
    "        PKG_METRICS_COLS.get('Aligned_BK', 'PKG BK Score'),\n",
    "        PKG_METRICS_COLS.get('Aligned_DK', 'PKG DK Score'),\n",
    "        PKG_METRICS_COLS.get('Aligned_Tremor_Score', 'PKG Tremor Score')\n",
    "    ]\n",
    "    ORDERED_PKG_SHORT_NAMES_FOR_HEATMAP = [PKG_DISPLAY_NAME_MAP[name] for name in ORDERED_PKG_METRIC_ORIGINAL_NAMES if name in PKG_DISPLAY_NAME_MAP]\n",
    "\n",
    "    for ap_metric_key_loop, ap_metric_name_display_loop in APERIODIC_METRICS_COLS.items():\n",
    "        \n",
    "        print(f\"\\\\n=== Generating Heatmaps for Aperiodic Metric: {ap_metric_name_display_loop} ===\")\n",
    "\n",
    "        for state_heatmap in TARGET_CLINICAL_STATES_ORDERED: \n",
    "            df_current_state_all_ap_corrs = df_partial_ap_pkg_state[df_partial_ap_pkg_state['ClinicalState'] == state_heatmap]\n",
    "            \n",
    "            df_current_state_single_ap_corrs = df_current_state_all_ap_corrs[\n",
    "                df_current_state_all_ap_corrs['AperiodicMetric'] == ap_metric_name_display_loop\n",
    "            ].copy() \n",
    "\n",
    "            if df_current_state_single_ap_corrs.empty:\n",
    "                continue\n",
    "            \n",
    "            for freq_label_heatmap in ORDERED_FREQ_LABELS:\n",
    "                df_heatmap_data_filtered = df_current_state_single_ap_corrs[\n",
    "                    df_current_state_single_ap_corrs['FreqBand'] == freq_label_heatmap\n",
    "                ].copy()\n",
    "\n",
    "                if df_heatmap_data_filtered.empty:\n",
    "                    continue\n",
    "                \n",
    "                print(f\"  Generating heatmap for Aperiodic: {ap_metric_name_display_loop}, State: {state_heatmap}, Freq: {freq_label_heatmap}\")\n",
    "\n",
    "                df_heatmap_data_filtered['PKGMetricShort'] = df_heatmap_data_filtered['PKGMetric'].map(PKG_DISPLAY_NAME_MAP)\n",
    "                df_heatmap_data_filtered = df_heatmap_data_filtered[df_heatmap_data_filtered['PKGMetricShort'].notna()]\n",
    "\n",
    "                if df_heatmap_data_filtered.empty:\n",
    "                    continue\n",
    "\n",
    "                pivot_index_col = CHANNEL_DISPLAY_COL if CHANNEL_DISPLAY_COL in df_heatmap_data_filtered.columns else 'Channel'\n",
    "\n",
    "                try:\n",
    "                    heatmap_pivot_rho = df_heatmap_data_filtered.pivot_table(\n",
    "                        index=pivot_index_col, \n",
    "                        columns='PKGMetricShort', \n",
    "                        values='PartialSpearmanRho_vs_BetaGamma',\n",
    "                        aggfunc='first'\n",
    "                    )\n",
    "                    heatmap_pivot_rho = heatmap_pivot_rho.reindex(\n",
    "                        index=[ch for ch in ORDERED_CHANNEL_LABELS if ch in heatmap_pivot_rho.index],\n",
    "                        columns=[name for name in ORDERED_PKG_SHORT_NAMES_FOR_HEATMAP if name in heatmap_pivot_rho.columns]\n",
    "                    ).dropna(how='all', axis=0).dropna(how='all', axis=1)\n",
    "\n",
    "                    heatmap_pivot_annot_underlying_data = df_heatmap_data_filtered.pivot_table(\n",
    "                        index=pivot_index_col,\n",
    "                        columns='PKGMetricShort', \n",
    "                        values=['PartialPValue', 'N_Partial'], # N_Partial still needed for significance logic\n",
    "                        aggfunc='first'\n",
    "                    )\n",
    "                    if not heatmap_pivot_annot_underlying_data.empty:\n",
    "                        heatmap_pivot_annot_underlying_data = heatmap_pivot_annot_underlying_data.reindex(\n",
    "                            index=[ch for ch in ORDERED_CHANNEL_LABELS if ch in heatmap_pivot_annot_underlying_data.index]\n",
    "                        )\n",
    "                        valid_pkg_cols_for_annot = [name for name in ORDERED_PKG_SHORT_NAMES_FOR_HEATMAP if name in heatmap_pivot_rho.columns]\n",
    "                        \n",
    "                        cols_to_reindex_annot = []\n",
    "                        for val_type in ['PartialPValue', 'N_Partial']:\n",
    "                            for pkg_short_name in valid_pkg_cols_for_annot:\n",
    "                                if (val_type, pkg_short_name) in heatmap_pivot_annot_underlying_data.columns:\n",
    "                                    cols_to_reindex_annot.append((val_type, pkg_short_name))\n",
    "                        \n",
    "                        if cols_to_reindex_annot:\n",
    "                             heatmap_pivot_annot_underlying_data = heatmap_pivot_annot_underlying_data.reindex(\n",
    "                                 columns=pd.MultiIndex.from_tuples(cols_to_reindex_annot)\n",
    "                             ).dropna(how='all', axis=0)\n",
    "                        else:\n",
    "                             heatmap_pivot_annot_underlying_data = pd.DataFrame(index=heatmap_pivot_annot_underlying_data.index)\n",
    "\n",
    "                except Exception as e_pivot_state:\n",
    "                    print(f\"    Error pivoting data for heatmap (Aperiodic: {ap_metric_name_display_loop}, State: {state_heatmap}, Freq: {freq_label_heatmap}): {e_pivot_state}. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                if heatmap_pivot_rho.empty:\n",
    "                    continue\n",
    "                \n",
    "                annot_text_final = heatmap_pivot_rho.copy().astype(object) \n",
    "                for r_idx in heatmap_pivot_rho.index:\n",
    "                    for c_idx_pkg_short_name in heatmap_pivot_rho.columns: \n",
    "                        rho_val = heatmap_pivot_rho.loc[r_idx, c_idx_pkg_short_name]\n",
    "                        \n",
    "                        p_val_val = np.nan\n",
    "                        n_val = 0\n",
    "                        \n",
    "                        if r_idx in heatmap_pivot_annot_underlying_data.index:\n",
    "                            p_val_col_tuple = ('PartialPValue', c_idx_pkg_short_name)\n",
    "                            n_val_col_tuple = ('N_Partial', c_idx_pkg_short_name)\n",
    "\n",
    "                            if p_val_col_tuple in heatmap_pivot_annot_underlying_data.columns:\n",
    "                                p_val_val = heatmap_pivot_annot_underlying_data.loc[r_idx, p_val_col_tuple]\n",
    "                            if n_val_col_tuple in heatmap_pivot_annot_underlying_data.columns:\n",
    "                                n_val = heatmap_pivot_annot_underlying_data.loc[r_idx, n_val_col_tuple]\n",
    "                        \n",
    "                        if pd.isna(rho_val):\n",
    "                            annot_text_final.loc[r_idx, c_idx_pkg_short_name] = \"N/A\"\n",
    "                        else:\n",
    "                            stars_str = \"\"\n",
    "                            if pd.notna(p_val_val) and pd.notna(n_val) and n_val >= MIN_SAMPLES_FOR_CORR:\n",
    "                                if p_val_val < 0.001: stars_str = \"***\"\n",
    "                                elif p_val_val < 0.01: stars_str = \"**\"\n",
    "                                elif p_val_val < P_VALUE_THRESHOLD: stars_str = \"*\"\n",
    "                            \n",
    "                            stars_formatted_str = \"\" # Renamed from stars_colored_str\n",
    "                            if stars_str: \n",
    "                                # Matplotlib mathtext string for bold stars (color removed)\n",
    "                                stars_formatted_str = f\"$\\\\mathbf{{{stars_str}}}$\"\n",
    "                                \n",
    "                            annot_text_final.loc[r_idx, c_idx_pkg_short_name] = f\"{rho_val:.2f}{stars_formatted_str}\"\n",
    "\n",
    "                plt.figure(figsize=(max(8, heatmap_pivot_rho.shape[1] * 2.5), max(6, heatmap_pivot_rho.shape[0] * 0.9)))\n",
    "                sns.heatmap(heatmap_pivot_rho.astype(float), annot=annot_text_final, fmt='s', \n",
    "                            cmap=\"coolwarm_r\", center=0, vmin=-1, vmax=1,\n",
    "                            linewidths=.5, linecolor='grey', cbar_kws={'label': f\"Partial Spearman œÅ\\n({ap_metric_name_display_loop} vs. PKG, ctrl Beta,Gamma)\"},\n",
    "                            annot_kws={\"size\": 9}) \n",
    "                \n",
    "                plt.title(f\"Partial Corr: {ap_metric_name_display_loop} vs. PKG (ctrl Beta,Gamma)\\nState: {state_heatmap} - Freq: {freq_label_heatmap} - Patient: {patient_hemisphere_id}\",\n",
    "                          fontsize=plt.rcParams['figure.titlesize']*0.80) \n",
    "                plt.ylabel(\"Channel\", fontsize=plt.rcParams['axes.labelsize'])\n",
    "                plt.xlabel(\"PKG Symptom\", fontsize=plt.rcParams['axes.labelsize']) \n",
    "                plt.xticks(rotation=0, ha=\"center\", fontsize=plt.rcParams['xtick.labelsize']*0.9) \n",
    "                plt.yticks(rotation=0, fontsize=plt.rcParams['ytick.labelsize']*0.9)\n",
    "                plt.tight_layout(rect=[0,0,1,0.92]) \n",
    "\n",
    "                safe_ap_name_file = get_safe_filename_step4(ap_metric_name_display_loop)\n",
    "                safe_state_name_file = get_safe_filename_step4(state_heatmap)\n",
    "                safe_freq_name_file = get_safe_filename_step4(freq_label_heatmap)\n",
    "                \n",
    "                plot_filename_heatmap = f\"Heatmap_PartialCorr_{safe_ap_name_file}_PKG_{safe_state_name_file}_{safe_freq_name_file}.png\"\n",
    "                plt.savefig(os.path.join(plot_subdir_heatmaps_state, plot_filename_heatmap))\n",
    "                plt.close()\n",
    "                # print(f\"    Saved partial correlation heatmap for {ap_metric_name_display_loop}, State: {state_heatmap}, Freq Band: {freq_label_heatmap}\")\n",
    "\n",
    "print(\"\\\\n--- Cell 5C (Revised Logic v3): State-Specific Heatmap Generation for Aperiodic vs. PKG Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf8f89-5f27-4586-8c02-cb669fb59433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 5D (New): Plot Spearman Coefficients vs. Clinical States (Revised for 4 States) ---\n",
    "# Generates line plots showing how Spearman Rho (Aperiodic vs PKG) changes across clinical states (now 4 states).\n",
    "# Separate plots for Exponent-PKG and Offset-PKG correlations.\n",
    "\n",
    "print(\"\\\\n--- Cell 5D (New): Starting Spearman Coefficients vs. Clinical States Plot Generation (4 States) ---\")\n",
    "\n",
    "# Ensure df_bivar_ap_pkg_state is the remapped version from the updated Cell 5A\n",
    "if 'df_bivar_ap_pkg_state' not in locals() or df_bivar_ap_pkg_state.empty:\n",
    "    print(\"State-specific bivariate AP vs PKG correlation data (df_bivar_ap_pkg_state) not available. Skipping Cell 5D.\")\n",
    "else:\n",
    "    # UPDATED FOLDER NAME\n",
    "    plot_subdir_coeff_vs_state = os.path.join(STATE_SPECIFIC_ANALYSIS_DIR, \"SpearmanCoeff_vs_ClinicalState\")\n",
    "    os.makedirs(plot_subdir_coeff_vs_state, exist_ok=True)\n",
    "\n",
    "    # Ensure the dataframe has the clinical states in the desired order for plotting\n",
    "    # TARGET_CLINICAL_STATES_ORDERED is now the 4-state list from Cell 5_PREAMBLE\n",
    "    df_bivar_ap_pkg_state_ordered_for_coeff_plot = df_bivar_ap_pkg_state.copy()\n",
    "    df_bivar_ap_pkg_state_ordered_for_coeff_plot['ClinicalState'] = pd.Categorical(\n",
    "        df_bivar_ap_pkg_state_ordered_for_coeff_plot['ClinicalState'],\n",
    "        categories=TARGET_CLINICAL_STATES_ORDERED, # Uses the 4-state list\n",
    "        ordered=True\n",
    "    )\n",
    "    # No need to sort here as .reindex later will handle order for plotting\n",
    "\n",
    "    for ap_metric_key, ap_metric_name_display in APERIODIC_METRICS_COLS.items():\n",
    "        print(f\"\\\\nProcessing coefficient plots for Aperiodic Metric: {ap_metric_name_display}\")\n",
    "        \n",
    "        df_ap_metric_subset_coeff = df_bivar_ap_pkg_state_ordered_for_coeff_plot[\n",
    "            df_bivar_ap_pkg_state_ordered_for_coeff_plot['AperiodicMetric'] == ap_metric_name_display\n",
    "        ]\n",
    "        if df_ap_metric_subset_coeff.empty:\n",
    "            print(f\"  No data for aperiodic metric: {ap_metric_name_display}. Skipping its plot.\")\n",
    "            continue\n",
    "\n",
    "        for channel_label_coeff_plot in ORDERED_CHANNEL_LABELS:\n",
    "            for freq_label_coeff_plot in ORDERED_FREQ_LABELS:\n",
    "                \n",
    "                df_plot_final_coeff = df_ap_metric_subset_coeff[\n",
    "                    (df_ap_metric_subset_coeff['Channel'] == channel_label_coeff_plot) &\n",
    "                    (df_ap_metric_subset_coeff['FreqBand'] == freq_label_coeff_plot)\n",
    "                ]\n",
    "\n",
    "                if df_plot_final_coeff.empty:\n",
    "                    continue\n",
    "\n",
    "                fig, ax = plt.subplots(figsize=(10, 6)) # Adjusted figsize slightly\n",
    "                has_data_for_plot = False\n",
    "\n",
    "                for pkg_col_coeff, pkg_name_coeff_display in PKG_METRICS_COLS.items():\n",
    "                    df_pkg_symptom_subset_coeff = df_plot_final_coeff[\n",
    "                        df_plot_final_coeff['PKGMetric'] == pkg_name_coeff_display\n",
    "                    ]\n",
    "                    \n",
    "                    if not df_pkg_symptom_subset_coeff.empty:\n",
    "                        pivoted_for_plot = df_pkg_symptom_subset_coeff.pivot_table(\n",
    "                            index='ClinicalState', values='SpearmanRho', aggfunc='mean' \n",
    "                        ).reindex(TARGET_CLINICAL_STATES_ORDERED) # Ensure correct order & NaNs for missing\n",
    "\n",
    "                        if not pivoted_for_plot['SpearmanRho'].isnull().all():\n",
    "                            ax.plot(pivoted_for_plot.index.astype(str), pivoted_for_plot['SpearmanRho'], # x-axis as string for categorical\n",
    "                                    marker='o', markersize=7, linestyle='-', linewidth=1.5,\n",
    "                                    label=pkg_name_coeff_display,\n",
    "                                    color=PKG_SYMPTOM_COLORS.get(pkg_col_coeff, 'grey'))\n",
    "                            has_data_for_plot = True\n",
    "                \n",
    "                if has_data_for_plot:\n",
    "                    ax.set_title(f\"Spearman œÅ ({ap_metric_name_display} vs. PKG) by Clinical State\\\\n{channel_label_coeff_plot} - {freq_label_coeff_plot} - Patient: {patient_hemisphere_id}\",\n",
    "                                 fontsize=plt.rcParams['axes.titlesize']*0.9)\n",
    "                    ax.set_xlabel(\"Clinical State\", fontsize=plt.rcParams['axes.labelsize'])\n",
    "                    ax.set_ylabel(\"Spearman Correlation Coefficient (œÅ)\", fontsize=plt.rcParams['axes.labelsize'])\n",
    "                    ax.legend(title=\"PKG Symptom\", loc='center left', bbox_to_anchor=(1, 0.5)) # Adjusted legend position\n",
    "                    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "                    plt.xticks(rotation=20, ha=\"right\", fontsize=plt.rcParams['xtick.labelsize']*0.9)\n",
    "                    ax.axhline(0, color='black', linewidth=0.8, linestyle='--') \n",
    "                    ax.set_ylim(-1.05, 1.05) # Ensure full range is visible\n",
    "\n",
    "                    plt.tight_layout(rect=[0, 0, 0.85, 0.95]) # Adjust for legend\n",
    "                    \n",
    "                    safe_ap_name_coeff = get_safe_filename_step4(ap_metric_name_display)\n",
    "                    safe_ch_name_coeff = get_safe_filename_step4(channel_label_coeff_plot)\n",
    "                    safe_freq_name_coeff = get_safe_filename_step4(freq_label_coeff_plot)\n",
    "                    \n",
    "                    # UPDATED FILENAME\n",
    "                    plot_filename_coeff = f\"CoeffVsState_{safe_ap_name_coeff}_{safe_ch_name_coeff}_{safe_freq_name_coeff}.png\"\n",
    "                    plt.savefig(os.path.join(plot_subdir_coeff_vs_state, plot_filename_coeff))\n",
    "                plt.close(fig)\n",
    "\n",
    "print(\"\\\\n--- Cell 5D (New): Spearman Coefficients vs. Clinical States Plot Generation (4 States) Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86625908-89d9-4fce-9aa4-209ab50e8e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 5 (Revised with 15-min Averaged Scatter Points): Bivariate & Partial Correlations, Aperiodic vs. Beta/Gamma ---\n",
    "# Iterates through Channel_Display AND FreqRangeLabel\n",
    "# Scatter points are 15-min averages; regression lines use all granular data.\n",
    "\n",
    "print(\"\\\\n--- Cell 5 (Revised with 15-min Averaged Scatter Points): Starting Correlation Analyses ---\")\n",
    "\n",
    "if 'master_df_step4' not in locals() or master_df_step4 is None or master_df_step4.empty:\n",
    "    print(\"master_df_step4 not available or empty. Skipping Cell 5.\")\n",
    "else:\n",
    "    # Create a working copy to add a datetime column for averaging\n",
    "    master_df_step4_processed_c5 = master_df_step4.copy()\n",
    "    if 'Aligned_PKG_UnixTimestamp' in master_df_step4_processed_c5.columns:\n",
    "        master_df_step4_processed_c5['datetime_for_avg_c5'] = pd.to_datetime(\n",
    "            master_df_step4_processed_c5['Aligned_PKG_UnixTimestamp'], unit='s', utc=True, errors='coerce'\n",
    "        )\n",
    "        if master_df_step4_processed_c5['datetime_for_avg_c5'].isnull().all():\n",
    "            print(\"Warning in Cell 5: 'datetime_for_avg_c5' could not be created (all NaT). 15-min averaging might fail or use granular points.\")\n",
    "    else:\n",
    "        print(\"Warning in Cell 5: 'Aligned_PKG_UnixTimestamp' not found. Cannot perform 15-minute averaging for scatter plots. Will plot granular points.\")\n",
    "        master_df_step4_processed_c5['datetime_for_avg_c5'] = pd.NaT \n",
    "\n",
    "    # Create subdirectories for plots from this cell (removed suffix)\n",
    "    plot_subdir_bivariate_ap_pkg = os.path.join(analysis_session_plot_folder_step4, \"Bivariate_AP_vs_PKG\")\n",
    "    plot_subdir_bivariate_ap_osc = os.path.join(analysis_session_plot_folder_step4, \"Bivariate_AP_vs_Oscillatory\")\n",
    "    os.makedirs(plot_subdir_bivariate_ap_pkg, exist_ok=True)\n",
    "    os.makedirs(plot_subdir_bivariate_ap_osc, exist_ok=True)\n",
    "\n",
    "    all_bivariate_ap_pkg_results = []\n",
    "    all_partial_ap_pkg_results = [] \n",
    "    all_bivariate_ap_osc_results = []\n",
    "\n",
    "    for channel_label in ORDERED_CHANNEL_LABELS: \n",
    "        df_channel = master_df_step4_processed_c5[master_df_step4_processed_c5[CHANNEL_DISPLAY_COL] == channel_label]\n",
    "        if df_channel.empty:\n",
    "            print(f\"\\\\nNo data for channel: {channel_label}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\\\nProcessing Channel: {channel_label}\")\n",
    "\n",
    "        for freq_label in ORDERED_FREQ_LABELS: \n",
    "            df_channel_freq = df_channel[df_channel[FOOOF_FREQ_BAND_COL] == freq_label].copy()\n",
    "            if df_channel_freq.empty:\n",
    "                print(f\"  No data for Freq Band: {freq_label} in Channel: {channel_label}. Skipping.\")\n",
    "                continue\n",
    "            print(f\"  Processing Freq Band: {freq_label}\")\n",
    "\n",
    "            # --- Part 5.1: Bivariate Spearman Correlations (Aperiodic vs. PKG) ---\n",
    "            print(f\"    Part 5.1: Bivariate Aperiodic vs. PKG Correlations for {channel_label} ({freq_label})\")\n",
    "            for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "                for pkg_col, pkg_name in PKG_METRICS_COLS.items():\n",
    "                    df_granular_for_corr_pkg = df_channel_freq.dropna(subset=[ap_col, pkg_col])\n",
    "                    rho, p_val, N = calculate_spearman_with_n(df_granular_for_corr_pkg, ap_col, pkg_col)\n",
    "                    \n",
    "                    all_bivariate_ap_pkg_results.append({\n",
    "                        'Channel': channel_label, 'FreqBand': freq_label,\n",
    "                        'AperiodicMetric': ap_name, 'PKGMetric': pkg_name,\n",
    "                        'SpearmanRho': rho, 'PValue': p_val, 'N': N\n",
    "                    })\n",
    "\n",
    "                    if N >= MIN_SAMPLES_FOR_CORR:\n",
    "                        plt.figure(figsize=(7, 6))\n",
    "                        ax = plt.gca() \n",
    "\n",
    "                        df_averaged_points_pkg = pd.DataFrame()\n",
    "                        # Check if 'datetime_for_avg_c5' exists and has non-null values before attempting to use it as index\n",
    "                        if 'datetime_for_avg_c5' in df_granular_for_corr_pkg.columns and \\\n",
    "                           not df_granular_for_corr_pkg['datetime_for_avg_c5'].isnull().all():\n",
    "                            try:\n",
    "                                # MODIFIED: Changed to 5T for 5-minute averaging\n",
    "                                df_averaged_points_pkg = df_granular_for_corr_pkg.set_index('datetime_for_avg_c5')\\\n",
    "                                    .groupby(pd.Grouper(freq='5T'))[[ap_col, pkg_col]]\\\n",
    "                                    .mean().dropna()\n",
    "                            except Exception as e_avg_pkg:\n",
    "                                # MODIFIED: Warning message for 5-min\n",
    "                                print(f\"      Warning: 5-min averaging failed for PKG plot ({ap_name} vs {pkg_name}). Plotting granular. Error: {e_avg_pkg}\")\n",
    "                                df_averaged_points_pkg = df_granular_for_corr_pkg \n",
    "                        else:\n",
    "                            df_averaged_points_pkg = df_granular_for_corr_pkg \n",
    "                        \n",
    "                        if df_averaged_points_pkg.empty and not df_granular_for_corr_pkg.empty:\n",
    "                            df_averaged_points_pkg = df_granular_for_corr_pkg\n",
    "                        \n",
    "                        if not df_averaged_points_pkg.empty:\n",
    "                             sns.scatterplot(data=df_averaged_points_pkg, x=pkg_col, y=ap_col,\n",
    "                                            color=COLOR_PALETTE_STEP4.get(ap_col, 'grey'), \n",
    "                                            alpha=DOT_ALPHA_STEP4 + 0.1, s=40, \n",
    "                                            edgecolor='k', linewidths=0.5, ax=ax)\n",
    "                        \n",
    "                        sns.regplot(data=df_granular_for_corr_pkg, x=pkg_col, y=ap_col, scatter=False, ax=ax,\n",
    "                                    line_kws={'color': COLOR_PALETTE_STEP4.get(pkg_col, 'black'), \n",
    "                                              'linewidth': REG_LINE_THICKNESS_STEP4, 'alpha': 0.7})\n",
    "                        \n",
    "                        annotate_correlation_on_plot(ax, rho, p_val, N) \n",
    "                        # MODIFIED: Removed averaging info from title\n",
    "                        ax.set_title(f\"{ap_name} vs. {pkg_name}\\\\n{channel_label} ({freq_label})\", fontsize=plt.rcParams['axes.titlesize'])\n",
    "                        ax.set_xlabel(pkg_name, fontsize=plt.rcParams['axes.labelsize'])\n",
    "                        ax.set_ylabel(ap_name, fontsize=plt.rcParams['axes.labelsize'])\n",
    "                        plt.tight_layout()\n",
    "                        \n",
    "                        safe_ch = get_safe_filename_step4(channel_label)\n",
    "                        safe_ap = get_safe_filename_step4(ap_name)\n",
    "                        safe_pkg = get_safe_filename_step4(pkg_name)\n",
    "                        # MODIFIED: Removed suffix from filename\n",
    "                        plot_filename = f\"Bivar_{safe_ap}_vs_{safe_pkg}_{safe_ch}_{freq_label}.png\" \n",
    "                        plt.savefig(os.path.join(plot_subdir_bivariate_ap_pkg, plot_filename))\n",
    "                        plt.close()\n",
    "            \n",
    "            print(f\"    Part 5.2: Partial Aperiodic vs. PKG Correlations for {channel_label} ({freq_label})\")\n",
    "            covariates_partial_corr = [col for col in OSCILLATORY_METRICS_COLS.keys() if col in df_channel_freq.columns]\n",
    "            if len(covariates_partial_corr) == 2: \n",
    "                for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "                    for pkg_col, pkg_name in PKG_METRICS_COLS.items():\n",
    "                        data_for_partial = df_channel_freq[[ap_col, pkg_col] + covariates_partial_corr].dropna()\n",
    "                        if len(data_for_partial) < MIN_SAMPLES_FOR_CORR:\n",
    "                             partial_rho, partial_p_val, N_partial = np.nan, np.nan, len(data_for_partial)\n",
    "                        else:\n",
    "                             partial_rho, partial_p_val, N_partial = calculate_partial_spearman(\n",
    "                                 data_for_partial, ap_col, pkg_col, covariates_partial_corr\n",
    "                             )\n",
    "                        all_partial_ap_pkg_results.append({\n",
    "                            'Channel': channel_label, 'FreqBand': freq_label,\n",
    "                            'AperiodicMetric': ap_name, 'PKGMetric': pkg_name,\n",
    "                            'PartialSpearmanRho_vs_BetaGamma': partial_rho, 'PartialPValue': partial_p_val, 'N_Partial': N_partial\n",
    "                        })\n",
    "\n",
    "            print(f\"    Part 5.3: Bivariate Aperiodic vs. Oscillatory Correlations for {channel_label} ({freq_label})\")\n",
    "            for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "                for osc_col, osc_name in OSCILLATORY_METRICS_COLS.items():\n",
    "                    if osc_col not in df_channel_freq.columns: continue \n",
    "                    \n",
    "                    df_granular_for_corr_osc = df_channel_freq.dropna(subset=[ap_col, osc_col])\n",
    "                    rho_ap_osc, p_val_ap_osc, N_ap_osc = calculate_spearman_with_n(df_granular_for_corr_osc, ap_col, osc_col)\n",
    "                    \n",
    "                    all_bivariate_ap_osc_results.append({\n",
    "                        'Channel': channel_label, 'FreqBand': freq_label,\n",
    "                        'AperiodicMetric': ap_name, 'OscillatoryMetric': osc_name,\n",
    "                        'SpearmanRho': rho_ap_osc, 'PValue': p_val_ap_osc, 'N': N_ap_osc\n",
    "                    })\n",
    "\n",
    "                    if N_ap_osc >= MIN_SAMPLES_FOR_CORR:\n",
    "                        plt.figure(figsize=(7, 6))\n",
    "                        ax_ap_osc = plt.gca()\n",
    "\n",
    "                        df_averaged_points_osc = pd.DataFrame()\n",
    "                        # Check if 'datetime_for_avg_c5' exists and has non-null values before attempting to use it as index\n",
    "                        if 'datetime_for_avg_c5' in df_granular_for_corr_osc.columns and \\\n",
    "                           not df_granular_for_corr_osc['datetime_for_avg_c5'].isnull().all():\n",
    "                            try:\n",
    "                                # MODIFIED: Changed to 5T for 15-minute averaging\n",
    "                                df_averaged_points_osc = df_granular_for_corr_osc.set_index('datetime_for_avg_c5')\\\n",
    "                                    .groupby(pd.Grouper(freq='5T'))[[ap_col, osc_col]]\\\n",
    "                                    .mean().dropna()\n",
    "                            except Exception as e_avg_osc:\n",
    "                                # MODIFIED: Warning message for 15-min\n",
    "                                print(f\"      Warning: 15-min averaging failed for Oscillatory plot ({ap_name} vs {osc_name}). Plotting granular. Error: {e_avg_osc}\")\n",
    "                                df_averaged_points_osc = df_granular_for_corr_osc \n",
    "                        else:\n",
    "                             df_averaged_points_osc = df_granular_for_corr_osc \n",
    "                        \n",
    "                        if df_averaged_points_osc.empty and not df_granular_for_corr_osc.empty:\n",
    "                            df_averaged_points_osc = df_granular_for_corr_osc\n",
    "\n",
    "                        if not df_averaged_points_osc.empty:\n",
    "                            sns.scatterplot(data=df_averaged_points_osc, x=osc_col, y=ap_col,\n",
    "                                            color=COLOR_PALETTE_STEP4.get(ap_col, 'grey'), \n",
    "                                            alpha=DOT_ALPHA_STEP4 + 0.1, s=40,\n",
    "                                            edgecolor='k', linewidths=0.5, ax=ax_ap_osc)\n",
    "                        \n",
    "                        sns.regplot(data=df_granular_for_corr_osc, x=osc_col, y=ap_col, scatter=False, ax=ax_ap_osc,\n",
    "                                    line_kws={'color': COLOR_PALETTE_STEP4.get(osc_col, 'black'), \n",
    "                                              'linewidth': REG_LINE_THICKNESS_STEP4, 'alpha': 0.7})\n",
    "                        \n",
    "                        annotate_correlation_on_plot(ax_ap_osc, rho_ap_osc, p_val_ap_osc, N_ap_osc, test_type=\"Spearman œÅ\")\n",
    "                        # MODIFIED: Removed averaging info from title\n",
    "                        ax_ap_osc.set_title(f\"{ap_name} vs. {osc_name}\\\\n{channel_label} ({freq_label})\", fontsize=plt.rcParams['axes.titlesize'])\n",
    "                        ax_ap_osc.set_xlabel(osc_name, fontsize=plt.rcParams['axes.labelsize'])\n",
    "                        ax_ap_osc.set_ylabel(ap_name, fontsize=plt.rcParams['axes.labelsize'])\n",
    "                        plt.tight_layout()\n",
    "                        \n",
    "                        safe_ch = get_safe_filename_step4(channel_label)\n",
    "                        safe_ap = get_safe_filename_step4(ap_name)\n",
    "                        safe_osc = get_safe_filename_step4(osc_name)\n",
    "                        # MODIFIED: Removed suffix from filename\n",
    "                        plot_filename_ap_osc = f\"Bivar_{safe_ap}_vs_{safe_osc}_{safe_ch}_{freq_label}.png\" \n",
    "                        plt.savefig(os.path.join(plot_subdir_bivariate_ap_osc, plot_filename_ap_osc))\n",
    "                        plt.close()\n",
    "\n",
    "    if all_bivariate_ap_pkg_results:\n",
    "        df_bivar_ap_pkg = pd.DataFrame(all_bivariate_ap_pkg_results)\n",
    "        df_bivar_ap_pkg.to_csv(os.path.join(analysis_session_plot_folder_step4, f\"{patient_hemisphere_id}_Bivariate_AP_vs_PKG_Correlations_Cell5Original.csv\"), index=False)\n",
    "        print(f\"\\\\nSaved Bivariate AP vs PKG correlation results (from original Cell 5 structure) for {patient_hemisphere_id}.\")\n",
    "\n",
    "    if all_partial_ap_pkg_results:\n",
    "        df_partial_ap_pkg = pd.DataFrame(all_partial_ap_pkg_results)\n",
    "        df_partial_ap_pkg.to_csv(os.path.join(analysis_session_plot_folder_step4, f\"{patient_hemisphere_id}_Partial_AP_vs_PKG_Correlations_Cell5Original.csv\"), index=False)\n",
    "        print(f\"Saved Partial AP vs PKG (controlling Beta, Gamma) correlation results (from original Cell 5 structure) for {patient_hemisphere_id}.\")\n",
    "\n",
    "    if all_bivariate_ap_osc_results:\n",
    "        df_bivar_ap_osc = pd.DataFrame(all_bivariate_ap_osc_results)\n",
    "        df_bivar_ap_osc.to_csv(os.path.join(analysis_session_plot_folder_step4, f\"{patient_hemisphere_id}_Bivariate_AP_vs_Oscillatory_Correlations_Cell5Original.csv\"), index=False)\n",
    "        print(f\"Saved Bivariate AP vs Oscillatory correlation results (from original Cell 5 structure) for {patient_hemisphere_id}.\")\n",
    "\n",
    "print(\"\\\\n--- Cell 5 (Revised with 15-min Averaged Scatter Points): Correlation Analyses Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ecdab-3696-42f6-ace7-6f10e5d73877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 5 (Revised with 15-min Averaged Scatter Points & PKG Zero Exclusion): Bivariate & Partial Correlations, Aperiodic vs. Beta/Gamma ---\n",
    "# Iterates through Channel_Display AND FreqRangeLabel\n",
    "# Scatter points are 15-min averages; regression lines use all granular data.\n",
    "# MODIFICATION: For analyses involving a specific PKG score, data points where that PKG score is zero are excluded.\n",
    "\n",
    "print(\"\\\\n--- Cell 5 (Revised with 15-min Averaged Scatter Points & PKG Zero Exclusion): Starting Correlation Analyses ---\")\n",
    "\n",
    "if 'master_df_step4' not in locals() or master_df_step4 is None or master_df_step4.empty:\n",
    "    print(\"master_df_step4 not available or empty. Skipping Cell 5.\")\n",
    "else:\n",
    "    # Create a working copy to add a datetime column for averaging\n",
    "    master_df_step4_processed_c5 = master_df_step4.copy()\n",
    "    if 'Aligned_PKG_UnixTimestamp' in master_df_step4_processed_c5.columns:\n",
    "        master_df_step4_processed_c5['datetime_for_avg_c5'] = pd.to_datetime(\n",
    "            master_df_step4_processed_c5['Aligned_PKG_UnixTimestamp'], unit='s', utc=True, errors='coerce'\n",
    "        )\n",
    "        if master_df_step4_processed_c5['datetime_for_avg_c5'].isnull().all():\n",
    "            print(\"Warning in Cell 5: 'datetime_for_avg_c5' could not be created (all NaT). 15-min averaging might fail or use granular points.\")\n",
    "    else:\n",
    "        print(\"Warning in Cell 5: 'Aligned_PKG_UnixTimestamp' not found. Cannot perform 15-minute averaging for scatter plots. Will plot granular points.\")\n",
    "        master_df_step4_processed_c5['datetime_for_avg_c5'] = pd.NaT \n",
    "\n",
    "    # Create subdirectories for plots from this cell\n",
    "    plot_subdir_bivariate_ap_pkg = os.path.join(analysis_session_plot_folder_step4, \"Bivariate_AP_vs_PKG\")\n",
    "    plot_subdir_bivariate_ap_osc = os.path.join(analysis_session_plot_folder_step4, \"Bivariate_AP_vs_Oscillatory\")\n",
    "    os.makedirs(plot_subdir_bivariate_ap_pkg, exist_ok=True)\n",
    "    os.makedirs(plot_subdir_bivariate_ap_osc, exist_ok=True)\n",
    "\n",
    "    all_bivariate_ap_pkg_results = []\n",
    "    all_partial_ap_pkg_results = [] \n",
    "    all_bivariate_ap_osc_results = []\n",
    "\n",
    "    for channel_label in ORDERED_CHANNEL_LABELS: \n",
    "        df_channel = master_df_step4_processed_c5[master_df_step4_processed_c5[CHANNEL_DISPLAY_COL] == channel_label]\n",
    "        if df_channel.empty:\n",
    "            print(f\"\\\\nNo data for channel: {channel_label}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\\\nProcessing Channel: {channel_label}\")\n",
    "\n",
    "        for freq_label in ORDERED_FREQ_LABELS: \n",
    "            df_channel_freq = df_channel[df_channel[FOOOF_FREQ_BAND_COL] == freq_label].copy()\n",
    "            if df_channel_freq.empty:\n",
    "                print(f\"  No data for Freq Band: {freq_label} in Channel: {channel_label}. Skipping.\")\n",
    "                continue\n",
    "            print(f\"  Processing Freq Band: {freq_label}\")\n",
    "\n",
    "            # --- Part 5.1: Bivariate Spearman Correlations (Aperiodic vs. PKG) ---\n",
    "            print(f\"    Part 5.1: Bivariate Aperiodic vs. PKG Correlations for {channel_label} ({freq_label})\")\n",
    "            for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "                for pkg_col, pkg_name in PKG_METRICS_COLS.items():\n",
    "                    if pkg_col not in df_channel_freq.columns or ap_col not in df_channel_freq.columns:\n",
    "                        print(f\"      Skipping {ap_name} vs {pkg_name}: Column missing.\")\n",
    "                        continue\n",
    "\n",
    "                    # MODIFICATION: Filter out rows where the current pkg_col is zero\n",
    "                    df_temp_no_zero_pkg = df_channel_freq[df_channel_freq[pkg_col] != 0]\n",
    "                    \n",
    "                    # Then, drop NaNs from the relevant columns (ap_col and current pkg_col)\n",
    "                    df_granular_for_corr_pkg = df_temp_no_zero_pkg.dropna(subset=[ap_col, pkg_col])\n",
    "                    \n",
    "                    rho, p_val, N = calculate_spearman_with_n(df_granular_for_corr_pkg, ap_col, pkg_col)\n",
    "                    \n",
    "                    all_bivariate_ap_pkg_results.append({\n",
    "                        'Channel': channel_label, 'FreqBand': freq_label,\n",
    "                        'AperiodicMetric': ap_name, 'PKGMetric': pkg_name,\n",
    "                        'SpearmanRho': rho, 'PValue': p_val, 'N': N\n",
    "                    })\n",
    "\n",
    "                    if N >= MIN_SAMPLES_FOR_CORR:\n",
    "                        plt.figure(figsize=(7, 6))\n",
    "                        ax = plt.gca() \n",
    "\n",
    "                        df_averaged_points_pkg = pd.DataFrame()\n",
    "                        if 'datetime_for_avg_c5' in df_granular_for_corr_pkg.columns and \\\n",
    "                           not df_granular_for_corr_pkg['datetime_for_avg_c5'].isnull().all():\n",
    "                            try:\n",
    "                                df_averaged_points_pkg = df_granular_for_corr_pkg.set_index('datetime_for_avg_c5')\\\n",
    "                                    .groupby(pd.Grouper(freq='5T'))[[ap_col, pkg_col]]\\\n",
    "                                    .mean().dropna()\n",
    "                            except Exception as e_avg_pkg:\n",
    "                                print(f\"      Warning: 15-min averaging failed for PKG plot ({ap_name} vs {pkg_name}). Plotting granular. Error: {e_avg_pkg}\")\n",
    "                                df_averaged_points_pkg = df_granular_for_corr_pkg.copy() # Use copy for safety\n",
    "                        else:\n",
    "                            df_averaged_points_pkg = df_granular_for_corr_pkg.copy() \n",
    "                        \n",
    "                        if df_averaged_points_pkg.empty and not df_granular_for_corr_pkg.empty:\n",
    "                            df_averaged_points_pkg = df_granular_for_corr_pkg.copy()\n",
    "                        \n",
    "                        if not df_averaged_points_pkg.empty:\n",
    "                             sns.scatterplot(data=df_averaged_points_pkg, x=pkg_col, y=ap_col,\n",
    "                                            color=COLOR_PALETTE_STEP4.get(ap_col, 'grey'), \n",
    "                                            alpha=DOT_ALPHA_STEP4 + 0.1, s=40, \n",
    "                                            edgecolor='k', linewidths=0.5, ax=ax)\n",
    "                        \n",
    "                        # Regression line uses the granular data (which is already filtered for pkg_col zeros and NaNs)\n",
    "                        sns.regplot(data=df_granular_for_corr_pkg, x=pkg_col, y=ap_col, scatter=False, ax=ax,\n",
    "                                    line_kws={'color': COLOR_PALETTE_STEP4.get(pkg_col, 'black'), \n",
    "                                              'linewidth': REG_LINE_THICKNESS_STEP4, 'alpha': 0.7})\n",
    "                        \n",
    "                        annotate_correlation_on_plot(ax, rho, p_val, N) \n",
    "                        ax.set_title(f\"{ap_name} vs. {pkg_name}\\n{channel_label} ({freq_label})\", fontsize=plt.rcParams['axes.titlesize'])\n",
    "                        ax.set_xlabel(pkg_name, fontsize=plt.rcParams['axes.labelsize'])\n",
    "                        ax.set_ylabel(ap_name, fontsize=plt.rcParams['axes.labelsize'])\n",
    "                        plt.tight_layout()\n",
    "                        \n",
    "                        safe_ch = get_safe_filename_step4(channel_label)\n",
    "                        safe_ap = get_safe_filename_step4(ap_name)\n",
    "                        safe_pkg = get_safe_filename_step4(pkg_name)\n",
    "                        plot_filename = f\"Bivar_{safe_ap}_vs_{safe_pkg}_{safe_ch}_{freq_label}.png\" \n",
    "                        plt.savefig(os.path.join(plot_subdir_bivariate_ap_pkg, plot_filename))\n",
    "                        plt.close()\n",
    "            \n",
    "            # --- Part 5.2: Partial Aperiodic vs. PKG Correlations ---\n",
    "            print(f\"    Part 5.2: Partial Aperiodic vs. PKG Correlations for {channel_label} ({freq_label})\")\n",
    "            covariates_partial_corr = [col for col in OSCILLATORY_METRICS_COLS.keys() if col in df_channel_freq.columns]\n",
    "            if len(covariates_partial_corr) == 2: \n",
    "                for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "                    for pkg_col, pkg_name in PKG_METRICS_COLS.items():\n",
    "                        if pkg_col not in df_channel_freq.columns or ap_col not in df_channel_freq.columns:\n",
    "                            continue # Skip if essential columns are missing\n",
    "\n",
    "                        # MODIFICATION: Filter out rows where the current pkg_col is zero\n",
    "                        df_temp_no_zero_pkg_partial = df_channel_freq[df_channel_freq[pkg_col] != 0]\n",
    "                        \n",
    "                        # Then, select columns for partial correlation and drop NaNs\n",
    "                        cols_for_partial_corr = [ap_col, pkg_col] + covariates_partial_corr\n",
    "                        # Ensure all selected columns actually exist in df_temp_no_zero_pkg_partial before selection\n",
    "                        cols_for_partial_corr_present = [c for c in cols_for_partial_corr if c in df_temp_no_zero_pkg_partial.columns]\n",
    "                        if len(cols_for_partial_corr_present) != len(cols_for_partial_corr):\n",
    "                            # This case should be rare if checks above are fine, but as a safeguard\n",
    "                            # print(f\"      Skipping partial corr {ap_name} vs {pkg_name}: Not all necessary columns present after filtering.\")\n",
    "                            partial_rho, partial_p_val, N_partial = np.nan, np.nan, 0\n",
    "                        else:\n",
    "                            data_for_partial = df_temp_no_zero_pkg_partial[cols_for_partial_corr_present].dropna()\n",
    "                        \n",
    "                            if len(data_for_partial) < MIN_SAMPLES_FOR_CORR or not all(data_for_partial[c].nunique() > 1 for c in [ap_col, pkg_col] if c in data_for_partial): # check variance for key vars\n",
    "                                 partial_rho, partial_p_val, N_partial = np.nan, np.nan, len(data_for_partial)\n",
    "                            else:\n",
    "                                 partial_rho, partial_p_val, N_partial = calculate_partial_spearman(\n",
    "                                     data_for_partial, ap_col, pkg_col, covariates_partial_corr # Pass original covariates list\n",
    "                                 )\n",
    "                        all_partial_ap_pkg_results.append({\n",
    "                            'Channel': channel_label, 'FreqBand': freq_label,\n",
    "                            'AperiodicMetric': ap_name, 'PKGMetric': pkg_name,\n",
    "                            'PartialSpearmanRho_vs_BetaGamma': partial_rho, 'PartialPValue': partial_p_val, 'N_Partial': N_partial\n",
    "                        })\n",
    "\n",
    "            # --- Part 5.3: Bivariate Aperiodic vs. Oscillatory Correlations ---\n",
    "            # This part remains unchanged by the PKG zero-filtering request, as it does not directly use PKG scores in the correlation.\n",
    "            print(f\"    Part 5.3: Bivariate Aperiodic vs. Oscillatory Correlations for {channel_label} ({freq_label})\")\n",
    "            for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "                for osc_col, osc_name in OSCILLATORY_METRICS_COLS.items():\n",
    "                    if osc_col not in df_channel_freq.columns or ap_col not in df_channel_freq.columns:\n",
    "                        continue \n",
    "                    \n",
    "                    # Data for this correlation is taken directly from df_channel_freq (no PKG zero filter here)\n",
    "                    df_granular_for_corr_osc = df_channel_freq.dropna(subset=[ap_col, osc_col])\n",
    "                    rho_ap_osc, p_val_ap_osc, N_ap_osc = calculate_spearman_with_n(df_granular_for_corr_osc, ap_col, osc_col)\n",
    "                    \n",
    "                    all_bivariate_ap_osc_results.append({\n",
    "                        'Channel': channel_label, 'FreqBand': freq_label,\n",
    "                        'AperiodicMetric': ap_name, 'OscillatoryMetric': osc_name,\n",
    "                        'SpearmanRho': rho_ap_osc, 'PValue': p_val_ap_osc, 'N': N_ap_osc\n",
    "                    })\n",
    "\n",
    "                    if N_ap_osc >= MIN_SAMPLES_FOR_CORR:\n",
    "                        plt.figure(figsize=(7, 6))\n",
    "                        ax_ap_osc = plt.gca()\n",
    "\n",
    "                        df_averaged_points_osc = pd.DataFrame()\n",
    "                        if 'datetime_for_avg_c5' in df_granular_for_corr_osc.columns and \\\n",
    "                           not df_granular_for_corr_osc['datetime_for_avg_c5'].isnull().all():\n",
    "                            try:\n",
    "                                df_averaged_points_osc = df_granular_for_corr_osc.set_index('datetime_for_avg_c5')\\\n",
    "                                    .groupby(pd.Grouper(freq='5T'))[[ap_col, osc_col]]\\\n",
    "                                    .mean().dropna()\n",
    "                            except Exception as e_avg_osc:\n",
    "                                print(f\"      Warning: 15-min averaging failed for Oscillatory plot ({ap_name} vs {osc_name}). Plotting granular. Error: {e_avg_osc}\")\n",
    "                                df_averaged_points_osc = df_granular_for_corr_osc.copy() \n",
    "                        else:\n",
    "                             df_averaged_points_osc = df_granular_for_corr_osc.copy() \n",
    "                        \n",
    "                        if df_averaged_points_osc.empty and not df_granular_for_corr_osc.empty:\n",
    "                            df_averaged_points_osc = df_granular_for_corr_osc.copy()\n",
    "\n",
    "                        if not df_averaged_points_osc.empty:\n",
    "                            sns.scatterplot(data=df_averaged_points_osc, x=osc_col, y=ap_col,\n",
    "                                            color=COLOR_PALETTE_STEP4.get(ap_col, 'grey'), \n",
    "                                            alpha=DOT_ALPHA_STEP4 + 0.1, s=40,\n",
    "                                            edgecolor='k', linewidths=0.5, ax=ax_ap_osc)\n",
    "                        \n",
    "                        sns.regplot(data=df_granular_for_corr_osc, x=osc_col, y=ap_col, scatter=False, ax=ax_ap_osc,\n",
    "                                    line_kws={'color': COLOR_PALETTE_STEP4.get(osc_col, 'black'), \n",
    "                                              'linewidth': REG_LINE_THICKNESS_STEP4, 'alpha': 0.7})\n",
    "                        \n",
    "                        annotate_correlation_on_plot(ax_ap_osc, rho_ap_osc, p_val_ap_osc, N_ap_osc, test_type=\"Spearman œÅ\")\n",
    "                        ax_ap_osc.set_title(f\"{ap_name} vs. {osc_name}\\n{channel_label} ({freq_label})\", fontsize=plt.rcParams['axes.titlesize'])\n",
    "                        ax_ap_osc.set_xlabel(osc_name, fontsize=plt.rcParams['axes.labelsize'])\n",
    "                        ax_ap_osc.set_ylabel(ap_name, fontsize=plt.rcParams['axes.labelsize'])\n",
    "                        plt.tight_layout()\n",
    "                        \n",
    "                        safe_ch = get_safe_filename_step4(channel_label)\n",
    "                        safe_ap = get_safe_filename_step4(ap_name)\n",
    "                        safe_osc = get_safe_filename_step4(osc_name)\n",
    "                        plot_filename_ap_osc = f\"Bivar_{safe_ap}_vs_{safe_osc}_{safe_ch}_{freq_label}.png\" \n",
    "                        plt.savefig(os.path.join(plot_subdir_bivariate_ap_osc, plot_filename_ap_osc))\n",
    "                        plt.close()\n",
    "\n",
    "    if all_bivariate_ap_pkg_results:\n",
    "        df_bivar_ap_pkg = pd.DataFrame(all_bivariate_ap_pkg_results)\n",
    "        df_bivar_ap_pkg.to_csv(os.path.join(analysis_session_plot_folder_step4, f\"{patient_hemisphere_id}_Bivariate_AP_vs_PKG_Correlations_NoZerosInPKG_Cell5.csv\"), index=False) # Filename updated\n",
    "        print(f\"\\\\nSaved Bivariate AP vs PKG correlation results (zeros in PKG excluded) for {patient_hemisphere_id}.\")\n",
    "\n",
    "    if all_partial_ap_pkg_results:\n",
    "        df_partial_ap_pkg = pd.DataFrame(all_partial_ap_pkg_results)\n",
    "        df_partial_ap_pkg.to_csv(os.path.join(analysis_session_plot_folder_step4, f\"{patient_hemisphere_id}_Partial_AP_vs_PKG_Correlations_NoZerosInPKG_Cell5.csv\"), index=False) # Filename updated\n",
    "        print(f\"Saved Partial AP vs PKG (zeros in PKG excluded) correlation results for {patient_hemisphere_id}.\")\n",
    "\n",
    "    if all_bivariate_ap_osc_results:\n",
    "        df_bivar_ap_osc = pd.DataFrame(all_bivariate_ap_osc_results)\n",
    "        # Filename remains the same as this part is not affected by PKG zero filtering\n",
    "        df_bivar_ap_osc.to_csv(os.path.join(analysis_session_plot_folder_step4, f\"{patient_hemisphere_id}_Bivariate_AP_vs_Oscillatory_Correlations_Cell5.csv\"), index=False) \n",
    "        print(f\"Saved Bivariate AP vs Oscillatory correlation results for {patient_hemisphere_id}.\")\n",
    "\n",
    "print(\"\\\\n--- Cell 5 (Revised with 15-min Averaged Scatter Points & PKG Zero Exclusion): Correlation Analyses Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74691efc-4f96-42ce-a155-9d299bad954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 6 (Streamlined V3 - Tiered MLR with Oscillatory-Only Model): Multiple Linear Regression ---\n",
    "# Focuses on separate models for Exponent and Offset, and introduces an Oscillatory-Only tier.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from scipy.stats import spearmanr \n",
    "\n",
    "print(\"\\n--- Cell 6 (Streamlined V3 - Tiered MLR with Oscillatory-Only Model): Starting Analyses ---\\n\")\n",
    "\n",
    "# <<< --- USER TOGGLE --- >>>\n",
    "ANALYZE_ALL_FREQ_BANDS = False\n",
    "TARGET_FREQ_BAND_IF_NOT_ALL = \"WideFreq\"\n",
    "# <<< ------------------ >>>\n",
    "\n",
    "if 'master_df_step4' not in locals() or master_df_step4.empty:\n",
    "    print(\"master_df_step4 not available or empty. Skipping Cell 6.\")\n",
    "else:\n",
    "    plot_subdir_mlr = os.path.join(analysis_session_plot_folder_step4, \"MultipleLinearRegression_PKG_on_Neural_STREAMLINED_V3\") # New folder name\n",
    "    os.makedirs(plot_subdir_mlr, exist_ok=True)\n",
    "    \n",
    "    plot_subdir_ap_corr = os.path.join(plot_subdir_mlr, \"Aperiodic_Intercorrelations\")\n",
    "    os.makedirs(plot_subdir_ap_corr, exist_ok=True)\n",
    "    \n",
    "    mlr_results_list_streamlined_v3 = [] \n",
    "    exp_offset_corr_results_list = [] \n",
    "\n",
    "    available_aperiodic_cols = [col for col in APERIODIC_METRICS_COLS.keys() if col in master_df_step4.columns]\n",
    "    available_oscillatory_cols = [col for col in OSCILLATORY_METRICS_COLS.keys() if col in master_df_step4.columns]\n",
    "\n",
    "    exponent_col_name = 'Exponent_BestModel' \n",
    "    offset_col_name = 'Offset_BestModel'\n",
    "    beta_col_name = 'Beta_Peak_Power_at_DominantFreq'\n",
    "    gamma_col_name = 'Gamma_Peak_Power_at_DominantFreq'\n",
    "\n",
    "    # Helper function (retained from previous streamlined version)\n",
    "    def fit_and_interpret_mlr_focused_v3(data_df, dv_col, dv_name, predictors, model_tier_label,\n",
    "                                          channel=\"N/A\", freq_band=\"N/A\"):\n",
    "        \n",
    "        if not predictors or not all(p in data_df.columns for p in predictors):\n",
    "            missing_p = [p for p in predictors if p not in data_df.columns] if predictors else []\n",
    "            # Only print warning if predictors were expected but missing. If predictors list is empty, it's handled.\n",
    "            if predictors and missing_p:\n",
    "                 print(f\"      Skipping {dv_name} ({model_tier_label}): Predictor(s) {missing_p} not found.\")\n",
    "            elif not predictors : # If predictor list is genuinely empty (e.g. no oscillatory features available)\n",
    "                 print(f\"      Skipping {dv_name} ({model_tier_label}): No valid predictors provided for this model tier.\")\n",
    "            return\n",
    "        \n",
    "        formula_to_fit = f\"{dv_col} ~ {' + '.join(predictors)}\"\n",
    "        \n",
    "        model_cols_to_check = [dv_col] + predictors\n",
    "        unique_model_cols_to_check = list(dict.fromkeys(model_cols_to_check))\n",
    "        current_data_for_model = data_df[unique_model_cols_to_check].dropna(how='any').copy()\n",
    "\n",
    "        if len(current_data_for_model) < (len(predictors) + 10): \n",
    "            print(f\"      Skipping {dv_name} ({model_tier_label}): Insufficient data ({len(current_data_for_model)}) for {len(predictors)} predictors.\")\n",
    "            return\n",
    "        \n",
    "        for pred_check in predictors: \n",
    "            if pred_check in current_data_for_model.columns and current_data_for_model[pred_check].nunique() < 2:\n",
    "                print(f\"      Skipping {dv_name} ({model_tier_label}): Constant predictor {pred_check} found.\")\n",
    "                return\n",
    "        \n",
    "        print(f\"      --- Model Tier: {model_tier_label} ---\")\n",
    "        print(f\"      Fitting for DV '{dv_name}' with formula: {formula_to_fit}\")\n",
    "        \n",
    "        try:\n",
    "            model_fit = smf.ols(formula=formula_to_fit, data=current_data_for_model).fit()\n",
    "            \n",
    "            print(f\"\\n      --- MLR Summary: {dv_name} ({model_tier_label}) ---\")\n",
    "            print(f\"      Channel: {channel}, Freq Band: {freq_band}\")\n",
    "            print(f\"      N = {model_fit.nobs}\")\n",
    "            print(model_fit.summary())\n",
    "            print(\"      --- End of Statsmodels Summary ---\\n\")\n",
    "\n",
    "            interpretation_string = f\"      --- Interpretation for {dv_name} ({model_tier_label} - {channel}, {freq_band}) ---\\n\"\n",
    "            interpretation_string += f\"      Overall Model Fit: Explains {model_fit.rsquared_adj * 100:.1f}% of variance (Adj. R¬≤ = {model_fit.rsquared_adj:.3f}, N = {model_fit.nobs}).\\n\"\n",
    "            interpretation_string += \"      Predictor Contributions:\\n\"\n",
    "\n",
    "            for term_in_model in model_fit.params.index:\n",
    "                if term_in_model == 'Intercept': continue\n",
    "                coeff = model_fit.params.get(term_in_model, np.nan)\n",
    "                pval = model_fit.pvalues.get(term_in_model, np.nan)\n",
    "                term_name_display = APERIODIC_METRICS_COLS.get(term_in_model, OSCILLATORY_METRICS_COLS.get(term_in_model, term_in_model))\n",
    "                \n",
    "                interpretation_string += f\"        - {term_name_display} (Term: {term_in_model}):\\n\"\n",
    "                interpretation_string += f\"          Coefficient: {coeff:.3f}, P-value: {pval:.3g}\"\n",
    "                \n",
    "                if pd.notna(pval) and pd.notna(coeff):\n",
    "                    is_significant = pval < P_VALUE_THRESHOLD \n",
    "                    direction = 'increase' if coeff > 0 else 'decrease' if coeff < 0 else 'no change'\n",
    "                    significance_text = ' (significant)' if is_significant else ' (not significant)'\n",
    "                    if is_significant:\n",
    "                        interpretation_string += f\"\\n          Interpretation: A 1-unit increase in {term_name_display} is associated with a {abs(coeff):.3f} unit {direction} in {dv_name}{significance_text}, controlling for other model predictors.\\n\"\n",
    "                    else:\n",
    "                        interpretation_string += f\"\\n          Interpretation: {term_name_display} was not a significant predictor of {dv_name} (p={pval:.3g}), controlling for other model predictors.\\n\"\n",
    "                else:\n",
    "                    interpretation_string += \"\\n          Interpretation: Stats not available.\\n\"\n",
    "\n",
    "                mlr_results_list_streamlined_v3.append({ \n",
    "                    'Channel': channel, 'FreqBand_Aperiodics': freq_band, 'PKG_Symptom_DV': dv_name,\n",
    "                    'Model_Tier': model_tier_label, 'Formula': formula_to_fit,\n",
    "                    'Predictor_Term': term_in_model, \n",
    "                    'Predictor_Name_Display': term_name_display,\n",
    "                    'Coefficient': coeff, 'StdErr': model_fit.bse.get(term_in_model, np.nan), 'PValue': pval,\n",
    "                    'Conf_Int_Lower': model_fit.conf_int().loc[term_in_model, 0] if term_in_model in model_fit.conf_int().index else np.nan,\n",
    "                    'Conf_Int_Upper': model_fit.conf_int().loc[term_in_model, 1] if term_in_model in model_fit.conf_int().index else np.nan,\n",
    "                    'N_model': model_fit.nobs, 'R_squared_adj_model': model_fit.rsquared_adj\n",
    "                })\n",
    "            print(interpretation_string)\n",
    "            print(\"      --- End of Interpretation ---\\n\")\n",
    "        except Exception as e_mlr_fit:\n",
    "            print(f\"      ERROR fitting MLR for {dv_name} ({model_tier_label}): {e_mlr_fit}\")\n",
    "\n",
    "\n",
    "    freq_bands_to_process = [TARGET_FREQ_BAND_IF_NOT_ALL] if not ANALYZE_ALL_FREQ_BANDS else ORDERED_FREQ_LABELS\n",
    "    if not ANALYZE_ALL_FREQ_BANDS: print(f\"--- Analyzing ONLY for Freq Band: {TARGET_FREQ_BAND_IF_NOT_ALL} ---\")\n",
    "\n",
    "    for channel_label_iter in ORDERED_CHANNEL_LABELS:\n",
    "        df_channel_mlr_main = master_df_step4[master_df_step4[CHANNEL_DISPLAY_COL] == channel_label_iter]\n",
    "        if df_channel_mlr_main.empty: continue\n",
    "        print(f\"\\n>>> Processing MLR for Channel: {channel_label_iter} <<<\")\n",
    "\n",
    "        for freq_label_iter in freq_bands_to_process:\n",
    "            df_channel_freq_mlr_main = df_channel_mlr_main[df_channel_mlr_main[FOOOF_FREQ_BAND_COL] == freq_label_iter].copy()\n",
    "            if df_channel_freq_mlr_main.empty: continue\n",
    "            print(f\"\\n  --- Freq Band: {freq_label_iter} ---\")\n",
    "\n",
    "            if exponent_col_name in df_channel_freq_mlr_main.columns and offset_col_name in df_channel_freq_mlr_main.columns:\n",
    "                print(f\"    Sanity Check: Bivariate Correlation between {exponent_col_name} and {offset_col_name}\")\n",
    "                exp_offset_data = df_channel_freq_mlr_main[[exponent_col_name, offset_col_name]].dropna()\n",
    "                if len(exp_offset_data) >= MIN_SAMPLES_FOR_CORR: \n",
    "                    rho_eo, p_eo, N_eo = calculate_spearman_with_n(exp_offset_data, exponent_col_name, offset_col_name)\n",
    "                    print(f\"      Spearman Rho (Exponent vs Offset): {rho_eo:.3f}, P-value: {p_eo:.3g}, N: {N_eo}\")\n",
    "                    exp_offset_corr_results_list.append({\n",
    "                        'Channel': channel_label_iter, 'FreqBand': freq_label_iter,\n",
    "                        'SpearmanRho_ExpOff': rho_eo, 'PValue_ExpOff': p_eo, 'N_ExpOff': N_eo\n",
    "                    })\n",
    "                    # Plotting Exponent vs Offset (retained)\n",
    "                    plt.figure(figsize=(7,6))\n",
    "                    ax_eo = sns.scatterplot(data=exp_offset_data, x=offset_col_name, y=exponent_col_name, alpha=0.5)\n",
    "                    sns.regplot(data=exp_offset_data, x=offset_col_name, y=exponent_col_name, scatter=False, ax=ax_eo, color='red')\n",
    "                    annotate_correlation_on_plot(ax_eo, rho_eo, p_eo, N_eo) \n",
    "                    ax_eo.set_title(f\"{APERIODIC_METRICS_COLS.get(exponent_col_name, exponent_col_name)} vs. {APERIODIC_METRICS_COLS.get(offset_col_name, offset_col_name)}\\n{channel_label_iter} ({freq_label_iter})\")\n",
    "                    ax_eo.set_xlabel(APERIODIC_METRICS_COLS.get(offset_col_name, offset_col_name))\n",
    "                    ax_eo.set_ylabel(APERIODIC_METRICS_COLS.get(exponent_col_name, exponent_col_name))\n",
    "                    plt.tight_layout()\n",
    "                    safe_ch_eo = get_safe_filename_step4(channel_label_iter) \n",
    "                    plt.savefig(os.path.join(plot_subdir_ap_corr, f\"Bivar_Exponent_vs_Offset_{safe_ch_eo}_{freq_label_iter}.png\")); plt.close()\n",
    "                    print(f\"        Saved Exponent vs Offset plot.\")\n",
    "                else: print(f\"      Insufficient data for Exponent vs Offset correlation.\")\n",
    "\n",
    "            for pkg_col_iter, pkg_name_iter in PKG_METRICS_COLS.items():\n",
    "                if pkg_col_iter not in df_channel_freq_mlr_main.columns: continue\n",
    "                print(f\"\\n    --- Predicting: {pkg_name_iter} (DV: {pkg_col_iter}) ---\")\n",
    "\n",
    "                # Tier 1: Exponent Only\n",
    "                if exponent_col_name in available_aperiodic_cols:\n",
    "                    fit_and_interpret_mlr_focused_v3(df_channel_freq_mlr_main, pkg_col_iter, pkg_name_iter, \n",
    "                                          [exponent_col_name], \"Tier 1: Exponent Only\", \n",
    "                                          channel=channel_label_iter, freq_band=freq_label_iter)\n",
    "                \n",
    "                # <<< NEW TIER 1b: Oscillatory Only >>>\n",
    "                tier1b_predictors_osc_only = [p for p in [beta_col_name, gamma_col_name] if p in available_oscillatory_cols and p in df_channel_freq_mlr_main.columns]\n",
    "                if len(tier1b_predictors_osc_only) > 0: # Run if at least one oscillatory predictor is available\n",
    "                     fit_and_interpret_mlr_focused_v3(df_channel_freq_mlr_main, pkg_col_iter, pkg_name_iter, \n",
    "                                           tier1b_predictors_osc_only, \"Tier 1b: Oscillatory Only\", \n",
    "                                           channel=channel_label_iter, freq_band=freq_label_iter)\n",
    "                \n",
    "                # Tier 1c (was Tier 1b): Exponent + Oscillatory\n",
    "                tier1c_predictors = []\n",
    "                if exponent_col_name in available_aperiodic_cols: tier1c_predictors.append(exponent_col_name)\n",
    "                tier1c_predictors.extend(p for p in [beta_col_name, gamma_col_name] if p in available_oscillatory_cols and p in df_channel_freq_mlr_main.columns)\n",
    "                if exponent_col_name in tier1c_predictors and len(tier1c_predictors) > 1: \n",
    "                     fit_and_interpret_mlr_focused_v3(df_channel_freq_mlr_main, pkg_col_iter, pkg_name_iter, \n",
    "                                           tier1c_predictors, \"Tier 1c: Exponent + Oscillatory\", \n",
    "                                           channel=channel_label_iter, freq_band=freq_label_iter)\n",
    "                \n",
    "                # Tier 2: Offset Only\n",
    "                if offset_col_name in available_aperiodic_cols:\n",
    "                    fit_and_interpret_mlr_focused_v3(df_channel_freq_mlr_main, pkg_col_iter, pkg_name_iter,\n",
    "                                          [offset_col_name], \"Tier 2: Offset Only\",\n",
    "                                          channel=channel_label_iter, freq_band=freq_label_iter)\n",
    "\n",
    "                # Tier 2b: Offset + Oscillatory\n",
    "                tier2b_predictors = []\n",
    "                if offset_col_name in available_aperiodic_cols: tier2b_predictors.append(offset_col_name)\n",
    "                tier2b_predictors.extend(p for p in [beta_col_name, gamma_col_name] if p in available_oscillatory_cols and p in df_channel_freq_mlr_main.columns)\n",
    "                if offset_col_name in tier2b_predictors and len(tier2b_predictors) > 1: \n",
    "                     fit_and_interpret_mlr_focused_v3(df_channel_freq_mlr_main, pkg_col_iter, pkg_name_iter, \n",
    "                                           tier2b_predictors, \"Tier 2b: Offset + Oscillatory\", \n",
    "                                           channel=channel_label_iter, freq_band=freq_label_iter)\n",
    "                \n",
    "    # Saving Exponent vs Offset correlation results\n",
    "    if exp_offset_corr_results_list:\n",
    "        df_exp_offset_corr = pd.DataFrame(exp_offset_corr_results_list)\n",
    "        csv_filename_exp_offset_corr = f\"{patient_hemisphere_id}_Exponent_vs_Offset_Correlations_Step6.csv\"\n",
    "        df_exp_offset_corr.to_csv(os.path.join(analysis_session_plot_folder_step4, csv_filename_exp_offset_corr), index=False)\n",
    "        print(f\"\\nSaved Exponent vs Offset bivariate correlation results to {csv_filename_exp_offset_corr}.\")\n",
    "        print(\"Sample of Exponent vs Offset correlations:\")\n",
    "        print(df_exp_offset_corr.head())\n",
    "\n",
    "    if mlr_results_list_streamlined_v3: \n",
    "        df_mlr_results_step6_streamlined_v3 = pd.DataFrame(mlr_results_list_streamlined_v3)\n",
    "        csv_filename_mlr_streamlined_v3 = f\"{patient_hemisphere_id}_MLR_Streamlined_V3_Results_Step6.csv\" \n",
    "        df_mlr_results_step6_streamlined_v3.to_csv(os.path.join(analysis_session_plot_folder_step4, csv_filename_mlr_streamlined_v3), index=False)\n",
    "        print(f\"\\nSaved Step 6 Streamlined V3 MLR results for {patient_hemisphere_id} to {csv_filename_mlr_streamlined_v3}.\")\n",
    "        cols_to_show_mlr = ['Channel', 'FreqBand_Aperiodics', 'PKG_Symptom_DV', 'Model_Tier', \n",
    "                            'Predictor_Term', 'Coefficient', 'PValue', 'R_squared_adj_model', 'N_model']\n",
    "        print(df_mlr_results_step6_streamlined_v3[[c for c in cols_to_show_mlr if c in df_mlr_results_step6_streamlined_v3.columns]].head())\n",
    "    else:\n",
    "        print(\"\\nNo Streamlined V3 MLR models were successfully fitted or no results to save for Step 6.\")\n",
    "\n",
    "print(f\"\\n--- Cell 6 (Streamlined V3 - Tiered MLR with Oscillatory-Only Model): Analyses Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed62b96-4898-417e-a7f1-2476be4cf221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 7: Box Plots - Aperiodic Metric Distributions by Channel (Exploratory) ---\n",
    "# Iterates through Channel_Display AND FreqRangeLabel\n",
    "\n",
    "print(\"\\n--- Cell 7: Generating Box Plots for Aperiodic Metric Distributions by Channel (Exploratory) ---\")\n",
    "\n",
    "if master_df_step4 is None or master_df_step4.empty:\n",
    "    print(\"master_df_step4 not available or empty. Skipping Cell 7.\")\n",
    "else:\n",
    "    plot_subdir_ap_dist = os.path.join(analysis_session_plot_folder_step4, \"Distributions_Aperiodic_by_Channel\")\n",
    "    os.makedirs(plot_subdir_ap_dist, exist_ok=True)\n",
    "\n",
    "    for freq_label in ORDERED_FREQ_LABELS:\n",
    "        df_freq_band_c7 = master_df_step4[master_df_step4[FOOOF_FREQ_BAND_COL] == freq_label].copy()\n",
    "        if df_freq_band_c7.empty:\n",
    "            print(f\"No data for Freq Band: {freq_label}. Skipping box plots for this band.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcessing Aperiodic Box Plots for Freq Band: {freq_label}\")\n",
    "\n",
    "        for ap_col, ap_name in APERIODIC_METRICS_COLS.items():\n",
    "            if ap_col not in df_freq_band_c7.columns or df_freq_band_c7[ap_col].isnull().all():\n",
    "                print(f\"  Skipping {ap_name}: column not found or all NaN for {freq_label}.\")\n",
    "                continue\n",
    "\n",
    "            plt.figure(figsize=(max(8, len(ORDERED_CHANNEL_LABELS) * 1.2), 6)) # Adjust width based on num channels\n",
    "            \n",
    "            # Data for boxplot - trim visual outliers\n",
    "            boxplot_viz_data_list_c7 = []\n",
    "            for ch_lab_c7 in ORDERED_CHANNEL_LABELS:\n",
    "                ch_data_c7 = df_freq_band_c7[df_freq_band_c7[CHANNEL_DISPLAY_COL] == ch_lab_c7]\n",
    "                if not ch_data_c7.empty:\n",
    "                    trimmed_ch_data_c7 = trim_data_for_boxplot_visualization(ch_data_c7, ap_col) # Helper from Cell 4\n",
    "                    boxplot_viz_data_list_c7.append(trimmed_ch_data_c7)\n",
    "            \n",
    "            boxplot_df_viz_c7 = pd.concat(boxplot_viz_data_list_c7, ignore_index=True) if boxplot_viz_data_list_c7 else pd.DataFrame()\n",
    "\n",
    "            if not boxplot_df_viz_c7.empty and not boxplot_df_viz_c7[ap_col].isnull().all():\n",
    "                current_ap_color_c7 = COLOR_PALETTE_STEP4.get(ap_col, 'grey')\n",
    "                current_ap_face_color_rgba_c7 = list(sns.color_palette([current_ap_color_c7])[0]) + [BOX_FILL_ALPHA_STEP4]\n",
    "\n",
    "\n",
    "                sns.boxplot(data=boxplot_df_viz_c7, x=CHANNEL_DISPLAY_COL, y=ap_col,\n",
    "                            order=ORDERED_CHANNEL_LABELS, showfliers=False,\n",
    "                            boxprops={'facecolor': tuple(current_ap_face_color_rgba_c7), 'edgecolor': current_ap_color_c7, 'linewidth': 1.5},\n",
    "                            whiskerprops={'color': current_ap_color_c7, 'linewidth': 1.5},\n",
    "                            capprops={'color': current_ap_color_c7, 'linewidth': 1.5},\n",
    "                            medianprops={'color': 'black', 'linewidth': 1.5} # Make median more distinct\n",
    "                           )\n",
    "                # Overlay stripplot with raw (but potentially filtered for NaNs) data for the current ap_col\n",
    "                strip_data_c7 = df_freq_band_c7.dropna(subset=[ap_col])\n",
    "                if not strip_data_c7.empty:\n",
    "                    sns.stripplot(data=strip_data_c7, x=CHANNEL_DISPLAY_COL, y=ap_col,\n",
    "                                  order=ORDERED_CHANNEL_LABELS, color=current_ap_color_c7,\n",
    "                                  alpha=DOT_ALPHA_STEP4*0.5, jitter=0.2, size=4, marker='o', linewidth=0)\n",
    "            else:\n",
    "                 plt.text(0.5, 0.5, \"No Data to Plot\", ha='center', va='center', transform=plt.gca().transAxes)\n",
    "\n",
    "\n",
    "            plt.title(f\"{ap_name} Distribution by Channel\\n{patient_hemisphere_id} - Freq Band: {freq_label}\", fontsize=plt.rcParams['axes.titlesize'])\n",
    "            plt.xlabel(\"Channel\", fontsize=plt.rcParams['axes.labelsize'])\n",
    "            plt.ylabel(ap_name, fontsize=plt.rcParams['axes.labelsize'])\n",
    "            plt.xticks(rotation=45, ha=\"right\")\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            safe_ap = get_safe_filename_step4(ap_name)\n",
    "            plot_filename_ap_dist = f\"Box_ApDist_{safe_ap}_{freq_label}.png\"\n",
    "            plt.savefig(os.path.join(plot_subdir_ap_dist, plot_filename_ap_dist))\n",
    "            plt.close()\n",
    "            print(f\"  Saved box plot for {ap_name} ({freq_label})\")\n",
    "\n",
    "print(\"\\n--- Cell 7: Aperiodic Metric Distribution Box Plots Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ddacab-2c13-4196-afa3-ac7831f723c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 9 (MODIFIED for 5 States - Sleep, Imm, NDM, TM, DM & 10-min avg points) ---\n",
    "\n",
    "print(\"\\\\n--- Cell 9 (Specific 5 States - Sleep, Immobile, NDM, TM, DM): Box Plots ---\")\n",
    "\n",
    "from scipy.stats import kruskal\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Constants assumed from your environment (define if not globally available)\n",
    "if 'ORDERED_CHANNEL_LABELS' not in locals(): ORDERED_CHANNEL_LABELS = [] # Should be defined from Cell 3 of Step 4\n",
    "if 'ORDERED_FREQ_LABELS' not in locals(): ORDERED_FREQ_LABELS = [\"LowFreq\", \"MidFreq\", \"WideFreq\"] # Should be from Cell 2 of Step 4\n",
    "if 'APERIODIC_METRICS_COLS' not in locals(): APERIODIC_METRICS_COLS = {} # Should be from Cell 2 of Step 4\n",
    "if 'CLINICAL_STATE_COL' not in locals(): CLINICAL_STATE_COL = 'Clinical_State_2min_Window' # Should be from Cell 2 of Step 4\n",
    "if 'CHANNEL_DISPLAY_COL' not in locals(): CHANNEL_DISPLAY_COL = 'Channel_Display' # Should be from Cell 2 of Step 4\n",
    "if 'FOOOF_FREQ_BAND_COL' not in locals(): FOOOF_FREQ_BAND_COL = 'FreqRangeLabel' # Should be from Cell 2 of Step 4\n",
    "if 'patient_hemisphere_id' not in locals(): patient_hemisphere_id = \"UnknownPatient\" # Should be from Cell 2 of Step 4\n",
    "if 'analysis_session_plot_folder_step4' not in locals(): analysis_session_plot_folder_step4 = \"./step4_plots\" # Fallback\n",
    "\n",
    "if 'N_CHANNELS_PER_OVERVIEW' not in locals(): N_CHANNELS_PER_OVERVIEW = len(ORDERED_CHANNEL_LABELS) if ORDERED_CHANNEL_LABELS else 2\n",
    "if 'N_FREQ_BANDS_PER_OVERVIEW' not in locals(): N_FREQ_BANDS_PER_OVERVIEW = len(ORDERED_FREQ_LABELS) if ORDERED_FREQ_LABELS else 3\n",
    "if 'BOX_FILL_ALPHA' not in locals(): BOX_FILL_ALPHA = 0.7\n",
    "if 'BOXPLOT_LINE_THICKNESS' not in locals(): BOXPLOT_LINE_THICKNESS = 1.5\n",
    "if 'DOT_ALPHA' not in locals(): DOT_ALPHA = 0.5\n",
    "if 'MIN_SAMPLES_FOR_GROUP_COMPARISON' not in locals(): MIN_SAMPLES_FOR_GROUP_COMPARISON = 5\n",
    "if 'P_VALUE_THRESHOLD' not in locals(): P_VALUE_THRESHOLD = 0.05\n",
    "\n",
    "if 'annotate_p_value' not in locals(): # Fallback definition\n",
    "    def annotate_p_value(ax, p_val, sig_threshold=0.05, custom_text=None, fontsize=8, y_pos=0.9, x_pos=0.98, N_val=\"\"):\n",
    "        if custom_text:\n",
    "            text_to_display = custom_text\n",
    "        elif pd.isna(p_val):\n",
    "            text_to_display = f\"P: N/A\"\n",
    "            if N_val: text_to_display += f\"\\\\nN: {N_val}\"\n",
    "        else:\n",
    "            stars = \"\"\n",
    "            if p_val < 0.001: stars = \"***\"\n",
    "            elif p_val < 0.01: stars = \"**\"\n",
    "            elif p_val < sig_threshold: stars = \"*\"\n",
    "            text_to_display = f\"P: {p_val:.2e}{stars}\"\n",
    "            if N_val: text_to_display += f\"\\\\nN: {N_val}\"\n",
    "        bg_color_ann = 'khaki' if not pd.isna(p_val) and p_val < sig_threshold else 'ivory'\n",
    "        ax.text(x_pos, y_pos, text_to_display, transform=ax.transAxes, fontsize=fontsize,\n",
    "                verticalalignment='top', horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round,pad=0.2', fc=bg_color_ann, alpha=0.7))\n",
    "\n",
    "# --- Cell 9 Specific State Definitions (5 States) ---\n",
    "CELL9_TARGET_STATES_ORDERED = [ # New 5-state order for this cell\n",
    "    \"Sleep\",\n",
    "    \"Immobile\",\n",
    "    \"Non-Dyskinetic Mobile\",\n",
    "    \"Transitional Mobile\",\n",
    "    \"Dyskinetic Mobile\"\n",
    "]\n",
    "\n",
    "CELL9_STATE_COLORS = { # Colors for Cell 9's specific 5 states\n",
    "    'Sleep': '#4169E1',                 # RoyalBlue\n",
    "    'Immobile': '#40E0D0',              # Turquoise\n",
    "    'Non-Dyskinetic Mobile': '#32CD32', # LimeGreen\n",
    "    'Transitional Mobile': '#FFD700',   # Gold\n",
    "    'Dyskinetic Mobile': '#FF6347',     # Tomato\n",
    "    # Add other potential states with a default color if they might appear\n",
    "    'Other': '#C0C0C0'\n",
    "}\n",
    "\n",
    "if 'master_df_step4' not in locals() or master_df_step4.empty:\n",
    "    print(\"master_df_step4 (base data) not available or empty. Skipping Cell 9.\")\n",
    "else:\n",
    "    # Prepare data specifically for Cell 9's 5-state configuration\n",
    "    # No remapping needed, just filtering for these 5 states\n",
    "    df_cell9_input = master_df_step4[master_df_step4[CLINICAL_STATE_COL].isin(CELL9_TARGET_STATES_ORDERED)].copy()\n",
    "\n",
    "    if not df_cell9_input.empty:\n",
    "        df_cell9_input.loc[:, CLINICAL_STATE_COL] = pd.Categorical(\n",
    "            df_cell9_input[CLINICAL_STATE_COL],\n",
    "            categories=CELL9_TARGET_STATES_ORDERED,\n",
    "            ordered=True\n",
    "        )\n",
    "        df_cell9_input.dropna(subset=[CLINICAL_STATE_COL], inplace=True)\n",
    "\n",
    "        if 'datetime_for_avg' not in df_cell9_input.columns:\n",
    "            if 'Aligned_PKG_UnixTimestamp' in df_cell9_input.columns:\n",
    "                df_cell9_input.loc[:, 'datetime_for_avg'] = pd.to_datetime(\n",
    "                    df_cell9_input['Aligned_PKG_UnixTimestamp'], unit='s', utc=True, errors='coerce'\n",
    "                )\n",
    "            else:\n",
    "                print(\"ERROR in Cell 9 Prep: 'Aligned_PKG_UnixTimestamp' missing. 'datetime_for_avg' cannot be created.\")\n",
    "                df_cell9_input.loc[:, 'datetime_for_avg'] = pd.NaT\n",
    "    \n",
    "    if 'df_cell9_input' not in locals() or df_cell9_input.empty:\n",
    "        print(f\"No data found after filtering for Cell 9's target clinical states: {CELL9_TARGET_STATES_ORDERED}. Skipping Cell 9.\")\n",
    "    else:\n",
    "        print(f\"Data prepared for Cell 9. Shape: {df_cell9_input.shape}. Unique states: {df_cell9_input[CLINICAL_STATE_COL].unique()}\")\n",
    "        \n",
    "        # UPDATED output directory name for these specific 5-state plots\n",
    "        plot_subdir_ap_dist_cell9_5states = os.path.join(analysis_session_plot_folder_step4, \"Distributions_Cell9_5States_Sl_Im_NDM_TM_DM\")\n",
    "        os.makedirs(plot_subdir_ap_dist_cell9_5states, exist_ok=True)\n",
    "\n",
    "        if not ORDERED_CHANNEL_LABELS:\n",
    "            first_two_channels, last_two_channels = [], []\n",
    "        else:\n",
    "            first_two_channels = ORDERED_CHANNEL_LABELS[:2]\n",
    "            last_two_channels = ORDERED_CHANNEL_LABELS[-2:] if len(ORDERED_CHANNEL_LABELS) > 2 else []\n",
    "        \n",
    "        print(f\"  Exponent filter (<=3.0) for 'Exponent_BestModel' on channels: {first_two_channels if first_two_channels else 'None'}.\")\n",
    "        if last_two_channels:\n",
    "            print(f\"  Exponent filter (<=5.0) for 'Exponent_BestModel' on channels: {last_two_channels}.\")\n",
    "        print(f\"  Strip plot points will be 10-minute averages.\")\n",
    "        print(f\"  Y-axis for box plots will be fixed to (0, 5.5).\")\n",
    "\n",
    "        subplot_base_width_inches = 2.5 # Adjusted for potentially 5 boxes\n",
    "        subplot_height_inches = subplot_base_width_inches * (16/9.0) \n",
    "\n",
    "        all_kruskal_wallis_results_cell9 = []\n",
    "\n",
    "        for ap_metric_col, ap_metric_name in APERIODIC_METRICS_COLS.items():\n",
    "            y_label_ap_metric = f'{ap_metric_name}'\n",
    "            print(f\"\\\\n  Processing {ap_metric_name} across Cell 9's 5 Clinical States\")\n",
    "\n",
    "            channels_to_plot_in_fig = ORDERED_CHANNEL_LABELS[:N_CHANNELS_PER_OVERVIEW]\n",
    "            if not channels_to_plot_in_fig: \n",
    "                print(f\"    No channels selected for overview plot of {ap_metric_name}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            num_plot_rows = len(channels_to_plot_in_fig)\n",
    "            num_plot_cols = N_FREQ_BANDS_PER_OVERVIEW\n",
    "\n",
    "            fig_overview, axes_overview = plt.subplots(\n",
    "                num_plot_rows, num_plot_cols, \n",
    "                figsize=(num_plot_cols * subplot_base_width_inches, num_plot_rows * subplot_height_inches), \n",
    "                sharey=False, \n",
    "                squeeze=False\n",
    "            )\n",
    "            fig_overview.suptitle(f\"Overview (Cell 9): {ap_metric_name} by 5 Clinical States (K-W & Dunn's)\\\\nPatient: {patient_hemisphere_id} (Y-axis 0-5.5, Pts: 10-min avg)\",\n",
    "                                  fontsize=plt.rcParams['figure.titlesize']*0.85, y=1.04) # Adjusted y for suptitle\n",
    "\n",
    "            for ch_idx, channel_label_plot in enumerate(channels_to_plot_in_fig):\n",
    "                df_channel_current = df_cell9_input[df_cell9_input[CHANNEL_DISPLAY_COL] == channel_label_plot]\n",
    "                \n",
    "                for fr_idx, freq_label_plot in enumerate(ORDERED_FREQ_LABELS): \n",
    "                    ax_current = axes_overview[ch_idx, fr_idx]\n",
    "                    df_stratum_plot = df_channel_current[df_channel_current[FOOOF_FREQ_BAND_COL] == freq_label_plot].copy()\n",
    "                    \n",
    "                    # Apply exponent filtering by setting out-of-range values to NaN, then dropping NaNs for that metric\n",
    "                    if ap_metric_col == 'Exponent_BestModel':\n",
    "                        if channel_label_plot in first_two_channels:\n",
    "                            df_stratum_plot.loc[df_stratum_plot[ap_metric_col] > 3.0, ap_metric_col] = np.nan\n",
    "                        elif channel_label_plot in last_two_channels and channel_label_plot not in first_two_channels:\n",
    "                            df_stratum_plot.loc[df_stratum_plot[ap_metric_col] > 5.0, ap_metric_col] = np.nan\n",
    "                        df_stratum_plot.dropna(subset=[ap_metric_col], inplace=True)\n",
    "                    \n",
    "                    ax_current.set_title(f\"{channel_label_plot}\\\\n{freq_label_plot}\", fontsize=plt.rcParams['axes.titlesize'] * 0.7)\n",
    "                    if ch_idx == num_plot_rows - 1: ax_current.set_xlabel(\"Clinical State\", fontsize=plt.rcParams['axes.labelsize'] * 0.75)\n",
    "                    else: ax_current.set_xlabel(\"\")\n",
    "                    if fr_idx == 0: ax_current.set_ylabel(y_label_ap_metric, fontsize=plt.rcParams['axes.labelsize'] * 0.8)\n",
    "                    else: ax_current.set_ylabel(\"\")\n",
    "                    \n",
    "                    ax_current.set_ylim(0, 5.5) # Y-AXIS LIMIT\n",
    "\n",
    "                    if df_stratum_plot.empty or \\\n",
    "                       df_stratum_plot[ap_metric_col].isnull().all() or \\\n",
    "                       ('datetime_for_avg' in df_stratum_plot.columns and df_stratum_plot['datetime_for_avg'].isnull().all()):\n",
    "                        ax_current.text(0.5, 0.5, \"Insufficient Data\", ha='center', va='center', transform=ax_current.transAxes, fontsize=8)\n",
    "                        ax_current.set_xticks([])\n",
    "                        continue\n",
    "\n",
    "                    boxplot_viz_data_list = []\n",
    "                    for state_val_box in CELL9_TARGET_STATES_ORDERED: \n",
    "                        state_data_for_box_plot = df_stratum_plot[df_stratum_plot[CLINICAL_STATE_COL] == state_val_box]\n",
    "                        if not state_data_for_box_plot.empty:\n",
    "                            trimmed_data = trim_data_for_boxplot_visualization(state_data_for_box_plot, ap_metric_col)\n",
    "                            trimmed_data.loc[:, CLINICAL_STATE_COL] = state_val_box \n",
    "                            boxplot_viz_data_list.append(trimmed_data)\n",
    "                    final_boxplot_viz_df = pd.concat(boxplot_viz_data_list) if boxplot_viz_data_list else pd.DataFrame()\n",
    "\n",
    "                    strip_plot_resampled_list = []\n",
    "                    if 'datetime_for_avg' in df_stratum_plot.columns:\n",
    "                        for state_val_strip in CELL9_TARGET_STATES_ORDERED: \n",
    "                            state_data_for_strip_plot = df_stratum_plot[df_stratum_plot[CLINICAL_STATE_COL] == state_val_strip]\n",
    "                            if not state_data_for_strip_plot.empty and not state_data_for_strip_plot['datetime_for_avg'].isnull().all():\n",
    "                                try:\n",
    "                                    resampled_data = state_data_for_strip_plot.set_index('datetime_for_avg')\\\n",
    "                                                                    .resample('10T')[[ap_metric_col]].mean().dropna()\n",
    "                                    if not resampled_data.empty:\n",
    "                                        resampled_data[CLINICAL_STATE_COL] = state_val_strip\n",
    "                                        strip_plot_resampled_list.append(resampled_data)\n",
    "                                except Exception as e_resample:\n",
    "                                    print(f\"    Resampling error for {channel_label_plot}, {freq_label_plot}, {state_val_strip}: {e_resample}\")\n",
    "                    df_for_stripplot_resampled = pd.concat(strip_plot_resampled_list) if strip_plot_resampled_list else pd.DataFrame()\n",
    "\n",
    "                    if not final_boxplot_viz_df.empty and not final_boxplot_viz_df[ap_metric_col].isnull().all():\n",
    "                        sns.boxplot(data=final_boxplot_viz_df, x=CLINICAL_STATE_COL, y=ap_metric_col, \n",
    "                                    order=CELL9_TARGET_STATES_ORDERED, \n",
    "                                    palette=CELL9_STATE_COLORS, \n",
    "                                    showfliers=False, width=0.7, ax=ax_current, # width can be adjusted for 5 groups\n",
    "                                    boxprops={'alpha': BOX_FILL_ALPHA, 'linewidth': BOXPLOT_LINE_THICKNESS}, \n",
    "                                    medianprops={'linewidth': BOXPLOT_LINE_THICKNESS, 'color':'black'})\n",
    "                    \n",
    "                    if not df_for_stripplot_resampled.empty and not df_for_stripplot_resampled[ap_metric_col].isnull().all():\n",
    "                        sns.stripplot(data=df_for_stripplot_resampled, x=CLINICAL_STATE_COL, y=ap_metric_col, \n",
    "                                      order=CELL9_TARGET_STATES_ORDERED,\n",
    "                                      palette=CELL9_STATE_COLORS, \n",
    "                                      jitter=0.1, alpha=DOT_ALPHA - 0.2 if DOT_ALPHA > 0.2 else 0.1, # Adjusted jitter and alpha\n",
    "                                      size=3.0, ax=ax_current) # Adjusted size\n",
    "                    \n",
    "                    ax_current.tick_params(axis='y', labelsize=plt.rcParams['ytick.labelsize'] * 0.75)\n",
    "                    # Create shorter labels for x-axis if needed, now for 5 states\n",
    "                    xtick_labels_c9_updated = [s.replace(\"Non-Dyskinetic Mobile\", \"NDM\")\n",
    "                                               .replace(\"Transitional Mobile\", \"TM\")\n",
    "                                               .replace(\"Dyskinetic Mobile\", \"DM\")\n",
    "                                               .replace(\"Immobile\", \"Imm.\") \n",
    "                                               .replace(\" Mobile\", \"\\nMob.\") # General catch for mobile if any other variations\n",
    "                                               for s in CELL9_TARGET_STATES_ORDERED]\n",
    "                    ax_current.set_xticklabels(xtick_labels_c9_updated, rotation=45, ha=\"right\", fontsize=plt.rcParams['xtick.labelsize'] * 0.65)\n",
    "\n",
    "                    groups_for_stat_test_kw, group_names_for_stat_test_kw, group_ns_kw = [], [], {}\n",
    "                    for state_val_kw in CELL9_TARGET_STATES_ORDERED: \n",
    "                        data_kw = df_stratum_plot[df_stratum_plot[CLINICAL_STATE_COL] == state_val_kw][ap_metric_col].dropna()\n",
    "                        group_ns_kw[state_val_kw] = len(data_kw)\n",
    "                        if len(data_kw) >= MIN_SAMPLES_FOR_GROUP_COMPARISON:\n",
    "                            groups_for_stat_test_kw.append(data_kw)\n",
    "                            group_names_for_stat_test_kw.append(state_val_kw)\n",
    "                    \n",
    "                    kw_h_val, kw_p_val_stat, annotation_text_kw = np.nan, np.nan, \"\"\n",
    "                    if len(groups_for_stat_test_kw) >= 2: \n",
    "                        try:\n",
    "                            kw_h_val, kw_p_val_stat = kruskal(*groups_for_stat_test_kw)\n",
    "                            annotation_text_kw += f\"K-W P: {kw_p_val_stat:.1e}\" # Slightly more precision for K-W P\n",
    "                            if kw_p_val_stat < P_VALUE_THRESHOLD: annotation_text_kw += \"*\"\n",
    "                            \n",
    "                            stat_entry_kw = {'PatientHemisphereID': patient_hemisphere_id,\n",
    "                                'Channel': channel_label_plot, 'FrequencyBand': freq_label_plot, 'AperiodicMetric': ap_metric_name,\n",
    "                                'Kruskal_H_statistic': kw_h_val, 'Kruskal_p_value': kw_p_val_stat,\n",
    "                                'Compared_Groups_Kruskal': \", \".join(group_names_for_stat_test_kw),\n",
    "                                'Group_Ns_Kruskal': \"; \".join([f\"{name.replace(' ','')[:10]}:{group_ns_kw[name]}\" for name in group_names_for_stat_test_kw])}\n",
    "\n",
    "                            if kw_p_val_stat < P_VALUE_THRESHOLD and len(groups_for_stat_test_kw) > 2:\n",
    "                                dunn_results_df = sp.posthoc_dunn(groups_for_stat_test_kw, p_adjust='bonferroni')\n",
    "                                dunn_results_df.columns = group_names_for_stat_test_kw\n",
    "                                dunn_results_df.index = group_names_for_stat_test_kw\n",
    "                                \n",
    "                                pairs_to_annotate_dunn = [] # Define relevant pairs for 5 states\n",
    "                                if \"Immobile\" in group_names_for_stat_test_kw:\n",
    "                                    for other_st in [\"Non-Dyskinetic Mobile\", \"Transitional Mobile\", \"Dyskinetic Mobile\", \"Sleep\"]:\n",
    "                                        if other_st in group_names_for_stat_test_kw: pairs_to_annotate_dunn.append((\"Immobile\", other_st))\n",
    "                                if \"Sleep\" in group_names_for_stat_test_kw:\n",
    "                                     for mobile_st in [\"Non-Dyskinetic Mobile\", \"Transitional Mobile\", \"Dyskinetic Mobile\"]:\n",
    "                                         if mobile_st in group_names_for_stat_test_kw: pairs_to_annotate_dunn.append((\"Sleep\", mobile_st))\n",
    "                                \n",
    "                                annotation_text_kw += \"\\nDunn's (Bonf):\"\n",
    "                                annot_count = 0\n",
    "                                unique_dunn_pairs_annotated = set()\n",
    "\n",
    "                                for g1_dunn, g2_dunn in pairs_to_annotate_dunn:\n",
    "                                    # Ensure pair is ordered to avoid duplicate checks (e.g. (A,B) vs (B,A)) for display\n",
    "                                    sorted_pair = tuple(sorted((g1_dunn, g2_dunn)))\n",
    "                                    if annot_count < 2 and sorted_pair not in unique_dunn_pairs_annotated and \\\n",
    "                                       g1_dunn in dunn_results_df.index and g2_dunn in dunn_results_df.columns:\n",
    "                                        pair_p_val_dunn = dunn_results_df.loc[g1_dunn, g2_dunn]\n",
    "                                        if pd.notna(pair_p_val_dunn):\n",
    "                                            g1_short = g1_dunn.replace(\"Non-Dyskinetic Mobile\", \"NDM\").replace(\"Transitional Mobile\",\"TM\").replace(\"Dyskinetic Mobile\",\"DM\")[:3]\n",
    "                                            g2_short = g2_dunn.replace(\"Non-Dyskinetic Mobile\", \"NDM\").replace(\"Transitional Mobile\",\"TM\").replace(\"Dyskinetic Mobile\",\"DM\")[:3]\n",
    "                                            pair_text_dunn = f\"\\n{g1_short}v{g2_short}:{pair_p_val_dunn:.1e}\"\n",
    "                                            if pair_p_val_dunn < P_VALUE_THRESHOLD: pair_text_dunn += \"*\"\n",
    "                                            annotation_text_kw += pair_text_dunn\n",
    "                                            annot_count +=1\n",
    "                                            unique_dunn_pairs_annotated.add(sorted_pair)\n",
    "                                        stat_entry_kw[f\"Dunn_{g1_dunn.replace(' ','').replace('-','')}_vs_{g2_dunn.replace(' ','').replace('-','')}_p_adj\"] = pair_p_val_dunn\n",
    "                            all_kruskal_wallis_results_cell9.append(stat_entry_kw)\n",
    "                        except ValueError as e_stat_kw:\n",
    "                            annotation_text_kw = \"Stat Err\"\n",
    "                            print(f\"    Stat error for K-W: {channel_label_plot}, {freq_label_plot}: {e_stat_kw}\")\n",
    "                    else:\n",
    "                        annotation_text_kw = \"N<2 valid grps\"\n",
    "                    \n",
    "                    annotate_p_value(ax_current, kw_p_val_stat if pd.notna(kw_p_val_stat) else 1.0, \n",
    "                                     sig_threshold=P_VALUE_THRESHOLD,\n",
    "                                     fontsize=4.5, y_pos=0.99, x_pos=0.99, # Even smaller for more text\n",
    "                                     custom_text=annotation_text_kw)\n",
    "            \n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.93]) \n",
    "            overview_filename_kw_cell9 = f\"Overview_Box_Cell9_5States_{ap_metric_name.replace(' ','').replace('/','_')}.png\"\n",
    "            plt.savefig(os.path.join(plot_subdir_ap_dist_cell9_5states, overview_filename_kw_cell9), dpi=300)\n",
    "            print(f\"  Saved Cell 9 (5-State) overview box plot for {ap_metric_name}: {overview_filename_kw_cell9}\")\n",
    "            plt.close(fig_overview)\n",
    "\n",
    "        if all_kruskal_wallis_results_cell9:\n",
    "            df_all_kw_stats_cell9 = pd.DataFrame(all_kruskal_wallis_results_cell9)\n",
    "            kw_stats_filename_cell9 = f\"{patient_hemisphere_id}_Cell9_5States_KruskalWallis_Dunn_Stats.csv\"\n",
    "            kw_stats_save_path_cell9 = os.path.join(plot_subdir_ap_dist_cell9_5states, kw_stats_filename_cell9)\n",
    "            df_all_kw_stats_cell9.to_csv(kw_stats_save_path_cell9, index=False)\n",
    "            print(f\"\\\\n  Saved all Cell 9 (5-State) Kruskal-Wallis & Dunn's statistical results to: {kw_stats_save_path_cell9}\")\n",
    "\n",
    "print(\"\\\\n--- Cell 9 (MODIFIED for 5 States - Sleep, Immobile, NDM, TM, DM & 10-min avg points): Box Plots by Clinical States generation attempt complete. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f1a88f-4171-4ce0-ab39-859889db2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- Cell 11: Generate Final Data Table for Cross-Subject Analysis (Input for Step 5) ---\n",
    "# This cell prepares the output from Step 4 to be used as input for Step 5.\n",
    "# The master_df_step4 already contains all necessary information, including\n",
    "# aperiodic metrics for EACH FreqRangeLabel, LEDD, Beta, Gamma.\n",
    "\n",
    "print(\"\\n--- Cell 11: Preparing Data Table for Step 5 (Cross-Subject Analysis) ---\")\n",
    "\n",
    "if master_df_step4 is None or master_df_step4.empty:\n",
    "    print(\"master_df_step4 not available or empty. Cannot generate final table for Step 5.\")\n",
    "else:\n",
    "    # Columns to include in the output for Step 5\n",
    "    # Should match 'master_table_columns' from Step 3 Cell 2, plus UserSessionName from Step 3 Cell 8\n",
    "    # Ensure 'UserSessionName' is defined. If this script is run standalone for one patient-hemi,\n",
    "    # 'UserSessionName' would be the patient_hemisphere_id.\n",
    "    \n",
    "    # Columns defined in Step 3's master_table_columns (Cell 2 of Step 3)\n",
    "    # This list must be kept in sync with the actual columns produced by Step 3.\n",
    "    # For robustness, we select columns that are ACTUALLY PRESENT in master_df_step4\n",
    "    # and try to match the intended set.\n",
    "    \n",
    "    intended_step5_cols = [\n",
    "        'SessionID', 'Hemisphere', 'Channel', CHANNEL_DISPLAY_COL, # CHANNEL_DISPLAY_COL is 'ElectrodeLabel' or similar\n",
    "        'Neural_Segment_Start_Unixtime', 'Neural_Segment_End_Unixtime',\n",
    "        'Neural_Segment_Duration_Sec', 'FS',\n",
    "        # PSD_Data_Str and Frequency_Vector_Str are usually too large for group analysis files\n",
    "        # 'PSD_Data_Str', 'Frequency_Vector_Str', \n",
    "        'Aligned_PKG_UnixTimestamp', 'Aligned_PKG_DateTime_Str', \n",
    "        CLINICAL_STATE_COL, CLINICAL_STATE_AGGREGATED_COL, # Clinical states\n",
    "        'Aligned_BK', 'Aligned_DK', 'Aligned_Tremor_Score', 'Aligned_Tremor',\n",
    "        # New Metrics\n",
    "        'Total_Daily_LEDD_mg',\n",
    "        'Beta_Peak_Power_at_DominantFreq',\n",
    "        'Gamma_Peak_Power_at_DominantFreq',\n",
    "        # FOOOF Results - these are per FreqRangeLabel, so FreqRangeLabel must be included\n",
    "        FOOOF_FREQ_BAND_COL, 'FreqLow', 'FreqHigh', # FreqRangeLabel is critical here\n",
    "        'BestModel_AperiodicMode',\n",
    "        'Offset_BestModel', 'Knee_BestModel', 'Exponent_BestModel',\n",
    "        'R2_BestModel', 'Error_BestModel', 'Num_Peaks_BestModel',\n",
    "        # Optionally, detailed fixed/knee params if needed for specific Step 5 checks:\n",
    "        # 'Offset_Fixed', 'Exponent_Fixed', 'R2_Fixed', 'Error_Fixed', 'Num_Peaks_Fixed',\n",
    "        # 'Offset_Knee', 'Knee_Knee', 'Exponent_Knee', 'R2_Knee', 'Error_Knee', 'Num_Peaks_Knee',\n",
    "        # 'ErrorMsg_FOOOF'\n",
    "    ]\n",
    "    \n",
    "    final_table_cols_step5_existing = [col for col in intended_step5_cols if col in master_df_step4.columns]\n",
    "    \n",
    "    if not final_table_cols_step5_existing:\n",
    "        print(\"Warning: No columns identified for the Step 5 data table. It will be empty.\")\n",
    "        final_data_table_for_step5 = pd.DataFrame()\n",
    "    else:\n",
    "        final_data_table_for_step5 = master_df_step4[final_table_cols_step5_existing].copy()\n",
    "        \n",
    "        # Add 'UserSessionName' which was previously added in Step 3 Cell 8.\n",
    "        # Here, we re-affirm it as the patient_hemisphere_id for this file.\n",
    "        if 'UserSessionName' not in final_data_table_for_step5.columns:\n",
    "            final_data_table_for_step5.insert(0, 'UserSessionName', patient_hemisphere_id)\n",
    "        else: # If it was somehow carried over from a loaded file that already had it\n",
    "            final_data_table_for_step5['UserSessionName'] = patient_hemisphere_id\n",
    "\n",
    "\n",
    "        # Optional: Sort the table\n",
    "        sort_by_cols_step5 = ['UserSessionName', 'Aligned_PKG_UnixTimestamp', CHANNEL_DISPLAY_COL, FOOOF_FREQ_BAND_COL]\n",
    "        sort_by_cols_step5_existing = [col for col in sort_by_cols_step5 if col in final_data_table_for_step5.columns]\n",
    "        if sort_by_cols_step5_existing:\n",
    "            final_data_table_for_step5.sort_values(by=sort_by_cols_step5_existing, inplace=True, ignore_index=True)\n",
    "\n",
    "        print(f\"  Final data table for Step 5 created with {final_data_table_for_step5.shape[0]} rows and {final_data_table_for_step5.shape[1]} columns.\")\n",
    "        print(f\"  Columns included: {final_data_table_for_step5.columns.tolist()}\")\n",
    "\n",
    "    # Define filename and save (this output path should ideally be outside the patient-specific plot folder,\n",
    "    # in a place where Step 5 can glob all such files)\n",
    "    # The original Step 4 saved this in analysis_plots_root_folder (one level up from session_plot_folder_name_step4)\n",
    "    \n",
    "    output_filename_for_step5 = f\"{patient_hemisphere_id}_CrossSubjectAnalysis_DataTable_{current_datetime_str_step4}.csv\"\n",
    "    # Save in the root of the Step 4 analysis folder (step4_analysis_root_folder)\n",
    "    # This aligns with where Step 5 would look for inputs from multiple subjects.\n",
    "    output_path_for_step5 = os.path.join(step4_analysis_root_folder, output_filename_for_step5)\n",
    "\n",
    "    try:\n",
    "        final_data_table_for_step5.to_csv(output_path_for_step5, index=False)\n",
    "        print(f\"  Successfully saved final data table for Step 5 input to: {output_path_for_step5}\")\n",
    "        print(\"\\n  Sample of this final data table (first 5 rows):\")\n",
    "        print(final_data_table_for_step5.head())\n",
    "    except Exception as e_save_final_step4:\n",
    "        print(f\"  ERROR saving the final data table for Step 5 input: {e_save_final_step4}\")\n",
    "\n",
    "print(f\"\\n--- Cell 11: Final Data Table generation for {patient_hemisphere_id} complete ---\")\n",
    "print(f\"\\n--- All Step 4 processing for {patient_hemisphere_id} complete. Outputs are in {analysis_session_plot_folder_step4} and {step4_analysis_root_folder} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96759d89-ec2c-4c98-b689-54b49f98877f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fooof_env",
   "language": "python",
   "name": "fooof_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
